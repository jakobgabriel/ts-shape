{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ts-shape | Timeseries Shaper","text":"<p>This repository contains the ts-shape python package. The abbreviation stands for</p> <p>\"Time Series shaping with rule based methods\".</p> <p>ts-shape is a Python library for efficiently transforms, contextualizes and extracts events from time series data. It provides a set of tools to handle various transformations, making data preparation tasks easier and more intuitive.</p> <p>Besides that multiple engineering specific methods are utilized to make it fast and easy to work with time series data.</p>"},{"location":"#features-concept","title":"Features | Concept","text":"Category Feature Status Transform Filters: Datatype-specific filters \u2714\ufe0f Functions: Lambda functions for transformations \u2714\ufe0f Time Functions: Time-specific transformations \u2714\ufe0f Calculator: Calculation-based transformations \u2714\ufe0f Features Stats: Datatype-specific statistics \u2714\ufe0f Time Stats: Timestamp-specific statistics \u2714\ufe0f Context Contextualize Timeseries datasets with foreign sources \u274c Events Quality Events \u274c Maintenance Events \u274c Production Events \u274c Engineering Events \u274c"},{"location":"#installation","title":"Installation","text":"<p>Install ts-shape using pip:</p> <pre><code>pip install timeseries-shaper\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"<p>For full documentation, visit GitHub Pages or check out the docstrings in the code.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>Contributions are welcome! For major changes, please open an issue first to discuss what you would like to change.</p> <p>Please ensure to update tests as appropriate.</p>"},{"location":"#license","title":"License","text":"<p>Distributed under the MIT License. See LICENSE for more information.</p>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>!TODO</p>"},{"location":"changelog/","title":"next","text":""},{"location":"changelog/#25-12-2024","title":"25-12-2024","text":"<ul> <li>pdoc docs exchanged with mkdocs material autodoc</li> </ul>"},{"location":"changelog/#_1","title":"...","text":""},{"location":"concept/","title":"Necessary Functionality","text":""},{"location":"concept/#inputs","title":"Inputs","text":"<ul> <li>parquet s3</li> <li>timescaledb</li> <li>postgresdb / rest api (signal context)</li> <li>postgrest (business context)</li> </ul>"},{"location":"concept/#combination","title":"Combination","text":"<ul> <li>timeseries combination with signal context</li> </ul> <p>----- HANDOVER FORMAT: DATAFRAME -----</p>"},{"location":"concept/#transform","title":"Transform","text":"<ul> <li>filters - datatype specific filters</li> <li>functions - lamda functions (more general)</li> <li>time_functions </li> <li>calculator</li> </ul>"},{"location":"concept/#features","title":"Features","text":"<ul> <li>stats - datatype specific stats</li> <li>time_stats - timestamp specific stats (last timestamp, first timestamp, occurence per hour, etc.)</li> </ul> <p>----- # -----</p>"},{"location":"concept/#metrics","title":"Metrics","text":"<p>----- # -----</p>"},{"location":"concept/#events","title":"Events","text":"<ul> <li>quality events - </li> <li>maintenance events - </li> <li>production events - </li> <li>engineering events - </li> </ul>"},{"location":"license/","title":"License","text":"<p>MIT License</p> <p>Copyright (c) [2024] Jakob Gabriel</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"insiders/development/","title":"Development","text":""},{"location":"insiders/development/#build-and-publish-package","title":"Build and Publish Package","text":"<ul> <li>Install package locally: <code>pip install -e .</code></li> <li> <p>Run tests locally with pytest: <code>pytest ./tests</code></p> </li> <li> <p>Build package for upload: <code>python setup.py sdist bdist_wheel</code></p> </li> <li>Upload build package to pypi: <code>twine upload dist/* --verbose --skip-existing</code></li> </ul>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>ts_shape<ul> <li>context<ul> <li>value_mapping</li> </ul> </li> <li>events<ul> <li>maintenance</li> <li>production</li> <li>quality<ul> <li>outlier_detection</li> <li>statistical_process_control</li> <li>tolerance_deviation</li> </ul> </li> </ul> </li> <li>features<ul> <li>cycles<ul> <li>cycle_processor</li> <li>cycles_extractor</li> </ul> </li> <li>stats<ul> <li>boolean_stats</li> <li>feature_table</li> <li>numeric_stats</li> <li>string_stats</li> <li>timestamp_stats</li> </ul> </li> <li>time_stats<ul> <li>time_stats_numeric</li> </ul> </li> </ul> </li> <li>loader<ul> <li>combine<ul> <li>integrator</li> </ul> </li> <li>context</li> <li>metadata<ul> <li>metadata_api_loader</li> <li>metadata_db_loader</li> </ul> </li> <li>timeseries<ul> <li>parquet_loader</li> <li>s3proxy_parquet_loader</li> <li>timescale_loader</li> </ul> </li> </ul> </li> <li>transform<ul> <li>calculator<ul> <li>numeric_calc</li> </ul> </li> <li>filter<ul> <li>boolean_filter</li> <li>custom_filter</li> <li>datetime_filter</li> <li>numeric_filter</li> <li>string_filter</li> </ul> </li> <li>functions<ul> <li>lambda_func</li> </ul> </li> <li>time_functions<ul> <li>timestamp_converter</li> <li>timezone_shift</li> </ul> </li> </ul> </li> <li>utils<ul> <li>base</li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/ts_shape/context/__init__/","title":"init","text":""},{"location":"reference/ts_shape/context/__init__/#ts_shape.context","title":"context","text":"<p>test</p> <p>Modules:</p> <ul> <li> <code>value_mapping</code>           \u2013            </li> </ul>"},{"location":"reference/ts_shape/context/value_mapping/","title":"value_mapping","text":""},{"location":"reference/ts_shape/context/value_mapping/#ts_shape.context.value_mapping","title":"value_mapping","text":"<p>Classes:</p> <ul> <li> <code>ValueMapper</code>           \u2013            <p>A class to map values from specified columns of a DataFrame using a mapping table (CSV or JSON file),</p> </li> </ul>"},{"location":"reference/ts_shape/context/value_mapping/#ts_shape.context.value_mapping.ValueMapper","title":"ValueMapper","text":"<pre><code>ValueMapper(dataframe: DataFrame, mapping_file: str, map_column: str, mapping_key_column: str, mapping_value_column: str, file_type: str = 'csv', sep: str = ',', encoding: str = 'utf-8', column_name: str = 'systime')\n</code></pre> <p>               Bases: <code>Base</code></p> <p>A class to map values from specified columns of a DataFrame using a mapping table (CSV or JSON file), inheriting from the Base class.</p> <p>Parameters:</p> <p>Methods:</p> <ul> <li> <code>get_dataframe</code>             \u2013              <p>Returns the processed DataFrame.</p> </li> <li> <code>map_values</code>             \u2013              <p>Maps values in the specified DataFrame column based on the mapping table.</p> </li> </ul> Source code in <code>src/ts_shape/context/value_mapping.py</code> <pre><code>def __init__(\n    self, \n    dataframe: pd.DataFrame, \n    mapping_file: str, \n    map_column: str, \n    mapping_key_column: str, \n    mapping_value_column: str, \n    file_type: str = 'csv', \n    sep: str = ',', \n    encoding: str = 'utf-8', \n    column_name: str = 'systime'\n) -&gt; None:\n    \"\"\"\n    Initializes ValueMapper and the base DataFrame from the Base class.\n\n    Args:\n        dataframe (pd.DataFrame): The DataFrame to be processed and mapped.\n        mapping_file (str): The file path of the mapping table (CSV or JSON).\n        map_column (str): The name of the column in the DataFrame that needs to be mapped.\n        mapping_key_column (str): The column in the mapping table to match with values from the DataFrame.\n        mapping_value_column (str): The column in the mapping table containing the values to map to.\n        file_type (str): The type of the mapping file ('csv' or 'json'). Defaults to 'csv'.\n        sep (str): The separator for CSV files. Defaults to ','.\n        encoding (str): The encoding to use for reading the file. Defaults to 'utf-8'.\n        column_name (str): The name of the column to sort the DataFrame by in the base class. Defaults to 'systime'.\n    \"\"\"\n    # Initialize the Base class with the sorted DataFrame\n    super().__init__(dataframe, column_name)\n\n    # Additional attributes for ValueMapper\n    self.map_column: str = map_column\n    self.mapping_key_column: str = mapping_key_column\n    self.mapping_value_column: str = mapping_value_column\n    self.sep: str = sep\n    self.encoding: str = encoding\n\n    # Load the mapping table based on file type\n    self.mapping_table: pd.DataFrame = self._load_mapping_table(mapping_file, file_type)\n</code></pre>"},{"location":"reference/ts_shape/context/value_mapping/#ts_shape.context.value_mapping.ValueMapper(dataframe)","title":"<code>dataframe</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The DataFrame to be processed and mapped.</p>"},{"location":"reference/ts_shape/context/value_mapping/#ts_shape.context.value_mapping.ValueMapper(mapping_file)","title":"<code>mapping_file</code>","text":"(<code>str</code>)           \u2013            <p>The file path of the mapping table (CSV or JSON).</p>"},{"location":"reference/ts_shape/context/value_mapping/#ts_shape.context.value_mapping.ValueMapper(map_column)","title":"<code>map_column</code>","text":"(<code>str</code>)           \u2013            <p>The name of the column in the DataFrame that needs to be mapped.</p>"},{"location":"reference/ts_shape/context/value_mapping/#ts_shape.context.value_mapping.ValueMapper(mapping_key_column)","title":"<code>mapping_key_column</code>","text":"(<code>str</code>)           \u2013            <p>The column in the mapping table to match with values from the DataFrame.</p>"},{"location":"reference/ts_shape/context/value_mapping/#ts_shape.context.value_mapping.ValueMapper(mapping_value_column)","title":"<code>mapping_value_column</code>","text":"(<code>str</code>)           \u2013            <p>The column in the mapping table containing the values to map to.</p>"},{"location":"reference/ts_shape/context/value_mapping/#ts_shape.context.value_mapping.ValueMapper(file_type)","title":"<code>file_type</code>","text":"(<code>str</code>, default:                   <code>'csv'</code> )           \u2013            <p>The type of the mapping file ('csv' or 'json'). Defaults to 'csv'.</p>"},{"location":"reference/ts_shape/context/value_mapping/#ts_shape.context.value_mapping.ValueMapper(sep)","title":"<code>sep</code>","text":"(<code>str</code>, default:                   <code>','</code> )           \u2013            <p>The separator for CSV files. Defaults to ','.</p>"},{"location":"reference/ts_shape/context/value_mapping/#ts_shape.context.value_mapping.ValueMapper(encoding)","title":"<code>encoding</code>","text":"(<code>str</code>, default:                   <code>'utf-8'</code> )           \u2013            <p>The encoding to use for reading the file. Defaults to 'utf-8'.</p>"},{"location":"reference/ts_shape/context/value_mapping/#ts_shape.context.value_mapping.ValueMapper(column_name)","title":"<code>column_name</code>","text":"(<code>str</code>, default:                   <code>'systime'</code> )           \u2013            <p>The name of the column to sort the DataFrame by in the base class. Defaults to 'systime'.</p>"},{"location":"reference/ts_shape/context/value_mapping/#ts_shape.context.value_mapping.ValueMapper.get_dataframe","title":"get_dataframe","text":"<pre><code>get_dataframe() -&gt; DataFrame\n</code></pre> <p>Returns the processed DataFrame.</p> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def get_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"Returns the processed DataFrame.\"\"\"\n    return self.dataframe\n</code></pre>"},{"location":"reference/ts_shape/context/value_mapping/#ts_shape.context.value_mapping.ValueMapper.map_values","title":"map_values","text":"<pre><code>map_values() -&gt; DataFrame\n</code></pre> <p>Maps values in the specified DataFrame column based on the mapping table.</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: A new DataFrame with the mapped values.</p> </li> </ul> Source code in <code>src/ts_shape/context/value_mapping.py</code> <pre><code>def map_values(self) -&gt; pd.DataFrame:\n    \"\"\"\n    Maps values in the specified DataFrame column based on the mapping table.\n\n    Returns:\n        pd.DataFrame: A new DataFrame with the mapped values.\n    \"\"\"\n    # Merge the mapping table with the DataFrame based on the map_column and mapping_key_column\n    mapped_df = self.dataframe.merge(\n        self.mapping_table[[self.mapping_key_column, self.mapping_value_column]],\n        left_on=self.map_column,\n        right_on=self.mapping_key_column,\n        how='left'\n    )\n\n    # Replace the original column with the mapped values\n    mapped_df[self.map_column] = mapped_df[self.mapping_value_column]\n\n    # Drop unnecessary columns\n    mapped_df = mapped_df.drop([self.mapping_key_column, self.mapping_value_column], axis=1)\n\n    return mapped_df\n</code></pre>"},{"location":"reference/ts_shape/events/__init__/","title":"init","text":""},{"location":"reference/ts_shape/events/__init__/#ts_shape.events","title":"events","text":"<p>Modules:</p> <ul> <li> <code>quality</code>           \u2013            </li> </ul>"},{"location":"reference/ts_shape/events/maintenance/__init__/","title":"maintenance","text":""},{"location":"reference/ts_shape/events/maintenance/__init__/#ts_shape.events.maintenance","title":"maintenance","text":""},{"location":"reference/ts_shape/events/production/__init__/","title":"production","text":""},{"location":"reference/ts_shape/events/production/__init__/#ts_shape.events.production","title":"production","text":""},{"location":"reference/ts_shape/events/quality/__init__/","title":"init","text":""},{"location":"reference/ts_shape/events/quality/__init__/#ts_shape.events.quality","title":"quality","text":"<p>Modules:</p> <ul> <li> <code>outlier_detection</code>           \u2013            </li> <li> <code>statistical_process_control</code>           \u2013            </li> <li> <code>tolerance_deviation</code>           \u2013            </li> </ul>"},{"location":"reference/ts_shape/events/quality/outlier_detection/","title":"outlier_detection","text":""},{"location":"reference/ts_shape/events/quality/outlier_detection/#ts_shape.events.quality.outlier_detection","title":"outlier_detection","text":"<p>Classes:</p> <ul> <li> <code>OutlierDetectionEvents</code>           \u2013            <p>Processes time series data to detect outliers based on specified statistical methods.</p> </li> </ul>"},{"location":"reference/ts_shape/events/quality/outlier_detection/#ts_shape.events.quality.outlier_detection.OutlierDetectionEvents","title":"OutlierDetectionEvents","text":"<pre><code>OutlierDetectionEvents(dataframe: DataFrame, value_column: str, event_uuid: str = 'outlier_event', time_threshold: str = '5min')\n</code></pre> <p>               Bases: <code>Base</code></p> <p>Processes time series data to detect outliers based on specified statistical methods.</p> <p>Parameters:</p> <p>Methods:</p> <ul> <li> <code>detect_outliers_iqr</code>             \u2013              <p>Detects outliers using the IQR method.</p> </li> <li> <code>detect_outliers_zscore</code>             \u2013              <p>Detects outliers using the Z-score method.</p> </li> <li> <code>get_dataframe</code>             \u2013              <p>Returns the processed DataFrame.</p> </li> </ul> Source code in <code>src/ts_shape/events/quality/outlier_detection.py</code> <pre><code>def __init__(self, dataframe: pd.DataFrame, value_column: str, event_uuid: str = 'outlier_event', \n             time_threshold: str = '5min') -&gt; None:\n    \"\"\"\n    Initializes the OutlierDetectionEvents with specific attributes for outlier detection.\n\n    Args:\n        dataframe (pd.DataFrame): The input time series DataFrame.\n        value_column (str): The name of the column containing the values for outlier detection.\n        event_uuid (str): A UUID or identifier for detected outlier events.\n        time_threshold (str): The time threshold to group close events together.\n    \"\"\"\n    super().__init__(dataframe)\n    self.value_column = value_column\n    self.event_uuid = event_uuid\n    self.time_threshold = time_threshold\n</code></pre>"},{"location":"reference/ts_shape/events/quality/outlier_detection/#ts_shape.events.quality.outlier_detection.OutlierDetectionEvents(dataframe)","title":"<code>dataframe</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The input time series DataFrame.</p>"},{"location":"reference/ts_shape/events/quality/outlier_detection/#ts_shape.events.quality.outlier_detection.OutlierDetectionEvents(value_column)","title":"<code>value_column</code>","text":"(<code>str</code>)           \u2013            <p>The name of the column containing the values for outlier detection.</p>"},{"location":"reference/ts_shape/events/quality/outlier_detection/#ts_shape.events.quality.outlier_detection.OutlierDetectionEvents(event_uuid)","title":"<code>event_uuid</code>","text":"(<code>str</code>, default:                   <code>'outlier_event'</code> )           \u2013            <p>A UUID or identifier for detected outlier events.</p>"},{"location":"reference/ts_shape/events/quality/outlier_detection/#ts_shape.events.quality.outlier_detection.OutlierDetectionEvents(time_threshold)","title":"<code>time_threshold</code>","text":"(<code>str</code>, default:                   <code>'5min'</code> )           \u2013            <p>The time threshold to group close events together.</p>"},{"location":"reference/ts_shape/events/quality/outlier_detection/#ts_shape.events.quality.outlier_detection.OutlierDetectionEvents.detect_outliers_iqr","title":"detect_outliers_iqr","text":"<pre><code>detect_outliers_iqr(threshold: tuple = (1.5, 1.5)) -&gt; DataFrame\n</code></pre> <p>Detects outliers using the IQR method.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: A DataFrame of detected outliers and grouped events.</p> </li> </ul> Source code in <code>src/ts_shape/events/quality/outlier_detection.py</code> <pre><code>def detect_outliers_iqr(self, threshold: tuple = (1.5, 1.5)) -&gt; pd.DataFrame:\n    \"\"\"\n    Detects outliers using the IQR method.\n\n    Args:\n        threshold (tuple): The multipliers for the IQR range for detecting outliers (lower, upper).\n\n    Returns:\n        pd.DataFrame: A DataFrame of detected outliers and grouped events.\n    \"\"\"\n    df = self.dataframe.copy()\n\n    # Convert 'systime' to datetime and sort the DataFrame by 'systime' in descending order\n    df['systime'] = pd.to_datetime(df['systime'])\n    df = df.sort_values(by='systime', ascending=False)\n\n    # Detect outliers using the IQR method\n    Q1 = df[self.value_column].quantile(0.25)\n    Q3 = df[self.value_column].quantile(0.75)\n    IQR = Q3 - Q1\n    lower_bound = Q1 - threshold[0] * IQR\n    upper_bound = Q3 + threshold[1] * IQR\n    df['outlier'] = (df[self.value_column] &lt; lower_bound) | (df[self.value_column] &gt; upper_bound)\n\n    # Filter to keep only outliers\n    outliers_df = df[df['outlier']]\n\n    # Group and return the outliers\n    return self._group_outliers(outliers_df)\n</code></pre>"},{"location":"reference/ts_shape/events/quality/outlier_detection/#ts_shape.events.quality.outlier_detection.OutlierDetectionEvents.detect_outliers_iqr(threshold)","title":"<code>threshold</code>","text":"(<code>tuple</code>, default:                   <code>(1.5, 1.5)</code> )           \u2013            <p>The multipliers for the IQR range for detecting outliers (lower, upper).</p>"},{"location":"reference/ts_shape/events/quality/outlier_detection/#ts_shape.events.quality.outlier_detection.OutlierDetectionEvents.detect_outliers_zscore","title":"detect_outliers_zscore","text":"<pre><code>detect_outliers_zscore(threshold: float = 3.0) -&gt; DataFrame\n</code></pre> <p>Detects outliers using the Z-score method.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: A DataFrame of detected outliers and grouped events.</p> </li> </ul> Source code in <code>src/ts_shape/events/quality/outlier_detection.py</code> <pre><code>def detect_outliers_zscore(self, threshold: float = 3.0) -&gt; pd.DataFrame:\n    \"\"\"\n    Detects outliers using the Z-score method.\n\n    Args:\n        threshold (float): The Z-score threshold for detecting outliers.\n\n    Returns:\n        pd.DataFrame: A DataFrame of detected outliers and grouped events.\n    \"\"\"\n    df = self.dataframe.copy()\n\n    # Convert 'systime' to datetime and sort the DataFrame by 'systime' in descending order\n    df['systime'] = pd.to_datetime(df['systime'])\n    df = df.sort_values(by='systime', ascending=False)\n\n    # Detect outliers using the Z-score method\n    df['outlier'] = np.abs(zscore(df[self.value_column])) &gt; threshold\n\n    # Filter to keep only outliers\n    outliers_df = df[df['outlier']]\n\n    # Group and return the outliers\n    return self._group_outliers(outliers_df)\n</code></pre>"},{"location":"reference/ts_shape/events/quality/outlier_detection/#ts_shape.events.quality.outlier_detection.OutlierDetectionEvents.detect_outliers_zscore(threshold)","title":"<code>threshold</code>","text":"(<code>float</code>, default:                   <code>3.0</code> )           \u2013            <p>The Z-score threshold for detecting outliers.</p>"},{"location":"reference/ts_shape/events/quality/outlier_detection/#ts_shape.events.quality.outlier_detection.OutlierDetectionEvents.get_dataframe","title":"get_dataframe","text":"<pre><code>get_dataframe() -&gt; DataFrame\n</code></pre> <p>Returns the processed DataFrame.</p> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def get_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"Returns the processed DataFrame.\"\"\"\n    return self.dataframe\n</code></pre>"},{"location":"reference/ts_shape/events/quality/statistical_process_control/","title":"statistical_process_control","text":""},{"location":"reference/ts_shape/events/quality/statistical_process_control/#ts_shape.events.quality.statistical_process_control","title":"statistical_process_control","text":"<p>Classes:</p> <ul> <li> <code>StatisticalProcessControlRuleBased</code>           \u2013            <p>Inherits from Base and applies SPC rules (Western Electric Rules) to a DataFrame for event detection.</p> </li> </ul>"},{"location":"reference/ts_shape/events/quality/statistical_process_control/#ts_shape.events.quality.statistical_process_control.StatisticalProcessControlRuleBased","title":"StatisticalProcessControlRuleBased","text":"<pre><code>StatisticalProcessControlRuleBased(dataframe: DataFrame, value_column: str, tolerance_uuid: str, actual_uuid: str, event_uuid: str)\n</code></pre> <p>               Bases: <code>Base</code></p> <p>Inherits from Base and applies SPC rules (Western Electric Rules) to a DataFrame for event detection. Processes data based on control limit UUIDs, actual value UUIDs, and generates events with an event UUID.</p> <p>Parameters:</p> <p>Methods:</p> <ul> <li> <code>calculate_control_limits</code>             \u2013              <p>Calculate the control limits (mean \u00b1 1\u03c3, 2\u03c3, 3\u03c3) for the tolerance values.</p> </li> <li> <code>get_dataframe</code>             \u2013              <p>Returns the processed DataFrame.</p> </li> <li> <code>process</code>             \u2013              <p>Applies the selected SPC rules and generates a DataFrame of events where any rules are violated.</p> </li> <li> <code>rule_1</code>             \u2013              <p>Rule 1: One point beyond the 3\u03c3 control limits.</p> </li> <li> <code>rule_2</code>             \u2013              <p>Rule 2: Nine consecutive points on one side of the mean.</p> </li> <li> <code>rule_3</code>             \u2013              <p>Rule 3: Six consecutive points steadily increasing or decreasing.</p> </li> <li> <code>rule_4</code>             \u2013              <p>Rule 4: Fourteen consecutive points alternating up and down.</p> </li> <li> <code>rule_5</code>             \u2013              <p>Rule 5: Two out of three consecutive points near the control limit (beyond 2\u03c3 but within 3\u03c3).</p> </li> <li> <code>rule_6</code>             \u2013              <p>Rule 6: Four out of five consecutive points near the control limit (beyond 1\u03c3 but within 2\u03c3).</p> </li> <li> <code>rule_7</code>             \u2013              <p>Rule 7: Fifteen consecutive points within 1\u03c3 of the centerline.</p> </li> <li> <code>rule_8</code>             \u2013              <p>Rule 8: Eight consecutive points on both sides of the mean within 1\u03c3.</p> </li> </ul> Source code in <code>src/ts_shape/events/quality/statistical_process_control.py</code> <pre><code>def __init__(self, dataframe: pd.DataFrame, value_column: str, tolerance_uuid: str, actual_uuid: str, event_uuid: str) -&gt; None:\n    \"\"\"\n    Initializes the SPCMonitor with UUIDs for tolerance, actual, and event values.\n    Inherits the sorted dataframe from the Base class.\n\n    Args:\n        dataframe (pd.DataFrame): The input DataFrame containing the data to be processed.\n        value_column (str): The column containing the values to monitor.\n        tolerance_uuid (str): UUID identifier for rows that set tolerance values.\n        actual_uuid (str): UUID identifier for rows containing actual values.\n        event_uuid (str): UUID to assign to generated events.\n    \"\"\"\n    super().__init__(dataframe)  # Initialize the Base class\n    self.value_column: str = value_column\n    self.tolerance_uuid: str = tolerance_uuid\n    self.actual_uuid: str = actual_uuid\n    self.event_uuid: str = event_uuid\n</code></pre>"},{"location":"reference/ts_shape/events/quality/statistical_process_control/#ts_shape.events.quality.statistical_process_control.StatisticalProcessControlRuleBased(dataframe)","title":"<code>dataframe</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The input DataFrame containing the data to be processed.</p>"},{"location":"reference/ts_shape/events/quality/statistical_process_control/#ts_shape.events.quality.statistical_process_control.StatisticalProcessControlRuleBased(value_column)","title":"<code>value_column</code>","text":"(<code>str</code>)           \u2013            <p>The column containing the values to monitor.</p>"},{"location":"reference/ts_shape/events/quality/statistical_process_control/#ts_shape.events.quality.statistical_process_control.StatisticalProcessControlRuleBased(tolerance_uuid)","title":"<code>tolerance_uuid</code>","text":"(<code>str</code>)           \u2013            <p>UUID identifier for rows that set tolerance values.</p>"},{"location":"reference/ts_shape/events/quality/statistical_process_control/#ts_shape.events.quality.statistical_process_control.StatisticalProcessControlRuleBased(actual_uuid)","title":"<code>actual_uuid</code>","text":"(<code>str</code>)           \u2013            <p>UUID identifier for rows containing actual values.</p>"},{"location":"reference/ts_shape/events/quality/statistical_process_control/#ts_shape.events.quality.statistical_process_control.StatisticalProcessControlRuleBased(event_uuid)","title":"<code>event_uuid</code>","text":"(<code>str</code>)           \u2013            <p>UUID to assign to generated events.</p>"},{"location":"reference/ts_shape/events/quality/statistical_process_control/#ts_shape.events.quality.statistical_process_control.StatisticalProcessControlRuleBased.calculate_control_limits","title":"calculate_control_limits","text":"<pre><code>calculate_control_limits() -&gt; DataFrame\n</code></pre> <p>Calculate the control limits (mean \u00b1 1\u03c3, 2\u03c3, 3\u03c3) for the tolerance values.</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: DataFrame with control limits for each tolerance group.</p> </li> </ul> Source code in <code>src/ts_shape/events/quality/statistical_process_control.py</code> <pre><code>def calculate_control_limits(self) -&gt; pd.DataFrame:\n    \"\"\"\n    Calculate the control limits (mean \u00b1 1\u03c3, 2\u03c3, 3\u03c3) for the tolerance values.\n\n    Returns:\n        pd.DataFrame: DataFrame with control limits for each tolerance group.\n    \"\"\"\n    df = self.dataframe[self.dataframe['uuid'] == self.tolerance_uuid]\n    mean = df[self.value_column].mean()\n    sigma = df[self.value_column].std()\n\n    control_limits = {\n        'mean': mean,\n        '1sigma_upper': mean + sigma,\n        '1sigma_lower': mean - sigma,\n        '2sigma_upper': mean + 2 * sigma,\n        '2sigma_lower': mean - 2 * sigma,\n        '3sigma_upper': mean + 3 * sigma,\n        '3sigma_lower': mean - 3 * sigma,\n    }\n\n    return pd.DataFrame([control_limits])\n</code></pre>"},{"location":"reference/ts_shape/events/quality/statistical_process_control/#ts_shape.events.quality.statistical_process_control.StatisticalProcessControlRuleBased.get_dataframe","title":"get_dataframe","text":"<pre><code>get_dataframe() -&gt; DataFrame\n</code></pre> <p>Returns the processed DataFrame.</p> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def get_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"Returns the processed DataFrame.\"\"\"\n    return self.dataframe\n</code></pre>"},{"location":"reference/ts_shape/events/quality/statistical_process_control/#ts_shape.events.quality.statistical_process_control.StatisticalProcessControlRuleBased.process","title":"process","text":"<pre><code>process(selected_rules: Optional[List[str]] = None) -&gt; DataFrame\n</code></pre> <p>Applies the selected SPC rules and generates a DataFrame of events where any rules are violated.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: DataFrame with rule violations and detected events.</p> </li> </ul> Source code in <code>src/ts_shape/events/quality/statistical_process_control.py</code> <pre><code>def process(self, selected_rules: Optional[List[str]] = None) -&gt; pd.DataFrame:\n    \"\"\"\n    Applies the selected SPC rules and generates a DataFrame of events where any rules are violated.\n\n    Args:\n        selected_rules (Optional[List[str]]): List of rule names (e.g., ['rule_1', 'rule_3']) to apply.\n\n    Returns:\n        pd.DataFrame: DataFrame with rule violations and detected events.\n    \"\"\"\n    df = self.dataframe[self.dataframe['uuid'] == self.actual_uuid]\n    df['systime'] = pd.to_datetime(df['systime'])\n    df = df.sort_values(by='systime')\n\n    limits = self.calculate_control_limits()\n\n    # Dictionary of rule functions\n    rules = {\n        'rule_1': lambda df: self.rule_1(df, limits),\n        'rule_2': lambda df: self.rule_2(df),\n        'rule_3': lambda df: self.rule_3(df),\n        'rule_4': lambda df: self.rule_4(df),\n        'rule_5': lambda df: self.rule_5(df, limits),\n        'rule_6': lambda df: self.rule_6(df, limits),\n        'rule_7': lambda df: self.rule_7(df, limits),\n        'rule_8': lambda df: self.rule_8(df, limits)\n    }\n\n    # If no specific rules are provided, use all rules\n    if selected_rules is None:\n        selected_rules = list(rules.keys())\n\n    # Apply selected rules and concatenate results\n    events = pd.concat([rules[rule](df) for rule in selected_rules if rule in rules]).drop_duplicates()\n\n    # Add the event UUID to the detected events\n    events['uuid'] = self.event_uuid\n\n    return events[['systime', self.value_column, 'uuid']].drop_duplicates()\n</code></pre>"},{"location":"reference/ts_shape/events/quality/statistical_process_control/#ts_shape.events.quality.statistical_process_control.StatisticalProcessControlRuleBased.process(selected_rules)","title":"<code>selected_rules</code>","text":"(<code>Optional[List[str]]</code>, default:                   <code>None</code> )           \u2013            <p>List of rule names (e.g., ['rule_1', 'rule_3']) to apply.</p>"},{"location":"reference/ts_shape/events/quality/statistical_process_control/#ts_shape.events.quality.statistical_process_control.StatisticalProcessControlRuleBased.rule_1","title":"rule_1","text":"<pre><code>rule_1(df: DataFrame, limits: DataFrame) -&gt; DataFrame\n</code></pre> <p>Rule 1: One point beyond the 3\u03c3 control limits.</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: Filtered DataFrame with rule violations.</p> </li> </ul> Source code in <code>src/ts_shape/events/quality/statistical_process_control.py</code> <pre><code>def rule_1(self, df: pd.DataFrame, limits: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"\n    Rule 1: One point beyond the 3\u03c3 control limits.\n\n    Returns:\n        pd.DataFrame: Filtered DataFrame with rule violations.\n    \"\"\"\n    df['rule_1'] = (df[self.value_column] &gt; limits['3sigma_upper'].values[0]) | (df[self.value_column] &lt; limits['3sigma_lower'].values[0])\n    return df[df['rule_1']]\n</code></pre>"},{"location":"reference/ts_shape/events/quality/statistical_process_control/#ts_shape.events.quality.statistical_process_control.StatisticalProcessControlRuleBased.rule_2","title":"rule_2","text":"<pre><code>rule_2(df: DataFrame) -&gt; DataFrame\n</code></pre> <p>Rule 2: Nine consecutive points on one side of the mean.</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: Filtered DataFrame with rule violations.</p> </li> </ul> Source code in <code>src/ts_shape/events/quality/statistical_process_control.py</code> <pre><code>def rule_2(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"\n    Rule 2: Nine consecutive points on one side of the mean.\n\n    Returns:\n        pd.DataFrame: Filtered DataFrame with rule violations.\n    \"\"\"\n    mean = df[self.value_column].mean()\n    df['above_mean'] = df[self.value_column] &gt; mean\n    df['below_mean'] = df[self.value_column] &lt; mean\n    df['rule_2'] = (df['above_mean'].rolling(window=9).sum() == 9) | (df['below_mean'].rolling(window=9).sum() == 9)\n    return df[df['rule_2']]\n</code></pre>"},{"location":"reference/ts_shape/events/quality/statistical_process_control/#ts_shape.events.quality.statistical_process_control.StatisticalProcessControlRuleBased.rule_3","title":"rule_3","text":"<pre><code>rule_3(df: DataFrame) -&gt; DataFrame\n</code></pre> <p>Rule 3: Six consecutive points steadily increasing or decreasing.</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: Filtered DataFrame with rule violations.</p> </li> </ul> Source code in <code>src/ts_shape/events/quality/statistical_process_control.py</code> <pre><code>def rule_3(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"\n    Rule 3: Six consecutive points steadily increasing or decreasing.\n\n    Returns:\n        pd.DataFrame: Filtered DataFrame with rule violations.\n    \"\"\"\n    df['increasing'] = df[self.value_column].diff().gt(0)\n    df['decreasing'] = df[self.value_column].diff().lt(0)\n    df['rule_3'] = (df['increasing'].rolling(window=6).sum() == 6) | (df['decreasing'].rolling(window=6).sum() == 6)\n    return df[df['rule_3']]\n</code></pre>"},{"location":"reference/ts_shape/events/quality/statistical_process_control/#ts_shape.events.quality.statistical_process_control.StatisticalProcessControlRuleBased.rule_4","title":"rule_4","text":"<pre><code>rule_4(df: DataFrame) -&gt; DataFrame\n</code></pre> <p>Rule 4: Fourteen consecutive points alternating up and down.</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: Filtered DataFrame with rule violations.</p> </li> </ul> Source code in <code>src/ts_shape/events/quality/statistical_process_control.py</code> <pre><code>def rule_4(self, df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"\n    Rule 4: Fourteen consecutive points alternating up and down.\n\n    Returns:\n        pd.DataFrame: Filtered DataFrame with rule violations.\n    \"\"\"\n    df['alternating'] = df[self.value_column].diff().apply(np.sign)\n    df['rule_4'] = df['alternating'].rolling(window=14).apply(lambda x: (x != x.shift()).sum() == 13, raw=True)\n    return df[df['rule_4']]\n</code></pre>"},{"location":"reference/ts_shape/events/quality/statistical_process_control/#ts_shape.events.quality.statistical_process_control.StatisticalProcessControlRuleBased.rule_5","title":"rule_5","text":"<pre><code>rule_5(df: DataFrame, limits: DataFrame) -&gt; DataFrame\n</code></pre> <p>Rule 5: Two out of three consecutive points near the control limit (beyond 2\u03c3 but within 3\u03c3).</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: Filtered DataFrame with rule violations.</p> </li> </ul> Source code in <code>src/ts_shape/events/quality/statistical_process_control.py</code> <pre><code>def rule_5(self, df: pd.DataFrame, limits: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"\n    Rule 5: Two out of three consecutive points near the control limit (beyond 2\u03c3 but within 3\u03c3).\n\n    Returns:\n        pd.DataFrame: Filtered DataFrame with rule violations.\n    \"\"\"\n    df['rule_5'] = df[self.value_column].apply(\n        lambda x: 1 if ((x &gt; limits['2sigma_upper'].values[0] and x &lt; limits['3sigma_upper'].values[0]) or \n                        (x &lt; limits['2sigma_lower'].values[0] and x &gt; limits['3sigma_lower'].values[0])) else 0\n    )\n    df['rule_5'] = df['rule_5'].rolling(window=3).sum() &gt;= 2\n    return df[df['rule_5']]\n</code></pre>"},{"location":"reference/ts_shape/events/quality/statistical_process_control/#ts_shape.events.quality.statistical_process_control.StatisticalProcessControlRuleBased.rule_6","title":"rule_6","text":"<pre><code>rule_6(df: DataFrame, limits: DataFrame) -&gt; DataFrame\n</code></pre> <p>Rule 6: Four out of five consecutive points near the control limit (beyond 1\u03c3 but within 2\u03c3).</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: Filtered DataFrame with rule violations.</p> </li> </ul> Source code in <code>src/ts_shape/events/quality/statistical_process_control.py</code> <pre><code>def rule_6(self, df: pd.DataFrame, limits: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"\n    Rule 6: Four out of five consecutive points near the control limit (beyond 1\u03c3 but within 2\u03c3).\n\n    Returns:\n        pd.DataFrame: Filtered DataFrame with rule violations.\n    \"\"\"\n    df['rule_6'] = df[self.value_column].apply(\n        lambda x: 1 if ((x &gt; limits['1sigma_upper'].values[0] and x &lt; limits['2sigma_upper'].values[0]) or \n                        (x &lt; limits['1sigma_lower'].values[0] and x &gt; limits['2sigma_lower'].values[0])) else 0\n    )\n    df['rule_6'] = df['rule_6'].rolling(window=5).sum() &gt;= 4\n    return df[df['rule_6']]\n</code></pre>"},{"location":"reference/ts_shape/events/quality/statistical_process_control/#ts_shape.events.quality.statistical_process_control.StatisticalProcessControlRuleBased.rule_7","title":"rule_7","text":"<pre><code>rule_7(df: DataFrame, limits: DataFrame) -&gt; DataFrame\n</code></pre> <p>Rule 7: Fifteen consecutive points within 1\u03c3 of the centerline.</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: Filtered DataFrame with rule violations.</p> </li> </ul> Source code in <code>src/ts_shape/events/quality/statistical_process_control.py</code> <pre><code>def rule_7(self, df: pd.DataFrame, limits: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"\n    Rule 7: Fifteen consecutive points within 1\u03c3 of the centerline.\n\n    Returns:\n        pd.DataFrame: Filtered DataFrame with rule violations.\n    \"\"\"\n    df['rule_7'] = df[self.value_column].apply(\n        lambda x: 1 if (x &lt; limits['1sigma_upper'].values[0] and x &gt; limits['1sigma_lower'].values[0]) else 0\n    )\n    df['rule_7'] = df['rule_7'].rolling(window=15).sum() == 15\n    return df[df['rule_7']]\n</code></pre>"},{"location":"reference/ts_shape/events/quality/statistical_process_control/#ts_shape.events.quality.statistical_process_control.StatisticalProcessControlRuleBased.rule_8","title":"rule_8","text":"<pre><code>rule_8(df: DataFrame, limits: DataFrame) -&gt; DataFrame\n</code></pre> <p>Rule 8: Eight consecutive points on both sides of the mean within 1\u03c3.</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: Filtered DataFrame with rule violations.</p> </li> </ul> Source code in <code>src/ts_shape/events/quality/statistical_process_control.py</code> <pre><code>def rule_8(self, df: pd.DataFrame, limits: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"\n    Rule 8: Eight consecutive points on both sides of the mean within 1\u03c3.\n\n    Returns:\n        pd.DataFrame: Filtered DataFrame with rule violations.\n    \"\"\"\n    df['rule_8'] = df[self.value_column].apply(\n        lambda x: 1 if (x &lt; limits['1sigma_upper'].values[0] and x &gt; limits['1sigma_lower'].values[0]) else 0\n    )\n    df['rule_8'] = df['rule_8'].rolling(window=8).sum() == 8\n    return df[df['rule_8']]\n</code></pre>"},{"location":"reference/ts_shape/events/quality/tolerance_deviation/","title":"tolerance_deviation","text":""},{"location":"reference/ts_shape/events/quality/tolerance_deviation/#ts_shape.events.quality.tolerance_deviation","title":"tolerance_deviation","text":"<p>Classes:</p> <ul> <li> <code>ToleranceDeviationEvents</code>           \u2013            <p>Inherits from Base and processes DataFrame data for specific events, comparing tolerance and actual values.</p> </li> </ul>"},{"location":"reference/ts_shape/events/quality/tolerance_deviation/#ts_shape.events.quality.tolerance_deviation.ToleranceDeviationEvents","title":"ToleranceDeviationEvents","text":"<pre><code>ToleranceDeviationEvents(dataframe: DataFrame, tolerance_column: str, actual_column: str, tolerance_uuid: str, actual_uuid: str, event_uuid: str, compare_func: Callable[[Series, Series], Series] = ge, time_threshold: str = '5min')\n</code></pre> <p>               Bases: <code>Base</code></p> <p>Inherits from Base and processes DataFrame data for specific events, comparing tolerance and actual values.</p> <p>Methods:</p> <ul> <li> <code>get_dataframe</code>             \u2013              <p>Returns the processed DataFrame.</p> </li> <li> <code>process_and_group_data_with_events</code>             \u2013              <p>Processes DataFrame to apply tolerance checks, group events by time, and generate an events DataFrame.</p> </li> </ul> Source code in <code>src/ts_shape/events/quality/tolerance_deviation.py</code> <pre><code>def __init__(self, dataframe: pd.DataFrame, tolerance_column: str, actual_column: str, \n             tolerance_uuid: str, actual_uuid: str, event_uuid: str, \n             compare_func: Callable[[pd.Series, pd.Series], pd.Series] = operator.ge, \n             time_threshold: str = '5min') -&gt; None:\n    \"\"\"\n    Initializes the ToleranceDeviationEvents with specific event attributes.\n    Inherits the sorted dataframe from the Base class.\n    \"\"\"\n    super().__init__(dataframe)  # Inherit and initialize Base class\n\n    self.tolerance_column: str = tolerance_column\n    self.actual_column: str = actual_column\n    self.tolerance_uuid: str = tolerance_uuid\n    self.actual_uuid: str = actual_uuid\n    self.event_uuid: str = event_uuid\n    self.compare_func: Callable[[pd.Series, pd.Series], pd.Series] = compare_func\n    self.time_threshold: str = time_threshold\n</code></pre>"},{"location":"reference/ts_shape/events/quality/tolerance_deviation/#ts_shape.events.quality.tolerance_deviation.ToleranceDeviationEvents.get_dataframe","title":"get_dataframe","text":"<pre><code>get_dataframe() -&gt; DataFrame\n</code></pre> <p>Returns the processed DataFrame.</p> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def get_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"Returns the processed DataFrame.\"\"\"\n    return self.dataframe\n</code></pre>"},{"location":"reference/ts_shape/events/quality/tolerance_deviation/#ts_shape.events.quality.tolerance_deviation.ToleranceDeviationEvents.process_and_group_data_with_events","title":"process_and_group_data_with_events","text":"<pre><code>process_and_group_data_with_events() -&gt; DataFrame\n</code></pre> <p>Processes DataFrame to apply tolerance checks, group events by time, and generate an events DataFrame.</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: A DataFrame of processed and grouped event data.</p> </li> </ul> Source code in <code>src/ts_shape/events/quality/tolerance_deviation.py</code> <pre><code>def process_and_group_data_with_events(self) -&gt; pd.DataFrame:\n    \"\"\"\n    Processes DataFrame to apply tolerance checks, group events by time, and generate an events DataFrame.\n\n    Returns:\n        pd.DataFrame: A DataFrame of processed and grouped event data.\n    \"\"\"\n    df = self.dataframe  # Inherited from Base class\n\n    # Convert 'systime' to datetime and sort the DataFrame by 'systime' in descending order\n    df['systime'] = pd.to_datetime(df['systime'])\n    df = df.sort_values(by='systime', ascending=False)\n\n    # Create a column for lagged tolerance values\n    df['tolerance_value'] = df.apply(\n        lambda row: row[self.tolerance_column] if (row['uuid'] == self.tolerance_uuid and row['is_delta']) else pd.NA, axis=1\n    )\n\n    # Forward fill the tolerance values to propagate the last observed tolerance value\n    df['tolerance_value'] = df['tolerance_value'].ffill()\n\n    # Remove tolerance setting rows from the dataset\n    df = df[df['uuid'] != self.tolerance_uuid]\n\n    # Ensure there are no NA values in the tolerance_value column before comparison\n    df = df.dropna(subset=['tolerance_value'])\n\n    # Apply comparison function to compare actual values with tolerance values\n    df = df[self.compare_func(df[self.actual_column], df['tolerance_value'])]\n    df['value_bool'] = True  # Assign True in the value_bool column for kept rows\n\n    # Grouping events that are close to each other in terms of time\n    df['group_id'] = (df['systime'].diff().abs() &gt; pd.to_timedelta(self.time_threshold)).cumsum()\n\n    # Filter for specific UUID and prepare events DataFrame\n    filtered_df = df[df['uuid'] == self.actual_uuid]\n    events_data = []\n\n    for group_id in filtered_df['group_id'].unique():\n        group_data = filtered_df[filtered_df['group_id'] == group_id]\n        if group_data.shape[0] &gt; 1:  # Ensure there's more than one row to work with\n            first_row = group_data.nsmallest(1, 'systime')\n            last_row = group_data.nlargest(1, 'systime')\n            combined_rows = pd.concat([first_row, last_row])\n            events_data.append(combined_rows)\n\n    # Convert list of DataFrame slices to a single DataFrame\n    if events_data:\n        events_df = pd.concat(events_data)\n        events_df['uuid'] = self.event_uuid\n    else:\n        events_df = pd.DataFrame(columns=filtered_df.columns)  # Create empty DataFrame if no data\n\n    events_df = events_df.drop(['tolerance_value', 'group_id'], axis=1)\n    events_df[self.actual_column] = np.nan\n    events_df['is_delta'] = True\n\n    return events_df\n</code></pre>"},{"location":"reference/ts_shape/features/__init__/","title":"init","text":""},{"location":"reference/ts_shape/features/__init__/#ts_shape.features","title":"features","text":"<p>Modules:</p> <ul> <li> <code>cycles</code>           \u2013            </li> <li> <code>stats</code>           \u2013            </li> <li> <code>time_stats</code>           \u2013            </li> </ul>"},{"location":"reference/ts_shape/features/cycles/__init__/","title":"init","text":""},{"location":"reference/ts_shape/features/cycles/__init__/#ts_shape.features.cycles","title":"cycles","text":"<p>Modules:</p> <ul> <li> <code>cycle_processor</code>           \u2013            </li> <li> <code>cycles_extractor</code>           \u2013            </li> </ul>"},{"location":"reference/ts_shape/features/cycles/cycle_processor/","title":"cycle_processor","text":""},{"location":"reference/ts_shape/features/cycles/cycle_processor/#ts_shape.features.cycles.cycle_processor","title":"cycle_processor","text":"<p>Classes:</p> <ul> <li> <code>CycleDataProcessor</code>           \u2013            <p>A class to process cycle-based data and values. It allows for splitting, merging, and grouping DataFrames </p> </li> </ul>"},{"location":"reference/ts_shape/features/cycles/cycle_processor/#ts_shape.features.cycles.cycle_processor.CycleDataProcessor","title":"CycleDataProcessor","text":"<pre><code>CycleDataProcessor(cycles_df: DataFrame, values_df: DataFrame, cycle_uuid_col: str = 'cycle_uuid', systime_col: str = 'systime')\n</code></pre> <p>               Bases: <code>Base</code></p> <p>A class to process cycle-based data and values. It allows for splitting, merging, and grouping DataFrames  based on cycles, as well as handling grouping and transformations by cycle UUIDs.</p> <p>Parameters:</p> <p>Methods:</p> <ul> <li> <code>get_dataframe</code>             \u2013              <p>Returns the processed DataFrame.</p> </li> <li> <code>group_by_cycle_uuid</code>             \u2013              <p>Group the DataFrame by the cycle_uuid column, resulting in a list of DataFrames, each containing data for one cycle.</p> </li> <li> <code>merge_dataframes_by_cycle</code>             \u2013              <p>Merges the values DataFrame with the cycles DataFrame based on the cycle time intervals. </p> </li> <li> <code>split_by_cycle</code>             \u2013              <p>Splits the values DataFrame by cycles defined in the cycles DataFrame. </p> </li> <li> <code>split_dataframes_by_group</code>             \u2013              <p>Splits a list of DataFrames by groups based on a specified column. </p> </li> </ul> Source code in <code>src/ts_shape/features/cycles/cycle_processor.py</code> <pre><code>def __init__(self, cycles_df: pd.DataFrame, values_df: pd.DataFrame, cycle_uuid_col: str = \"cycle_uuid\", systime_col: str = \"systime\"):\n    \"\"\"\n    Initializes the CycleDataProcessor with cycles and values DataFrames.\n\n    Args:\n        cycles_df: DataFrame containing columns 'cycle_start', 'cycle_end', and 'cycle_uuid'.\n        values_df: DataFrame containing the values and timestamps in the 'systime' column.\n        cycle_uuid_col: Name of the column representing cycle UUIDs.\n        systime_col: Name of the column representing the timestamps for the values.\n    \"\"\"\n    super().__init__(values_df)  # Call the parent constructor\n    self.values_df = values_df.copy()  # Initialize self.values_df explicitly\n    self.cycles_df = cycles_df.copy()\n    self.cycle_uuid_col = cycle_uuid_col\n    self.systime_col = systime_col\n\n    # Ensure proper datetime format\n    self.cycles_df['cycle_start'] = pd.to_datetime(self.cycles_df['cycle_start'])\n    self.cycles_df['cycle_end'] = pd.to_datetime(self.cycles_df['cycle_end'])\n    self.values_df[systime_col] = pd.to_datetime(self.values_df[systime_col])\n\n    logging.info(\"CycleDataProcessor initialized with cycles and values DataFrames.\")\n</code></pre>"},{"location":"reference/ts_shape/features/cycles/cycle_processor/#ts_shape.features.cycles.cycle_processor.CycleDataProcessor(cycles_df)","title":"<code>cycles_df</code>","text":"(<code>DataFrame</code>)           \u2013            <p>DataFrame containing columns 'cycle_start', 'cycle_end', and 'cycle_uuid'.</p>"},{"location":"reference/ts_shape/features/cycles/cycle_processor/#ts_shape.features.cycles.cycle_processor.CycleDataProcessor(values_df)","title":"<code>values_df</code>","text":"(<code>DataFrame</code>)           \u2013            <p>DataFrame containing the values and timestamps in the 'systime' column.</p>"},{"location":"reference/ts_shape/features/cycles/cycle_processor/#ts_shape.features.cycles.cycle_processor.CycleDataProcessor(cycle_uuid_col)","title":"<code>cycle_uuid_col</code>","text":"(<code>str</code>, default:                   <code>'cycle_uuid'</code> )           \u2013            <p>Name of the column representing cycle UUIDs.</p>"},{"location":"reference/ts_shape/features/cycles/cycle_processor/#ts_shape.features.cycles.cycle_processor.CycleDataProcessor(systime_col)","title":"<code>systime_col</code>","text":"(<code>str</code>, default:                   <code>'systime'</code> )           \u2013            <p>Name of the column representing the timestamps for the values.</p>"},{"location":"reference/ts_shape/features/cycles/cycle_processor/#ts_shape.features.cycles.cycle_processor.CycleDataProcessor.get_dataframe","title":"get_dataframe","text":"<pre><code>get_dataframe() -&gt; DataFrame\n</code></pre> <p>Returns the processed DataFrame.</p> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def get_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"Returns the processed DataFrame.\"\"\"\n    return self.dataframe\n</code></pre>"},{"location":"reference/ts_shape/features/cycles/cycle_processor/#ts_shape.features.cycles.cycle_processor.CycleDataProcessor.group_by_cycle_uuid","title":"group_by_cycle_uuid","text":"<pre><code>group_by_cycle_uuid(data: Optional[DataFrame] = None) -&gt; List[DataFrame]\n</code></pre> <p>Group the DataFrame by the cycle_uuid column, resulting in a list of DataFrames, each containing data for one cycle.</p> <p>Parameters:</p> Return <p>List of DataFrames, each containing data for a unique cycle_uuid.</p> Source code in <code>src/ts_shape/features/cycles/cycle_processor.py</code> <pre><code>def group_by_cycle_uuid(self, data: Optional[pd.DataFrame] = None) -&gt; List[pd.DataFrame]:\n    \"\"\"\n    Group the DataFrame by the cycle_uuid column, resulting in a list of DataFrames, each containing data for one cycle.\n\n    Args:\n        data: DataFrame containing the data to be grouped by cycle_uuid. If None, uses the internal values_df.\n\n    Return:\n        List of DataFrames, each containing data for a unique cycle_uuid.\n    \"\"\"\n    if data is None:\n        data = self.values_df\n\n    grouped_dataframes = [group for _, group in data.groupby(self.cycle_uuid_col)]\n    logging.info(f\"Grouped data into {len(grouped_dataframes)} cycle UUID groups.\")\n    return grouped_dataframes\n</code></pre>"},{"location":"reference/ts_shape/features/cycles/cycle_processor/#ts_shape.features.cycles.cycle_processor.CycleDataProcessor.group_by_cycle_uuid(data)","title":"<code>data</code>","text":"(<code>Optional[DataFrame]</code>, default:                   <code>None</code> )           \u2013            <p>DataFrame containing the data to be grouped by cycle_uuid. If None, uses the internal values_df.</p>"},{"location":"reference/ts_shape/features/cycles/cycle_processor/#ts_shape.features.cycles.cycle_processor.CycleDataProcessor.merge_dataframes_by_cycle","title":"merge_dataframes_by_cycle","text":"<pre><code>merge_dataframes_by_cycle() -&gt; DataFrame\n</code></pre> <p>Merges the values DataFrame with the cycles DataFrame based on the cycle time intervals.  Appends the 'cycle_uuid' to the values DataFrame.</p> Return <p>DataFrame with an added 'cycle_uuid' column.</p> Source code in <code>src/ts_shape/features/cycles/cycle_processor.py</code> <pre><code>def merge_dataframes_by_cycle(self) -&gt; pd.DataFrame:\n    \"\"\"\n    Merges the values DataFrame with the cycles DataFrame based on the cycle time intervals. \n    Appends the 'cycle_uuid' to the values DataFrame.\n\n    Return:\n        DataFrame with an added 'cycle_uuid' column.\n    \"\"\"\n    # Merge based on systime falling within cycle_start and cycle_end\n    self.values_df[self.cycle_uuid_col] = None\n\n    for _, row in self.cycles_df.iterrows():\n        mask = (self.values_df[self.systime_col] &gt;= row['cycle_start']) &amp; (self.values_df[self.systime_col] &lt;= row['cycle_end'])\n        self.values_df.loc[mask, self.cycle_uuid_col] = row[self.cycle_uuid_col]\n\n    merged_df = self.values_df.dropna(subset=[self.cycle_uuid_col])\n    logging.info(f\"Merged DataFrame contains {len(merged_df)} records.\")\n    return merged_df\n</code></pre>"},{"location":"reference/ts_shape/features/cycles/cycle_processor/#ts_shape.features.cycles.cycle_processor.CycleDataProcessor.split_by_cycle","title":"split_by_cycle","text":"<pre><code>split_by_cycle() -&gt; Dict[str, DataFrame]\n</code></pre> <p>Splits the values DataFrame by cycles defined in the cycles DataFrame.  Each cycle is defined by a start and end time, and the corresponding values are filtered accordingly.</p> Return <p>Dictionary where keys are cycle_uuids and values are DataFrames with the corresponding cycle data.</p> Source code in <code>src/ts_shape/features/cycles/cycle_processor.py</code> <pre><code>def split_by_cycle(self) -&gt; Dict[str, pd.DataFrame]:\n    \"\"\"\n    Splits the values DataFrame by cycles defined in the cycles DataFrame. \n    Each cycle is defined by a start and end time, and the corresponding values are filtered accordingly.\n\n    Return:\n        Dictionary where keys are cycle_uuids and values are DataFrames with the corresponding cycle data.\n    \"\"\"\n    result = {}\n    for _, row in self.cycles_df.iterrows():\n        mask = (self.values_df[self.systime_col] &gt;= row['cycle_start']) &amp; (self.values_df[self.systime_col] &lt;= row['cycle_end'])\n        result[row[self.cycle_uuid_col]] = self.values_df[mask].copy()\n\n    logging.info(f\"Split {len(result)} cycles.\")\n    return result\n</code></pre>"},{"location":"reference/ts_shape/features/cycles/cycle_processor/#ts_shape.features.cycles.cycle_processor.CycleDataProcessor.split_dataframes_by_group","title":"split_dataframes_by_group","text":"<pre><code>split_dataframes_by_group(dfs: List[DataFrame], column: str) -&gt; List[DataFrame]\n</code></pre> <p>Splits a list of DataFrames by groups based on a specified column.  This function performs a groupby operation on each DataFrame in the list and then flattens the result.</p> <p>Parameters:</p> Return <p>List of DataFrames, each corresponding to a group in the original DataFrames.</p> Source code in <code>src/ts_shape/features/cycles/cycle_processor.py</code> <pre><code>def split_dataframes_by_group(self, dfs: List[pd.DataFrame], column: str) -&gt; List[pd.DataFrame]:\n    \"\"\"\n    Splits a list of DataFrames by groups based on a specified column. \n    This function performs a groupby operation on each DataFrame in the list and then flattens the result.\n\n    Args:\n        dfs: List of DataFrames to be split.\n        column: Column name to group by.\n\n    Return:\n        List of DataFrames, each corresponding to a group in the original DataFrames.\n    \"\"\"\n    split_dfs = []\n    for df in dfs:\n        groups = df.groupby(column)\n        for _, group in groups:\n            split_dfs.append(group)\n\n    logging.info(f\"Split data into {len(split_dfs)} groups based on column '{column}'.\")\n    return split_dfs\n</code></pre>"},{"location":"reference/ts_shape/features/cycles/cycle_processor/#ts_shape.features.cycles.cycle_processor.CycleDataProcessor.split_dataframes_by_group(dfs)","title":"<code>dfs</code>","text":"(<code>List[DataFrame]</code>)           \u2013            <p>List of DataFrames to be split.</p>"},{"location":"reference/ts_shape/features/cycles/cycle_processor/#ts_shape.features.cycles.cycle_processor.CycleDataProcessor.split_dataframes_by_group(column)","title":"<code>column</code>","text":"(<code>str</code>)           \u2013            <p>Column name to group by.</p>"},{"location":"reference/ts_shape/features/cycles/cycles_extractor/","title":"cycles_extractor","text":""},{"location":"reference/ts_shape/features/cycles/cycles_extractor/#ts_shape.features.cycles.cycles_extractor","title":"cycles_extractor","text":"<p>Classes:</p> <ul> <li> <code>CycleExtractor</code>           \u2013            <p>Class for processing cycles based on different criteria.</p> </li> </ul>"},{"location":"reference/ts_shape/features/cycles/cycles_extractor/#ts_shape.features.cycles.cycles_extractor.CycleExtractor","title":"CycleExtractor","text":"<pre><code>CycleExtractor(dataframe: DataFrame, start_uuid: str, end_uuid: Optional[str] = None)\n</code></pre> <p>               Bases: <code>Base</code></p> <p>Class for processing cycles based on different criteria.</p> <p>Methods:</p> <ul> <li> <code>get_dataframe</code>             \u2013              <p>Returns the processed DataFrame.</p> </li> <li> <code>process_persistent_cycle</code>             \u2013              <p>Processes cycles where the value of the variable stays true during the cycle.</p> </li> <li> <code>process_separate_start_end_cycle</code>             \u2013              <p>Processes cycles where different variables indicate cycle start and end.</p> </li> <li> <code>process_state_change_cycle</code>             \u2013              <p>Processes cycles where the start of a new cycle is the end of the previous cycle.</p> </li> <li> <code>process_step_sequence</code>             \u2013              <p>Processes cycles based on a step sequence, where specific integer values denote cycle start and end.</p> </li> <li> <code>process_trigger_cycle</code>             \u2013              <p>Processes cycles where the value of the variable goes from true to false during the cycle.</p> </li> <li> <code>process_value_change_cycle</code>             \u2013              <p>Processes cycles where a change in the value indicates a new cycle.</p> </li> </ul> Source code in <code>src/ts_shape/features/cycles/cycles_extractor.py</code> <pre><code>def __init__(self, dataframe: pd.DataFrame, start_uuid: str, end_uuid: Optional[str] = None):\n    \"\"\"Initializes the class with the data and the UUIDs for cycle start and end.\"\"\"\n    super().__init__(dataframe)\n\n    # Validate input types\n    if not isinstance(dataframe, pd.DataFrame):\n        raise ValueError(\"dataframe must be a pandas DataFrame\")\n    if not isinstance(start_uuid, str):\n        raise ValueError(\"start_uuid must be a string\")\n\n    self.df = dataframe  # Use the provided DataFrame directly\n    self.start_uuid = start_uuid\n    self.end_uuid = end_uuid if end_uuid else start_uuid\n    logging.info(f\"CycleExtractor initialized with start_uuid: {self.start_uuid} and end_uuid: {self.end_uuid}\")\n</code></pre>"},{"location":"reference/ts_shape/features/cycles/cycles_extractor/#ts_shape.features.cycles.cycles_extractor.CycleExtractor.get_dataframe","title":"get_dataframe","text":"<pre><code>get_dataframe() -&gt; DataFrame\n</code></pre> <p>Returns the processed DataFrame.</p> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def get_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"Returns the processed DataFrame.\"\"\"\n    return self.dataframe\n</code></pre>"},{"location":"reference/ts_shape/features/cycles/cycles_extractor/#ts_shape.features.cycles.cycles_extractor.CycleExtractor.process_persistent_cycle","title":"process_persistent_cycle","text":"<pre><code>process_persistent_cycle() -&gt; DataFrame\n</code></pre> <p>Processes cycles where the value of the variable stays true during the cycle.</p> Source code in <code>src/ts_shape/features/cycles/cycles_extractor.py</code> <pre><code>def process_persistent_cycle(self) -&gt; pd.DataFrame:\n    \"\"\"Processes cycles where the value of the variable stays true during the cycle.\"\"\"\n    # Assuming dataframe is pre-filtered\n    cycle_starts = self.df[self.df['value_bool'] == True]\n    cycle_ends = self.df[self.df['value_bool'] == False]\n\n    return self._generate_cycle_dataframe(cycle_starts, cycle_ends)\n</code></pre>"},{"location":"reference/ts_shape/features/cycles/cycles_extractor/#ts_shape.features.cycles.cycles_extractor.CycleExtractor.process_separate_start_end_cycle","title":"process_separate_start_end_cycle","text":"<pre><code>process_separate_start_end_cycle() -&gt; DataFrame\n</code></pre> <p>Processes cycles where different variables indicate cycle start and end.</p> Source code in <code>src/ts_shape/features/cycles/cycles_extractor.py</code> <pre><code>def process_separate_start_end_cycle(self) -&gt; pd.DataFrame:\n    \"\"\"Processes cycles where different variables indicate cycle start and end.\"\"\"\n    # Assuming dataframe is pre-filtered for both start_uuid and end_uuid\n    cycle_starts = self.df[self.df['value_bool'] == True]\n    cycle_ends = self.df[self.df['value_bool'] == True]\n\n    return self._generate_cycle_dataframe(cycle_starts, cycle_ends)\n</code></pre>"},{"location":"reference/ts_shape/features/cycles/cycles_extractor/#ts_shape.features.cycles.cycles_extractor.CycleExtractor.process_state_change_cycle","title":"process_state_change_cycle","text":"<pre><code>process_state_change_cycle() -&gt; DataFrame\n</code></pre> <p>Processes cycles where the start of a new cycle is the end of the previous cycle.</p> Source code in <code>src/ts_shape/features/cycles/cycles_extractor.py</code> <pre><code>def process_state_change_cycle(self) -&gt; pd.DataFrame:\n    \"\"\"Processes cycles where the start of a new cycle is the end of the previous cycle.\"\"\"\n    # Assuming dataframe is pre-filtered\n    cycle_starts = self.df.copy()\n    cycle_ends = self.df.shift(-1)\n\n    return self._generate_cycle_dataframe(cycle_starts, cycle_ends)\n</code></pre>"},{"location":"reference/ts_shape/features/cycles/cycles_extractor/#ts_shape.features.cycles.cycles_extractor.CycleExtractor.process_step_sequence","title":"process_step_sequence","text":"<pre><code>process_step_sequence(start_step: int, end_step: int) -&gt; DataFrame\n</code></pre> <p>Processes cycles based on a step sequence, where specific integer values denote cycle start and end.</p> Source code in <code>src/ts_shape/features/cycles/cycles_extractor.py</code> <pre><code>def process_step_sequence(self, start_step: int, end_step: int) -&gt; pd.DataFrame:\n    \"\"\"Processes cycles based on a step sequence, where specific integer values denote cycle start and end.\"\"\"\n    # Assuming dataframe is pre-filtered\n    cycle_starts = self.df[self.df['value_integer'] == start_step]\n    cycle_ends = self.df[self.df['value_integer'] == end_step]\n\n    return self._generate_cycle_dataframe(cycle_starts, cycle_ends)\n</code></pre>"},{"location":"reference/ts_shape/features/cycles/cycles_extractor/#ts_shape.features.cycles.cycles_extractor.CycleExtractor.process_trigger_cycle","title":"process_trigger_cycle","text":"<pre><code>process_trigger_cycle() -&gt; DataFrame\n</code></pre> <p>Processes cycles where the value of the variable goes from true to false during the cycle.</p> Source code in <code>src/ts_shape/features/cycles/cycles_extractor.py</code> <pre><code>def process_trigger_cycle(self) -&gt; pd.DataFrame:\n    \"\"\"Processes cycles where the value of the variable goes from true to false during the cycle.\"\"\"\n    # Assuming dataframe is pre-filtered\n    cycle_starts = self.df[self.df['value_bool'] == True]\n    cycle_ends = self.df[self.df['value_bool'] == False].shift(-1)\n\n    return self._generate_cycle_dataframe(cycle_starts, cycle_ends)\n</code></pre>"},{"location":"reference/ts_shape/features/cycles/cycles_extractor/#ts_shape.features.cycles.cycles_extractor.CycleExtractor.process_value_change_cycle","title":"process_value_change_cycle","text":"<pre><code>process_value_change_cycle() -&gt; DataFrame\n</code></pre> <p>Processes cycles where a change in the value indicates a new cycle.</p> Source code in <code>src/ts_shape/features/cycles/cycles_extractor.py</code> <pre><code>def process_value_change_cycle(self) -&gt; pd.DataFrame:\n    \"\"\"Processes cycles where a change in the value indicates a new cycle.\"\"\"\n    # Assuming dataframe is pre-filtered\n\n    # Fill NaN or None values with appropriate defaults for diff() to work\n    self.df['value_double'] = self.df['value_double'].fillna(0)  # Assuming numeric column\n    self.df['value_bool'] = self.df['value_bool'].fillna(False)  # Assuming boolean column\n    self.df['value_string'] = self.df['value_string'].fillna('')  # Assuming string column\n    self.df['value_integer'] = self.df['value_integer'].fillna(0)  # Assuming integer column\n\n    # Detect changes across the relevant columns using diff()\n    self.df['value_change'] = (\n        (self.df['value_double'].diff().ne(0)) |\n        (self.df['value_bool'].diff().ne(0)) |\n        (self.df['value_string'].shift().ne(self.df['value_string'])) |\n        (self.df['value_integer'].diff().ne(0))\n    )\n\n    # Define cycle starts and ends based on changes\n    cycle_starts = self.df[self.df['value_change'] == True]\n    cycle_ends = self.df[self.df['value_change'] == True].shift(-1)\n\n    return self._generate_cycle_dataframe(cycle_starts, cycle_ends)\n</code></pre>"},{"location":"reference/ts_shape/features/stats/__init__/","title":"init","text":""},{"location":"reference/ts_shape/features/stats/__init__/#ts_shape.features.stats","title":"stats","text":"<p>Modules:</p> <ul> <li> <code>boolean_stats</code>           \u2013            </li> <li> <code>feature_table</code>           \u2013            </li> <li> <code>numeric_stats</code>           \u2013            </li> <li> <code>string_stats</code>           \u2013            </li> <li> <code>timestamp_stats</code>           \u2013            </li> </ul>"},{"location":"reference/ts_shape/features/stats/boolean_stats/","title":"boolean_stats","text":""},{"location":"reference/ts_shape/features/stats/boolean_stats/#ts_shape.features.stats.boolean_stats","title":"boolean_stats","text":"<p>Classes:</p> <ul> <li> <code>BooleanStatistics</code>           \u2013            <p>Provides class methods to calculate statistics on a boolean column in a pandas DataFrame.</p> </li> </ul>"},{"location":"reference/ts_shape/features/stats/boolean_stats/#ts_shape.features.stats.boolean_stats.BooleanStatistics","title":"BooleanStatistics","text":"<pre><code>BooleanStatistics(dataframe: DataFrame, column_name: str = 'systime')\n</code></pre> <p>               Bases: <code>Base</code></p> <p>Provides class methods to calculate statistics on a boolean column in a pandas DataFrame.</p> <p>Parameters:</p> <p>Methods:</p> <ul> <li> <code>count_false</code>             \u2013              <p>Returns the count of False values in the boolean column.</p> </li> <li> <code>count_not_null</code>             \u2013              <p>Returns the count of non-null (True or False) values in the boolean column.</p> </li> <li> <code>count_null</code>             \u2013              <p>Returns the count of null (NaN) values in the boolean column.</p> </li> <li> <code>count_true</code>             \u2013              <p>Returns the count of True values in the boolean column.</p> </li> <li> <code>false_percentage</code>             \u2013              <p>Returns the percentage of False values in the boolean column.</p> </li> <li> <code>get_dataframe</code>             \u2013              <p>Returns the processed DataFrame.</p> </li> <li> <code>is_balanced</code>             \u2013              <p>Indicates if the distribution is balanced (50% True and False) in the specified boolean column.</p> </li> <li> <code>mode</code>             \u2013              <p>Returns the mode (most common value) of the specified boolean column.</p> </li> <li> <code>summary_as_dataframe</code>             \u2013              <p>Returns a summary of boolean statistics for the specified column as a DataFrame.</p> </li> <li> <code>summary_as_dict</code>             \u2013              <p>Returns a summary of boolean statistics for the specified column as a dictionary.</p> </li> <li> <code>true_percentage</code>             \u2013              <p>Returns the percentage of True values in the boolean column.</p> </li> </ul> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def __init__(self, dataframe: pd.DataFrame, column_name: str = 'systime') -&gt; pd.DataFrame:\n    \"\"\"\n    Initializes the Base with a DataFrame, detects time columns, converts them to datetime,\n    and sorts the DataFrame by the specified column (or the detected time column if applicable).\n\n    Args:\n        dataframe (pd.DataFrame): The DataFrame to be processed.\n        column_name (str): The column to sort by. Default is 'systime'. If the column is not found or is not a time column, the class will attempt to detect other time columns.\n    \"\"\"\n    self.dataframe = dataframe.copy()\n\n    # Attempt to convert the specified column_name to datetime if it exists\n    if column_name in self.dataframe.columns:\n        self.dataframe[column_name] = pd.to_datetime(self.dataframe[column_name], errors='coerce')\n    else:\n        # If the column_name is not in the DataFrame, fallback to automatic time detection\n        time_columns = [col for col in self.dataframe.columns if 'time' in col.lower() or 'date' in col.lower()]\n\n        # Convert all detected time columns to datetime, if any\n        for col in time_columns:\n            self.dataframe[col] = pd.to_datetime(self.dataframe[col], errors='coerce')\n\n        # If any time columns are detected, sort by the first one; otherwise, do nothing\n        if time_columns:\n            column_name = time_columns[0]\n\n    # Sort by the datetime column (either specified or detected)\n    if column_name in self.dataframe.columns:\n        self.dataframe = self.dataframe.sort_values(by=column_name)\n</code></pre>"},{"location":"reference/ts_shape/features/stats/boolean_stats/#ts_shape.features.stats.boolean_stats.BooleanStatistics(dataframe)","title":"<code>dataframe</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The DataFrame to be processed.</p>"},{"location":"reference/ts_shape/features/stats/boolean_stats/#ts_shape.features.stats.boolean_stats.BooleanStatistics(column_name)","title":"<code>column_name</code>","text":"(<code>str</code>, default:                   <code>'systime'</code> )           \u2013            <p>The column to sort by. Default is 'systime'. If the column is not found or is not a time column, the class will attempt to detect other time columns.</p>"},{"location":"reference/ts_shape/features/stats/boolean_stats/#ts_shape.features.stats.boolean_stats.BooleanStatistics.count_false","title":"count_false  <code>classmethod</code>","text":"<pre><code>count_false(dataframe: DataFrame, column_name: str = 'value_bool') -&gt; int\n</code></pre> <p>Returns the count of False values in the boolean column.</p> Source code in <code>src/ts_shape/features/stats/boolean_stats.py</code> <pre><code>@classmethod\ndef count_false(cls, dataframe: pd.DataFrame, column_name: str = 'value_bool') -&gt; int:\n    \"\"\"Returns the count of False values in the boolean column.\"\"\"\n    return (dataframe[column_name] == False).sum()\n</code></pre>"},{"location":"reference/ts_shape/features/stats/boolean_stats/#ts_shape.features.stats.boolean_stats.BooleanStatistics.count_not_null","title":"count_not_null  <code>classmethod</code>","text":"<pre><code>count_not_null(dataframe: DataFrame, column_name: str = 'value_bool') -&gt; int\n</code></pre> <p>Returns the count of non-null (True or False) values in the boolean column.</p> Source code in <code>src/ts_shape/features/stats/boolean_stats.py</code> <pre><code>@classmethod\ndef count_not_null(cls, dataframe: pd.DataFrame, column_name: str = 'value_bool') -&gt; int:\n    \"\"\"Returns the count of non-null (True or False) values in the boolean column.\"\"\"\n    return dataframe[column_name].notna().sum()\n</code></pre>"},{"location":"reference/ts_shape/features/stats/boolean_stats/#ts_shape.features.stats.boolean_stats.BooleanStatistics.count_null","title":"count_null  <code>classmethod</code>","text":"<pre><code>count_null(dataframe: DataFrame, column_name: str = 'value_bool') -&gt; int\n</code></pre> <p>Returns the count of null (NaN) values in the boolean column.</p> Source code in <code>src/ts_shape/features/stats/boolean_stats.py</code> <pre><code>@classmethod\ndef count_null(cls, dataframe: pd.DataFrame, column_name: str = 'value_bool') -&gt; int:\n    \"\"\"Returns the count of null (NaN) values in the boolean column.\"\"\"\n    return dataframe[column_name].isna().sum()\n</code></pre>"},{"location":"reference/ts_shape/features/stats/boolean_stats/#ts_shape.features.stats.boolean_stats.BooleanStatistics.count_true","title":"count_true  <code>classmethod</code>","text":"<pre><code>count_true(dataframe: DataFrame, column_name: str = 'value_bool') -&gt; int\n</code></pre> <p>Returns the count of True values in the boolean column.</p> Source code in <code>src/ts_shape/features/stats/boolean_stats.py</code> <pre><code>@classmethod\ndef count_true(cls, dataframe: pd.DataFrame, column_name: str = 'value_bool') -&gt; int:\n    \"\"\"Returns the count of True values in the boolean column.\"\"\"\n    return dataframe[column_name].sum()\n</code></pre>"},{"location":"reference/ts_shape/features/stats/boolean_stats/#ts_shape.features.stats.boolean_stats.BooleanStatistics.false_percentage","title":"false_percentage  <code>classmethod</code>","text":"<pre><code>false_percentage(dataframe: DataFrame, column_name: str = 'value_bool') -&gt; float\n</code></pre> <p>Returns the percentage of False values in the boolean column.</p> Source code in <code>src/ts_shape/features/stats/boolean_stats.py</code> <pre><code>@classmethod\ndef false_percentage(cls, dataframe: pd.DataFrame, column_name: str = 'value_bool') -&gt; float:\n    \"\"\"Returns the percentage of False values in the boolean column.\"\"\"\n    false_count = cls.count_false(dataframe, column_name)\n    total_count = cls.count_not_null(dataframe, column_name)\n    return (false_count / total_count) * 100 if total_count &gt; 0 else 0.0\n</code></pre>"},{"location":"reference/ts_shape/features/stats/boolean_stats/#ts_shape.features.stats.boolean_stats.BooleanStatistics.get_dataframe","title":"get_dataframe","text":"<pre><code>get_dataframe() -&gt; DataFrame\n</code></pre> <p>Returns the processed DataFrame.</p> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def get_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"Returns the processed DataFrame.\"\"\"\n    return self.dataframe\n</code></pre>"},{"location":"reference/ts_shape/features/stats/boolean_stats/#ts_shape.features.stats.boolean_stats.BooleanStatistics.is_balanced","title":"is_balanced  <code>classmethod</code>","text":"<pre><code>is_balanced(dataframe: DataFrame, column_name: str) -&gt; bool\n</code></pre> <p>Indicates if the distribution is balanced (50% True and False) in the specified boolean column.</p> Source code in <code>src/ts_shape/features/stats/boolean_stats.py</code> <pre><code>@classmethod\ndef is_balanced(cls, dataframe: pd.DataFrame, column_name: str) -&gt; bool:\n    \"\"\"Indicates if the distribution is balanced (50% True and False) in the specified boolean column.\"\"\"\n    true_percentage = dataframe[column_name].mean()\n    return true_percentage == 0.5\n</code></pre>"},{"location":"reference/ts_shape/features/stats/boolean_stats/#ts_shape.features.stats.boolean_stats.BooleanStatistics.mode","title":"mode  <code>classmethod</code>","text":"<pre><code>mode(dataframe: DataFrame, column_name: str) -&gt; bool\n</code></pre> <p>Returns the mode (most common value) of the specified boolean column.</p> Source code in <code>src/ts_shape/features/stats/boolean_stats.py</code> <pre><code>@classmethod\ndef mode(cls, dataframe: pd.DataFrame, column_name: str) -&gt; bool:\n    \"\"\"Returns the mode (most common value) of the specified boolean column.\"\"\"\n    return dataframe[column_name].mode()[0]\n</code></pre>"},{"location":"reference/ts_shape/features/stats/boolean_stats/#ts_shape.features.stats.boolean_stats.BooleanStatistics.summary_as_dataframe","title":"summary_as_dataframe  <code>classmethod</code>","text":"<pre><code>summary_as_dataframe(dataframe: DataFrame, column_name: str) -&gt; DataFrame\n</code></pre> <p>Returns a summary of boolean statistics for the specified column as a DataFrame.</p> Source code in <code>src/ts_shape/features/stats/boolean_stats.py</code> <pre><code>@classmethod\ndef summary_as_dataframe(cls, dataframe: pd.DataFrame, column_name: str) -&gt; pd.DataFrame:\n    \"\"\"Returns a summary of boolean statistics for the specified column as a DataFrame.\"\"\"\n    summary_data = cls.summary_as_dict(dataframe, column_name)\n    return pd.DataFrame([summary_data])\n</code></pre>"},{"location":"reference/ts_shape/features/stats/boolean_stats/#ts_shape.features.stats.boolean_stats.BooleanStatistics.summary_as_dict","title":"summary_as_dict  <code>classmethod</code>","text":"<pre><code>summary_as_dict(dataframe: DataFrame, column_name: str) -&gt; Dict[str, Union[int, float, bool]]\n</code></pre> <p>Returns a summary of boolean statistics for the specified column as a dictionary.</p> Source code in <code>src/ts_shape/features/stats/boolean_stats.py</code> <pre><code>@classmethod\ndef summary_as_dict(cls, dataframe: pd.DataFrame, column_name: str) -&gt; Dict[str, Union[int, float, bool]]:\n    \"\"\"Returns a summary of boolean statistics for the specified column as a dictionary.\"\"\"\n    return {\n        'true_count': cls.count_true(dataframe, column_name),\n        'false_count': cls.count_false(dataframe, column_name),\n        'true_percentage': cls.true_percentage(dataframe, column_name),\n        'false_percentage': cls.false_percentage(dataframe, column_name),\n        'mode': cls.mode(dataframe, column_name),\n        'is_balanced': cls.is_balanced(dataframe, column_name)\n    }\n</code></pre>"},{"location":"reference/ts_shape/features/stats/boolean_stats/#ts_shape.features.stats.boolean_stats.BooleanStatistics.true_percentage","title":"true_percentage  <code>classmethod</code>","text":"<pre><code>true_percentage(dataframe: DataFrame, column_name: str = 'value_bool') -&gt; float\n</code></pre> <p>Returns the percentage of True values in the boolean column.</p> Source code in <code>src/ts_shape/features/stats/boolean_stats.py</code> <pre><code>@classmethod\ndef true_percentage(cls, dataframe: pd.DataFrame, column_name: str = 'value_bool') -&gt; float:\n    \"\"\"Returns the percentage of True values in the boolean column.\"\"\"\n    true_count = cls.count_true(dataframe, column_name)\n    total_count = cls.count_not_null(dataframe, column_name)\n    return (true_count / total_count) * 100 if total_count &gt; 0 else 0.0\n</code></pre>"},{"location":"reference/ts_shape/features/stats/feature_table/","title":"feature_table","text":""},{"location":"reference/ts_shape/features/stats/feature_table/#ts_shape.features.stats.feature_table","title":"feature_table","text":"<p>Classes:</p> <ul> <li> <code>DescriptiveFeatures</code>           \u2013            <p>A class used to compute descriptive statistics for a DataFrame, grouped by UUID.</p> </li> </ul>"},{"location":"reference/ts_shape/features/stats/feature_table/#ts_shape.features.stats.feature_table.DescriptiveFeatures","title":"DescriptiveFeatures","text":"<pre><code>DescriptiveFeatures(dataframe: DataFrame)\n</code></pre> <p>A class used to compute descriptive statistics for a DataFrame, grouped by UUID.</p>"},{"location":"reference/ts_shape/features/stats/feature_table/#ts_shape.features.stats.feature_table.DescriptiveFeatures--attributes","title":"Attributes","text":"<p>data : pandas.DataFrame     DataFrame containing the data</p>"},{"location":"reference/ts_shape/features/stats/feature_table/#ts_shape.features.stats.feature_table.DescriptiveFeatures--methods","title":"Methods","text":"<p>compute():     Compute and return descriptive statistics for each UUID in the DataFrame.</p> <p>dataframe : pandas.DataFrame     DataFrame containing the data</p> <p>Methods:</p> <ul> <li> <code>compute</code>             \u2013              <p>Compute and return descriptive statistics for each UUID in the DataFrame.</p> </li> <li> <code>compute_per_group</code>             \u2013              <p>Compute and return statistics for each column in the DataFrame group.</p> </li> <li> <code>overall_stats</code>             \u2013              <p>Compute and return overall statistics for the DataFrame group.</p> </li> </ul> Source code in <code>src/ts_shape/features/stats/feature_table.py</code> <pre><code>def __init__(self, dataframe: pd.DataFrame):\n    \"\"\"\n    Parameters\n    ----------\n    dataframe : pandas.DataFrame\n        DataFrame containing the data\n    \"\"\"\n    self.data = dataframe\n</code></pre>"},{"location":"reference/ts_shape/features/stats/feature_table/#ts_shape.features.stats.feature_table.DescriptiveFeatures.compute","title":"compute","text":"<pre><code>compute(output_format: str = 'dict') -&gt; Union[DataFrame, Dict[str, Dict[str, Dict[str, Union[int, float, str, bool]]]]]\n</code></pre> <p>Compute and return descriptive statistics for each UUID in the DataFrame.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Union[DataFrame, Dict[str, Dict[str, Dict[str, Union[int, float, str, bool]]]]]</code>           \u2013            <p>Union[DataFrame, dict]: A DataFrame or a nested dictionary with the UUID as the key and specific statistics related to that UUID's data type.</p> </li> </ul> Source code in <code>src/ts_shape/features/stats/feature_table.py</code> <pre><code>def compute(self, output_format: str = 'dict') -&gt; Union[pd.DataFrame, Dict[str, Dict[str, Dict[str, Union[int, float, str, bool]]]]]:\n    \"\"\"Compute and return descriptive statistics for each UUID in the DataFrame.\n\n    Args:\n        output_format (str, optional): The desired output format ('dict' or 'dataframe'). Defaults to 'dict'.\n\n    Returns:\n        Union[DataFrame, dict]: A DataFrame or a nested dictionary with the UUID as the key and specific statistics related to that UUID's data type.\n    \"\"\"\n    if output_format == 'dataframe':\n        rows_list = []\n\n        # Iterate through each group of UUID\n        for uuid, group in self.data.groupby('uuid'):\n            stats_per_group = self.compute_per_group(group)\n\n            # Iterate through the nested stats and create flat columns\n            row_dict = {}\n            for section, stats in stats_per_group.items():\n                if isinstance(stats, dict):\n                    for key, value in stats.items():\n                        if isinstance(value, dict):\n                            for sub_key, sub_value in value.items():\n                                column_name = f'{uuid}::{section}::{key}::{sub_key}'\n                                row_dict[column_name] = sub_value\n                        else:\n                            column_name = f'{uuid}::{section}::{key}'\n                            row_dict[column_name] = value\n                else:\n                    column_name = f'{uuid}::{section}'\n                    row_dict[column_name] = stats\n\n            rows_list.append(row_dict)\n\n        return pd.DataFrame(rows_list)\n\n    elif output_format == 'dict':\n        return self.data.groupby('uuid').apply(self.compute_per_group).to_dict()\n\n    else:\n        raise ValueError(\"Invalid output format. Choose either 'dict' or 'dataframe'.\")\n</code></pre>"},{"location":"reference/ts_shape/features/stats/feature_table/#ts_shape.features.stats.feature_table.DescriptiveFeatures.compute(output_format)","title":"<code>output_format</code>","text":"(<code>str</code>, default:                   <code>'dict'</code> )           \u2013            <p>The desired output format ('dict' or 'dataframe'). Defaults to 'dict'.</p>"},{"location":"reference/ts_shape/features/stats/feature_table/#ts_shape.features.stats.feature_table.DescriptiveFeatures.compute_per_group","title":"compute_per_group","text":"<pre><code>compute_per_group(group: DataFrame) -&gt; Dict[str, Dict[str, Union[int, float, str, bool]]]\n</code></pre> <p>Compute and return statistics for each column in the DataFrame group.</p> <p>Returns:</p> <ul> <li> <code>dict</code> (              <code>Dict[str, Dict[str, Union[int, float, str, bool]]]</code> )          \u2013            <p>A dictionary with overall statistics, and string, numeric, and boolean statistics per column.</p> </li> </ul> Source code in <code>src/ts_shape/features/stats/feature_table.py</code> <pre><code>def compute_per_group(self, group: pd.DataFrame) -&gt; Dict[str, Dict[str, Union[int, float, str, bool]]]:\n    \"\"\"Compute and return statistics for each column in the DataFrame group.\n\n    Returns:\n        dict: A dictionary with overall statistics, and string, numeric, and boolean statistics per column.\n    \"\"\"\n    results = {\n        'overall': self.overall_stats(group)\n    }\n    for col in group.columns:\n        if col == 'uuid':\n            continue\n        elif is_bool_dtype(group[col]):\n            # Use BooleanStatistics for boolean columns\n            results[col] = {'boolean_stats': BooleanStatistics.summary_as_dict(group, col)}\n        elif is_numeric_dtype(group[col]):\n            # Use NumericStatistics for numeric columns\n            results[col] = {'numeric_stats': NumericStatistics.summary_as_dict(group, col)}\n        elif is_object_dtype(group[col]):\n            # Use StringStatistics for string columns\n            results[col] = {'string_stats': StringStatistics.summary_as_dict(group, col)}\n\n    return results\n</code></pre>"},{"location":"reference/ts_shape/features/stats/feature_table/#ts_shape.features.stats.feature_table.DescriptiveFeatures.overall_stats","title":"overall_stats","text":"<pre><code>overall_stats(group: DataFrame) -&gt; Dict[str, Union[int, float]]\n</code></pre> <p>Compute and return overall statistics for the DataFrame group.</p> <ul> <li>total_rows: Total number of rows in the group.</li> <li>total_time: Total time difference from max and min of 'systime' column.</li> <li>is_delta_sum: Sum of the 'is_delta' column.</li> <li>is_delta_avg: Mean of the 'is_delta' column.</li> <li>is_delta_std: Standard deviation of the 'is_delta' column.</li> </ul> <p>Returns:</p> <ul> <li> <code>dict</code> (              <code>Dict[str, Union[int, float]]</code> )          \u2013            <p>A dictionary with overall statistics.</p> </li> </ul> Source code in <code>src/ts_shape/features/stats/feature_table.py</code> <pre><code>def overall_stats(self, group: pd.DataFrame) -&gt; Dict[str, Union[int, float]]:\n    \"\"\"Compute and return overall statistics for the DataFrame group.\n\n    - **total_rows**: Total number of rows in the group.\n    - **total_time**: Total time difference from max and min of 'systime' column.\n    - **is_delta_sum**: Sum of the 'is_delta' column.\n    - **is_delta_avg**: Mean of the 'is_delta' column.\n    - **is_delta_std**: Standard deviation of the 'is_delta' column.\n\n    Returns:\n        dict: A dictionary with overall statistics.\n    \"\"\"\n    statistics = {\n        'total_rows': len(group),\n        'total_time': group['systime'].max() - group['systime'].min(),\n        'is_delta_sum': group['is_delta'].sum(),\n        'is_delta_avg': group['is_delta'].mean(),\n        'is_delta_std': group['is_delta'].std(),\n    }\n    return statistics\n</code></pre>"},{"location":"reference/ts_shape/features/stats/numeric_stats/","title":"numeric_stats","text":""},{"location":"reference/ts_shape/features/stats/numeric_stats/#ts_shape.features.stats.numeric_stats","title":"numeric_stats","text":"<p>Classes:</p> <ul> <li> <code>NumericStatistics</code>           \u2013            <p>Provides class methods to calculate statistics on numeric columns in a pandas DataFrame.</p> </li> </ul>"},{"location":"reference/ts_shape/features/stats/numeric_stats/#ts_shape.features.stats.numeric_stats.NumericStatistics","title":"NumericStatistics","text":"<pre><code>NumericStatistics(dataframe: DataFrame, column_name: str = 'systime')\n</code></pre> <p>               Bases: <code>Base</code></p> <p>Provides class methods to calculate statistics on numeric columns in a pandas DataFrame.</p> <p>Parameters:</p> <p>Methods:</p> <ul> <li> <code>coefficient_of_variation</code>             \u2013              <p>Calculate the coefficient of variation of the column.</p> </li> <li> <code>column_iqr</code>             \u2013              <p>Calculate the interquartile range of the column.</p> </li> <li> <code>column_kurtosis</code>             \u2013              <p>Calculate the kurtosis of a specified column.</p> </li> <li> <code>column_mad</code>             \u2013              <p>Calculate the mean absolute deviation of the column.</p> </li> <li> <code>column_max</code>             \u2013              <p>Calculate the maximum value of a specified column.</p> </li> <li> <code>column_mean</code>             \u2013              <p>Calculate the mean of a specified column.</p> </li> <li> <code>column_median</code>             \u2013              <p>Calculate the median of a specified column.</p> </li> <li> <code>column_min</code>             \u2013              <p>Calculate the minimum value of a specified column.</p> </li> <li> <code>column_quantile</code>             \u2013              <p>Calculate a specific quantile of the column.</p> </li> <li> <code>column_range</code>             \u2013              <p>Calculate the range of the column.</p> </li> <li> <code>column_skewness</code>             \u2013              <p>Calculate the skewness of a specified column.</p> </li> <li> <code>column_std</code>             \u2013              <p>Calculate the standard deviation of a specified column.</p> </li> <li> <code>column_sum</code>             \u2013              <p>Calculate the sum of a specified column.</p> </li> <li> <code>column_variance</code>             \u2013              <p>Calculate the variance of a specified column.</p> </li> <li> <code>describe</code>             \u2013              <p>Provide a statistical summary for numeric columns in the DataFrame.</p> </li> <li> <code>get_dataframe</code>             \u2013              <p>Returns the processed DataFrame.</p> </li> <li> <code>standard_error_mean</code>             \u2013              <p>Calculate the standard error of the mean for the column.</p> </li> <li> <code>summary_as_dataframe</code>             \u2013              <p>Returns a DataFrame with comprehensive numeric statistics for the specified column.</p> </li> <li> <code>summary_as_dict</code>             \u2013              <p>Returns a dictionary with comprehensive numeric statistics for the specified column.</p> </li> </ul> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def __init__(self, dataframe: pd.DataFrame, column_name: str = 'systime') -&gt; pd.DataFrame:\n    \"\"\"\n    Initializes the Base with a DataFrame, detects time columns, converts them to datetime,\n    and sorts the DataFrame by the specified column (or the detected time column if applicable).\n\n    Args:\n        dataframe (pd.DataFrame): The DataFrame to be processed.\n        column_name (str): The column to sort by. Default is 'systime'. If the column is not found or is not a time column, the class will attempt to detect other time columns.\n    \"\"\"\n    self.dataframe = dataframe.copy()\n\n    # Attempt to convert the specified column_name to datetime if it exists\n    if column_name in self.dataframe.columns:\n        self.dataframe[column_name] = pd.to_datetime(self.dataframe[column_name], errors='coerce')\n    else:\n        # If the column_name is not in the DataFrame, fallback to automatic time detection\n        time_columns = [col for col in self.dataframe.columns if 'time' in col.lower() or 'date' in col.lower()]\n\n        # Convert all detected time columns to datetime, if any\n        for col in time_columns:\n            self.dataframe[col] = pd.to_datetime(self.dataframe[col], errors='coerce')\n\n        # If any time columns are detected, sort by the first one; otherwise, do nothing\n        if time_columns:\n            column_name = time_columns[0]\n\n    # Sort by the datetime column (either specified or detected)\n    if column_name in self.dataframe.columns:\n        self.dataframe = self.dataframe.sort_values(by=column_name)\n</code></pre>"},{"location":"reference/ts_shape/features/stats/numeric_stats/#ts_shape.features.stats.numeric_stats.NumericStatistics(dataframe)","title":"<code>dataframe</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The DataFrame to be processed.</p>"},{"location":"reference/ts_shape/features/stats/numeric_stats/#ts_shape.features.stats.numeric_stats.NumericStatistics(column_name)","title":"<code>column_name</code>","text":"(<code>str</code>, default:                   <code>'systime'</code> )           \u2013            <p>The column to sort by. Default is 'systime'. If the column is not found or is not a time column, the class will attempt to detect other time columns.</p>"},{"location":"reference/ts_shape/features/stats/numeric_stats/#ts_shape.features.stats.numeric_stats.NumericStatistics.coefficient_of_variation","title":"coefficient_of_variation  <code>classmethod</code>","text":"<pre><code>coefficient_of_variation(dataframe: DataFrame, column_name: str) -&gt; float\n</code></pre> <p>Calculate the coefficient of variation of the column.</p> Source code in <code>src/ts_shape/features/stats/numeric_stats.py</code> <pre><code>@classmethod\ndef coefficient_of_variation(cls, dataframe: pd.DataFrame, column_name: str) -&gt; float:\n    \"\"\"Calculate the coefficient of variation of the column.\"\"\"\n    mean = cls.column_mean(dataframe, column_name)\n    return cls.column_std(dataframe, column_name) / mean if mean != 0 else None\n</code></pre>"},{"location":"reference/ts_shape/features/stats/numeric_stats/#ts_shape.features.stats.numeric_stats.NumericStatistics.column_iqr","title":"column_iqr  <code>classmethod</code>","text":"<pre><code>column_iqr(dataframe: DataFrame, column_name: str) -&gt; float\n</code></pre> <p>Calculate the interquartile range of the column.</p> Source code in <code>src/ts_shape/features/stats/numeric_stats.py</code> <pre><code>@classmethod\ndef column_iqr(cls, dataframe: pd.DataFrame, column_name: str) -&gt; float:\n    \"\"\"Calculate the interquartile range of the column.\"\"\"\n    return stats.iqr(dataframe[column_name])\n</code></pre>"},{"location":"reference/ts_shape/features/stats/numeric_stats/#ts_shape.features.stats.numeric_stats.NumericStatistics.column_kurtosis","title":"column_kurtosis  <code>classmethod</code>","text":"<pre><code>column_kurtosis(dataframe: DataFrame, column_name: str) -&gt; float\n</code></pre> <p>Calculate the kurtosis of a specified column.</p> Source code in <code>src/ts_shape/features/stats/numeric_stats.py</code> <pre><code>@classmethod\ndef column_kurtosis(cls, dataframe: pd.DataFrame, column_name: str) -&gt; float:\n    \"\"\"Calculate the kurtosis of a specified column.\"\"\"\n    return dataframe[column_name].kurt()\n</code></pre>"},{"location":"reference/ts_shape/features/stats/numeric_stats/#ts_shape.features.stats.numeric_stats.NumericStatistics.column_mad","title":"column_mad  <code>classmethod</code>","text":"<pre><code>column_mad(dataframe: DataFrame, column_name: str) -&gt; float\n</code></pre> <p>Calculate the mean absolute deviation of the column.</p> Source code in <code>src/ts_shape/features/stats/numeric_stats.py</code> <pre><code>@classmethod\ndef column_mad(cls, dataframe: pd.DataFrame, column_name: str) -&gt; float:\n    \"\"\"Calculate the mean absolute deviation of the column.\"\"\"\n    return dataframe[column_name].mad()\n</code></pre>"},{"location":"reference/ts_shape/features/stats/numeric_stats/#ts_shape.features.stats.numeric_stats.NumericStatistics.column_max","title":"column_max  <code>classmethod</code>","text":"<pre><code>column_max(dataframe: DataFrame, column_name: str) -&gt; float\n</code></pre> <p>Calculate the maximum value of a specified column.</p> Source code in <code>src/ts_shape/features/stats/numeric_stats.py</code> <pre><code>@classmethod\ndef column_max(cls, dataframe: pd.DataFrame, column_name: str) -&gt; float:\n    \"\"\"Calculate the maximum value of a specified column.\"\"\"\n    return dataframe[column_name].max()\n</code></pre>"},{"location":"reference/ts_shape/features/stats/numeric_stats/#ts_shape.features.stats.numeric_stats.NumericStatistics.column_mean","title":"column_mean  <code>classmethod</code>","text":"<pre><code>column_mean(dataframe: DataFrame, column_name: str) -&gt; float\n</code></pre> <p>Calculate the mean of a specified column.</p> Source code in <code>src/ts_shape/features/stats/numeric_stats.py</code> <pre><code>@classmethod\ndef column_mean(cls, dataframe: pd.DataFrame, column_name: str) -&gt; float:\n    \"\"\"Calculate the mean of a specified column.\"\"\"\n    return dataframe[column_name].mean()\n</code></pre>"},{"location":"reference/ts_shape/features/stats/numeric_stats/#ts_shape.features.stats.numeric_stats.NumericStatistics.column_median","title":"column_median  <code>classmethod</code>","text":"<pre><code>column_median(dataframe: DataFrame, column_name: str) -&gt; float\n</code></pre> <p>Calculate the median of a specified column.</p> Source code in <code>src/ts_shape/features/stats/numeric_stats.py</code> <pre><code>@classmethod\ndef column_median(cls, dataframe: pd.DataFrame, column_name: str) -&gt; float:\n    \"\"\"Calculate the median of a specified column.\"\"\"\n    return dataframe[column_name].median()\n</code></pre>"},{"location":"reference/ts_shape/features/stats/numeric_stats/#ts_shape.features.stats.numeric_stats.NumericStatistics.column_min","title":"column_min  <code>classmethod</code>","text":"<pre><code>column_min(dataframe: DataFrame, column_name: str) -&gt; float\n</code></pre> <p>Calculate the minimum value of a specified column.</p> Source code in <code>src/ts_shape/features/stats/numeric_stats.py</code> <pre><code>@classmethod\ndef column_min(cls, dataframe: pd.DataFrame, column_name: str) -&gt; float:\n    \"\"\"Calculate the minimum value of a specified column.\"\"\"\n    return dataframe[column_name].min()\n</code></pre>"},{"location":"reference/ts_shape/features/stats/numeric_stats/#ts_shape.features.stats.numeric_stats.NumericStatistics.column_quantile","title":"column_quantile  <code>classmethod</code>","text":"<pre><code>column_quantile(dataframe: DataFrame, column_name: str, quantile: float) -&gt; float\n</code></pre> <p>Calculate a specific quantile of the column.</p> Source code in <code>src/ts_shape/features/stats/numeric_stats.py</code> <pre><code>@classmethod\ndef column_quantile(cls, dataframe: pd.DataFrame, column_name: str, quantile: float) -&gt; float:\n    \"\"\"Calculate a specific quantile of the column.\"\"\"\n    return dataframe[column_name].quantile(quantile)\n</code></pre>"},{"location":"reference/ts_shape/features/stats/numeric_stats/#ts_shape.features.stats.numeric_stats.NumericStatistics.column_range","title":"column_range  <code>classmethod</code>","text":"<pre><code>column_range(dataframe: DataFrame, column_name: str) -&gt; float\n</code></pre> <p>Calculate the range of the column.</p> Source code in <code>src/ts_shape/features/stats/numeric_stats.py</code> <pre><code>@classmethod\ndef column_range(cls, dataframe: pd.DataFrame, column_name: str) -&gt; float:\n    \"\"\"Calculate the range of the column.\"\"\"\n    return cls.column_max(dataframe, column_name) - cls.column_min(dataframe, column_name)\n</code></pre>"},{"location":"reference/ts_shape/features/stats/numeric_stats/#ts_shape.features.stats.numeric_stats.NumericStatistics.column_skewness","title":"column_skewness  <code>classmethod</code>","text":"<pre><code>column_skewness(dataframe: DataFrame, column_name: str) -&gt; float\n</code></pre> <p>Calculate the skewness of a specified column.</p> Source code in <code>src/ts_shape/features/stats/numeric_stats.py</code> <pre><code>@classmethod\ndef column_skewness(cls, dataframe: pd.DataFrame, column_name: str) -&gt; float:\n    \"\"\"Calculate the skewness of a specified column.\"\"\"\n    return dataframe[column_name].skew()\n</code></pre>"},{"location":"reference/ts_shape/features/stats/numeric_stats/#ts_shape.features.stats.numeric_stats.NumericStatistics.column_std","title":"column_std  <code>classmethod</code>","text":"<pre><code>column_std(dataframe: DataFrame, column_name: str) -&gt; float\n</code></pre> <p>Calculate the standard deviation of a specified column.</p> Source code in <code>src/ts_shape/features/stats/numeric_stats.py</code> <pre><code>@classmethod\ndef column_std(cls, dataframe: pd.DataFrame, column_name: str) -&gt; float:\n    \"\"\"Calculate the standard deviation of a specified column.\"\"\"\n    return dataframe[column_name].std()\n</code></pre>"},{"location":"reference/ts_shape/features/stats/numeric_stats/#ts_shape.features.stats.numeric_stats.NumericStatistics.column_sum","title":"column_sum  <code>classmethod</code>","text":"<pre><code>column_sum(dataframe: DataFrame, column_name: str) -&gt; float\n</code></pre> <p>Calculate the sum of a specified column.</p> Source code in <code>src/ts_shape/features/stats/numeric_stats.py</code> <pre><code>@classmethod\ndef column_sum(cls, dataframe: pd.DataFrame, column_name: str) -&gt; float:\n    \"\"\"Calculate the sum of a specified column.\"\"\"\n    return dataframe[column_name].sum()\n</code></pre>"},{"location":"reference/ts_shape/features/stats/numeric_stats/#ts_shape.features.stats.numeric_stats.NumericStatistics.column_variance","title":"column_variance  <code>classmethod</code>","text":"<pre><code>column_variance(dataframe: DataFrame, column_name: str) -&gt; float\n</code></pre> <p>Calculate the variance of a specified column.</p> Source code in <code>src/ts_shape/features/stats/numeric_stats.py</code> <pre><code>@classmethod\ndef column_variance(cls, dataframe: pd.DataFrame, column_name: str) -&gt; float:\n    \"\"\"Calculate the variance of a specified column.\"\"\"\n    return dataframe[column_name].var()\n</code></pre>"},{"location":"reference/ts_shape/features/stats/numeric_stats/#ts_shape.features.stats.numeric_stats.NumericStatistics.describe","title":"describe  <code>classmethod</code>","text":"<pre><code>describe(dataframe: DataFrame) -&gt; DataFrame\n</code></pre> <p>Provide a statistical summary for numeric columns in the DataFrame.</p> Source code in <code>src/ts_shape/features/stats/numeric_stats.py</code> <pre><code>@classmethod\ndef describe(cls, dataframe: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Provide a statistical summary for numeric columns in the DataFrame.\"\"\"\n    return dataframe.describe()\n</code></pre>"},{"location":"reference/ts_shape/features/stats/numeric_stats/#ts_shape.features.stats.numeric_stats.NumericStatistics.get_dataframe","title":"get_dataframe","text":"<pre><code>get_dataframe() -&gt; DataFrame\n</code></pre> <p>Returns the processed DataFrame.</p> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def get_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"Returns the processed DataFrame.\"\"\"\n    return self.dataframe\n</code></pre>"},{"location":"reference/ts_shape/features/stats/numeric_stats/#ts_shape.features.stats.numeric_stats.NumericStatistics.standard_error_mean","title":"standard_error_mean  <code>classmethod</code>","text":"<pre><code>standard_error_mean(dataframe: DataFrame, column_name: str) -&gt; float\n</code></pre> <p>Calculate the standard error of the mean for the column.</p> Source code in <code>src/ts_shape/features/stats/numeric_stats.py</code> <pre><code>@classmethod\ndef standard_error_mean(cls, dataframe: pd.DataFrame, column_name: str) -&gt; float:\n    \"\"\"Calculate the standard error of the mean for the column.\"\"\"\n    return dataframe[column_name].sem()\n</code></pre>"},{"location":"reference/ts_shape/features/stats/numeric_stats/#ts_shape.features.stats.numeric_stats.NumericStatistics.summary_as_dataframe","title":"summary_as_dataframe  <code>classmethod</code>","text":"<pre><code>summary_as_dataframe(dataframe: DataFrame, column_name: str) -&gt; DataFrame\n</code></pre> <p>Returns a DataFrame with comprehensive numeric statistics for the specified column.</p> Source code in <code>src/ts_shape/features/stats/numeric_stats.py</code> <pre><code>@classmethod\ndef summary_as_dataframe(cls, dataframe: pd.DataFrame, column_name: str) -&gt; pd.DataFrame:\n    \"\"\"Returns a DataFrame with comprehensive numeric statistics for the specified column.\"\"\"\n    summary_data = cls.summary_as_dict(dataframe, column_name)\n    return pd.DataFrame([summary_data])\n</code></pre>"},{"location":"reference/ts_shape/features/stats/numeric_stats/#ts_shape.features.stats.numeric_stats.NumericStatistics.summary_as_dict","title":"summary_as_dict  <code>classmethod</code>","text":"<pre><code>summary_as_dict(dataframe: DataFrame, column_name: str) -&gt; Dict[str, Union[float, int]]\n</code></pre> <p>Returns a dictionary with comprehensive numeric statistics for the specified column.</p> Source code in <code>src/ts_shape/features/stats/numeric_stats.py</code> <pre><code>@classmethod\ndef summary_as_dict(cls, dataframe: pd.DataFrame, column_name: str) -&gt; Dict[str, Union[float, int]]:\n    \"\"\"Returns a dictionary with comprehensive numeric statistics for the specified column.\"\"\"\n    series = dataframe[column_name]\n    return {\n        'min': cls.column_min(dataframe, column_name),\n        'max': cls.column_max(dataframe, column_name),\n        'mean': cls.column_mean(dataframe, column_name),\n        'median': cls.column_median(dataframe, column_name),\n        'std': cls.column_std(dataframe, column_name),\n        'var': cls.column_variance(dataframe, column_name),\n        'sum': cls.column_sum(dataframe, column_name),\n        'kurtosis': cls.column_kurtosis(dataframe, column_name),\n        'skewness': cls.column_skewness(dataframe, column_name),\n        'q1': cls.column_quantile(dataframe, column_name, 0.25),\n        'q3': cls.column_quantile(dataframe, column_name, 0.75),\n        'iqr': cls.column_iqr(dataframe, column_name),\n        'range': cls.column_range(dataframe, column_name),\n        'mad': cls.column_mad(dataframe, column_name),\n        'coeff_var': cls.coefficient_of_variation(dataframe, column_name),\n        'sem': cls.standard_error_mean(dataframe, column_name),\n        'mode': cls.column_mode(dataframe, column_name),\n        'percentile_90': cls.column_quantile(dataframe, column_name, 0.90),\n        'percentile_10': cls.column_quantile(dataframe, column_name, 0.10),\n    }\n</code></pre>"},{"location":"reference/ts_shape/features/stats/string_stats/","title":"string_stats","text":""},{"location":"reference/ts_shape/features/stats/string_stats/#ts_shape.features.stats.string_stats","title":"string_stats","text":"<p>Classes:</p> <ul> <li> <code>StringStatistics</code>           \u2013            <p>Provides class methods to calculate statistics on string columns in a pandas DataFrame.</p> </li> </ul>"},{"location":"reference/ts_shape/features/stats/string_stats/#ts_shape.features.stats.string_stats.StringStatistics","title":"StringStatistics","text":"<pre><code>StringStatistics(dataframe: DataFrame, column_name: str = 'systime')\n</code></pre> <p>               Bases: <code>Base</code></p> <p>Provides class methods to calculate statistics on string columns in a pandas DataFrame.</p> <p>Parameters:</p> <p>Methods:</p> <ul> <li> <code>average_string_length</code>             \u2013              <p>Returns the average length of strings in the column, excluding null values.</p> </li> <li> <code>contains_digit_count</code>             \u2013              <p>Counts how many strings contain digits.</p> </li> <li> <code>contains_substring_count</code>             \u2013              <p>Counts how many strings contain the specified substring.</p> </li> <li> <code>count_most_frequent</code>             \u2013              <p>Returns the count of the most frequent string in the column.</p> </li> <li> <code>count_null</code>             \u2013              <p>Returns the number of null (NaN) values in the column.</p> </li> <li> <code>count_unique</code>             \u2013              <p>Returns the number of unique strings in the column.</p> </li> <li> <code>ends_with_count</code>             \u2013              <p>Counts how many strings end with the specified suffix.</p> </li> <li> <code>get_dataframe</code>             \u2013              <p>Returns the processed DataFrame.</p> </li> <li> <code>longest_string</code>             \u2013              <p>Returns the longest string in the column.</p> </li> <li> <code>lowercase_percentage</code>             \u2013              <p>Returns the percentage of strings that are fully lowercase.</p> </li> <li> <code>most_common_n_strings</code>             \u2013              <p>Returns the top N most frequent strings in the column.</p> </li> <li> <code>most_frequent</code>             \u2013              <p>Returns the most frequent string in the column.</p> </li> <li> <code>shortest_string</code>             \u2013              <p>Returns the shortest string in the column.</p> </li> <li> <code>starts_with_count</code>             \u2013              <p>Counts how many strings start with the specified prefix.</p> </li> <li> <code>string_length_summary</code>             \u2013              <p>Returns a summary of string lengths, including min, max, and average lengths.</p> </li> <li> <code>summary_as_dataframe</code>             \u2013              <p>Returns a DataFrame with comprehensive string statistics for the specified column.</p> </li> <li> <code>summary_as_dict</code>             \u2013              <p>Returns a dictionary with comprehensive string statistics for the specified column.</p> </li> <li> <code>uppercase_percentage</code>             \u2013              <p>Returns the percentage of strings that are fully uppercase.</p> </li> </ul> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def __init__(self, dataframe: pd.DataFrame, column_name: str = 'systime') -&gt; pd.DataFrame:\n    \"\"\"\n    Initializes the Base with a DataFrame, detects time columns, converts them to datetime,\n    and sorts the DataFrame by the specified column (or the detected time column if applicable).\n\n    Args:\n        dataframe (pd.DataFrame): The DataFrame to be processed.\n        column_name (str): The column to sort by. Default is 'systime'. If the column is not found or is not a time column, the class will attempt to detect other time columns.\n    \"\"\"\n    self.dataframe = dataframe.copy()\n\n    # Attempt to convert the specified column_name to datetime if it exists\n    if column_name in self.dataframe.columns:\n        self.dataframe[column_name] = pd.to_datetime(self.dataframe[column_name], errors='coerce')\n    else:\n        # If the column_name is not in the DataFrame, fallback to automatic time detection\n        time_columns = [col for col in self.dataframe.columns if 'time' in col.lower() or 'date' in col.lower()]\n\n        # Convert all detected time columns to datetime, if any\n        for col in time_columns:\n            self.dataframe[col] = pd.to_datetime(self.dataframe[col], errors='coerce')\n\n        # If any time columns are detected, sort by the first one; otherwise, do nothing\n        if time_columns:\n            column_name = time_columns[0]\n\n    # Sort by the datetime column (either specified or detected)\n    if column_name in self.dataframe.columns:\n        self.dataframe = self.dataframe.sort_values(by=column_name)\n</code></pre>"},{"location":"reference/ts_shape/features/stats/string_stats/#ts_shape.features.stats.string_stats.StringStatistics(dataframe)","title":"<code>dataframe</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The DataFrame to be processed.</p>"},{"location":"reference/ts_shape/features/stats/string_stats/#ts_shape.features.stats.string_stats.StringStatistics(column_name)","title":"<code>column_name</code>","text":"(<code>str</code>, default:                   <code>'systime'</code> )           \u2013            <p>The column to sort by. Default is 'systime'. If the column is not found or is not a time column, the class will attempt to detect other time columns.</p>"},{"location":"reference/ts_shape/features/stats/string_stats/#ts_shape.features.stats.string_stats.StringStatistics.average_string_length","title":"average_string_length  <code>classmethod</code>","text":"<pre><code>average_string_length(dataframe: DataFrame, column_name: str = 'value_string') -&gt; float\n</code></pre> <p>Returns the average length of strings in the column, excluding null values.</p> Source code in <code>src/ts_shape/features/stats/string_stats.py</code> <pre><code>@classmethod\ndef average_string_length(cls, dataframe: pd.DataFrame, column_name: str = 'value_string') -&gt; float:\n    \"\"\"Returns the average length of strings in the column, excluding null values.\"\"\"\n    return dataframe[column_name].dropna().str.len().mean()\n</code></pre>"},{"location":"reference/ts_shape/features/stats/string_stats/#ts_shape.features.stats.string_stats.StringStatistics.contains_digit_count","title":"contains_digit_count  <code>classmethod</code>","text":"<pre><code>contains_digit_count(dataframe: DataFrame, column_name: str = 'value_string') -&gt; int\n</code></pre> <p>Counts how many strings contain digits.</p> Source code in <code>src/ts_shape/features/stats/string_stats.py</code> <pre><code>@classmethod\ndef contains_digit_count(cls, dataframe: pd.DataFrame, column_name: str = 'value_string') -&gt; int:\n    \"\"\"Counts how many strings contain digits.\"\"\"\n    return dataframe[column_name].dropna().str.contains(r'\\d').sum()\n</code></pre>"},{"location":"reference/ts_shape/features/stats/string_stats/#ts_shape.features.stats.string_stats.StringStatistics.contains_substring_count","title":"contains_substring_count  <code>classmethod</code>","text":"<pre><code>contains_substring_count(dataframe: DataFrame, substring: str, column_name: str = 'value_string') -&gt; int\n</code></pre> <p>Counts how many strings contain the specified substring.</p> Source code in <code>src/ts_shape/features/stats/string_stats.py</code> <pre><code>@classmethod\ndef contains_substring_count(cls, dataframe: pd.DataFrame, substring: str, column_name: str = 'value_string') -&gt; int:\n    \"\"\"Counts how many strings contain the specified substring.\"\"\"\n    return dataframe[column_name].dropna().str.contains(substring).sum()\n</code></pre>"},{"location":"reference/ts_shape/features/stats/string_stats/#ts_shape.features.stats.string_stats.StringStatistics.count_most_frequent","title":"count_most_frequent  <code>classmethod</code>","text":"<pre><code>count_most_frequent(dataframe: DataFrame, column_name: str = 'value_string') -&gt; int\n</code></pre> <p>Returns the count of the most frequent string in the column.</p> Source code in <code>src/ts_shape/features/stats/string_stats.py</code> <pre><code>@classmethod\ndef count_most_frequent(cls, dataframe: pd.DataFrame, column_name: str = 'value_string') -&gt; int:\n    \"\"\"Returns the count of the most frequent string in the column.\"\"\"\n    most_frequent_value = cls.most_frequent(dataframe, column_name)\n    return dataframe[column_name].value_counts().loc[most_frequent_value]\n</code></pre>"},{"location":"reference/ts_shape/features/stats/string_stats/#ts_shape.features.stats.string_stats.StringStatistics.count_null","title":"count_null  <code>classmethod</code>","text":"<pre><code>count_null(dataframe: DataFrame, column_name: str = 'value_string') -&gt; int\n</code></pre> <p>Returns the number of null (NaN) values in the column.</p> Source code in <code>src/ts_shape/features/stats/string_stats.py</code> <pre><code>@classmethod\ndef count_null(cls, dataframe: pd.DataFrame, column_name: str = 'value_string') -&gt; int:\n    \"\"\"Returns the number of null (NaN) values in the column.\"\"\"\n    return dataframe[column_name].isna().sum()\n</code></pre>"},{"location":"reference/ts_shape/features/stats/string_stats/#ts_shape.features.stats.string_stats.StringStatistics.count_unique","title":"count_unique  <code>classmethod</code>","text":"<pre><code>count_unique(dataframe: DataFrame, column_name: str = 'value_string') -&gt; int\n</code></pre> <p>Returns the number of unique strings in the column.</p> Source code in <code>src/ts_shape/features/stats/string_stats.py</code> <pre><code>@classmethod\ndef count_unique(cls, dataframe: pd.DataFrame, column_name: str = 'value_string') -&gt; int:\n    \"\"\"Returns the number of unique strings in the column.\"\"\"\n    return dataframe[column_name].nunique()\n</code></pre>"},{"location":"reference/ts_shape/features/stats/string_stats/#ts_shape.features.stats.string_stats.StringStatistics.ends_with_count","title":"ends_with_count  <code>classmethod</code>","text":"<pre><code>ends_with_count(dataframe: DataFrame, suffix: str, column_name: str = 'value_string') -&gt; int\n</code></pre> <p>Counts how many strings end with the specified suffix.</p> Source code in <code>src/ts_shape/features/stats/string_stats.py</code> <pre><code>@classmethod\ndef ends_with_count(cls, dataframe: pd.DataFrame, suffix: str, column_name: str = 'value_string') -&gt; int:\n    \"\"\"Counts how many strings end with the specified suffix.\"\"\"\n    return dataframe[column_name].dropna().str.endswith(suffix).sum()\n</code></pre>"},{"location":"reference/ts_shape/features/stats/string_stats/#ts_shape.features.stats.string_stats.StringStatistics.get_dataframe","title":"get_dataframe","text":"<pre><code>get_dataframe() -&gt; DataFrame\n</code></pre> <p>Returns the processed DataFrame.</p> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def get_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"Returns the processed DataFrame.\"\"\"\n    return self.dataframe\n</code></pre>"},{"location":"reference/ts_shape/features/stats/string_stats/#ts_shape.features.stats.string_stats.StringStatistics.longest_string","title":"longest_string  <code>classmethod</code>","text":"<pre><code>longest_string(dataframe: DataFrame, column_name: str = 'value_string') -&gt; str\n</code></pre> <p>Returns the longest string in the column.</p> Source code in <code>src/ts_shape/features/stats/string_stats.py</code> <pre><code>@classmethod\ndef longest_string(cls, dataframe: pd.DataFrame, column_name: str = 'value_string') -&gt; str:\n    \"\"\"Returns the longest string in the column.\"\"\"\n    return dataframe[column_name].dropna().loc[dataframe[column_name].dropna().str.len().idxmax()]\n</code></pre>"},{"location":"reference/ts_shape/features/stats/string_stats/#ts_shape.features.stats.string_stats.StringStatistics.lowercase_percentage","title":"lowercase_percentage  <code>classmethod</code>","text":"<pre><code>lowercase_percentage(dataframe: DataFrame, column_name: str = 'value_string') -&gt; float\n</code></pre> <p>Returns the percentage of strings that are fully lowercase.</p> Source code in <code>src/ts_shape/features/stats/string_stats.py</code> <pre><code>@classmethod\ndef lowercase_percentage(cls, dataframe: pd.DataFrame, column_name: str = 'value_string') -&gt; float:\n    \"\"\"Returns the percentage of strings that are fully lowercase.\"\"\"\n    total_non_null = dataframe[column_name].notna().sum()\n    if total_non_null == 0:\n        return 0.0\n    lowercase_count = dataframe[column_name].dropna().str.islower().sum()\n    return (lowercase_count / total_non_null) * 100\n</code></pre>"},{"location":"reference/ts_shape/features/stats/string_stats/#ts_shape.features.stats.string_stats.StringStatistics.most_common_n_strings","title":"most_common_n_strings  <code>classmethod</code>","text":"<pre><code>most_common_n_strings(dataframe: DataFrame, n: int, column_name: str = 'value_string') -&gt; Series\n</code></pre> <p>Returns the top N most frequent strings in the column.</p> Source code in <code>src/ts_shape/features/stats/string_stats.py</code> <pre><code>@classmethod\ndef most_common_n_strings(cls, dataframe: pd.DataFrame, n: int, column_name: str = 'value_string') -&gt; pd.Series:\n    \"\"\"Returns the top N most frequent strings in the column.\"\"\"\n    return dataframe[column_name].value_counts().head(n)\n</code></pre>"},{"location":"reference/ts_shape/features/stats/string_stats/#ts_shape.features.stats.string_stats.StringStatistics.most_frequent","title":"most_frequent  <code>classmethod</code>","text":"<pre><code>most_frequent(dataframe: DataFrame, column_name: str = 'value_string') -&gt; str\n</code></pre> <p>Returns the most frequent string in the column.</p> Source code in <code>src/ts_shape/features/stats/string_stats.py</code> <pre><code>@classmethod\ndef most_frequent(cls, dataframe: pd.DataFrame, column_name: str = 'value_string') -&gt; str:\n    \"\"\"Returns the most frequent string in the column.\"\"\"\n    return dataframe[column_name].mode().iloc[0]\n</code></pre>"},{"location":"reference/ts_shape/features/stats/string_stats/#ts_shape.features.stats.string_stats.StringStatistics.shortest_string","title":"shortest_string  <code>classmethod</code>","text":"<pre><code>shortest_string(dataframe: DataFrame, column_name: str = 'value_string') -&gt; str\n</code></pre> <p>Returns the shortest string in the column.</p> Source code in <code>src/ts_shape/features/stats/string_stats.py</code> <pre><code>@classmethod\ndef shortest_string(cls, dataframe: pd.DataFrame, column_name: str = 'value_string') -&gt; str:\n    \"\"\"Returns the shortest string in the column.\"\"\"\n    return dataframe[column_name].dropna().loc[dataframe[column_name].dropna().str.len().idxmin()]\n</code></pre>"},{"location":"reference/ts_shape/features/stats/string_stats/#ts_shape.features.stats.string_stats.StringStatistics.starts_with_count","title":"starts_with_count  <code>classmethod</code>","text":"<pre><code>starts_with_count(dataframe: DataFrame, prefix: str, column_name: str = 'value_string') -&gt; int\n</code></pre> <p>Counts how many strings start with the specified prefix.</p> Source code in <code>src/ts_shape/features/stats/string_stats.py</code> <pre><code>@classmethod\ndef starts_with_count(cls, dataframe: pd.DataFrame, prefix: str, column_name: str = 'value_string') -&gt; int:\n    \"\"\"Counts how many strings start with the specified prefix.\"\"\"\n    return dataframe[column_name].dropna().str.startswith(prefix).sum()\n</code></pre>"},{"location":"reference/ts_shape/features/stats/string_stats/#ts_shape.features.stats.string_stats.StringStatistics.string_length_summary","title":"string_length_summary  <code>classmethod</code>","text":"<pre><code>string_length_summary(dataframe: DataFrame, column_name: str = 'value_string') -&gt; DataFrame\n</code></pre> <p>Returns a summary of string lengths, including min, max, and average lengths.</p> Source code in <code>src/ts_shape/features/stats/string_stats.py</code> <pre><code>@classmethod\ndef string_length_summary(cls, dataframe: pd.DataFrame, column_name: str = 'value_string') -&gt; pd.DataFrame:\n    \"\"\"Returns a summary of string lengths, including min, max, and average lengths.\"\"\"\n    lengths = dataframe[column_name].dropna().str.len()\n    return pd.DataFrame({\n        'Min Length': [lengths.min()],\n        'Max Length': [lengths.max()],\n        'Average Length': [lengths.mean()]\n    })\n</code></pre>"},{"location":"reference/ts_shape/features/stats/string_stats/#ts_shape.features.stats.string_stats.StringStatistics.summary_as_dataframe","title":"summary_as_dataframe  <code>classmethod</code>","text":"<pre><code>summary_as_dataframe(dataframe: DataFrame, column_name: str) -&gt; DataFrame\n</code></pre> <p>Returns a DataFrame with comprehensive string statistics for the specified column.</p> Source code in <code>src/ts_shape/features/stats/string_stats.py</code> <pre><code>@classmethod\ndef summary_as_dataframe(cls, dataframe: pd.DataFrame, column_name: str) -&gt; pd.DataFrame:\n    \"\"\"Returns a DataFrame with comprehensive string statistics for the specified column.\"\"\"\n    summary_data = cls.summary_as_dict(dataframe, column_name)\n    return pd.DataFrame([summary_data])\n</code></pre>"},{"location":"reference/ts_shape/features/stats/string_stats/#ts_shape.features.stats.string_stats.StringStatistics.summary_as_dict","title":"summary_as_dict  <code>classmethod</code>","text":"<pre><code>summary_as_dict(dataframe: DataFrame, column_name: str) -&gt; Dict[str, Union[int, str, float]]\n</code></pre> <p>Returns a dictionary with comprehensive string statistics for the specified column.</p> Source code in <code>src/ts_shape/features/stats/string_stats.py</code> <pre><code>@classmethod\ndef summary_as_dict(cls, dataframe: pd.DataFrame, column_name: str) -&gt; Dict[str, Union[int, str, float]]:\n    \"\"\"Returns a dictionary with comprehensive string statistics for the specified column.\"\"\"\n    most_frequent = cls.most_frequent(dataframe, column_name)\n    value_counts = dataframe[column_name].value_counts()\n\n    return {\n        'unique_values': cls.count_unique(dataframe, column_name),\n        'most_frequent': most_frequent,\n        'count_most_frequent': cls.count_most_frequent(dataframe, column_name),\n        'count_null': cls.count_null(dataframe, column_name),\n        'average_string_length': cls.average_string_length(dataframe, column_name),\n        'longest_string': cls.longest_string(dataframe, column_name),\n        'shortest_string': cls.shortest_string(dataframe, column_name),\n        'uppercase_percentage': cls.uppercase_percentage(dataframe, column_name),\n        'lowercase_percentage': cls.lowercase_percentage(dataframe, column_name),\n        'contains_digit_count': cls.contains_digit_count(dataframe, column_name),\n        'least_common': value_counts.idxmin() if not value_counts.empty else None,\n        'frequency_least_common': value_counts.min() if not value_counts.empty else 0\n    }\n</code></pre>"},{"location":"reference/ts_shape/features/stats/string_stats/#ts_shape.features.stats.string_stats.StringStatistics.uppercase_percentage","title":"uppercase_percentage  <code>classmethod</code>","text":"<pre><code>uppercase_percentage(dataframe: DataFrame, column_name: str = 'value_string') -&gt; float\n</code></pre> <p>Returns the percentage of strings that are fully uppercase.</p> Source code in <code>src/ts_shape/features/stats/string_stats.py</code> <pre><code>@classmethod\ndef uppercase_percentage(cls, dataframe: pd.DataFrame, column_name: str = 'value_string') -&gt; float:\n    \"\"\"Returns the percentage of strings that are fully uppercase.\"\"\"\n    total_non_null = dataframe[column_name].notna().sum()\n    if total_non_null == 0:\n        return 0.0\n    uppercase_count = dataframe[column_name].dropna().str.isupper().sum()\n    return (uppercase_count / total_non_null) * 100\n</code></pre>"},{"location":"reference/ts_shape/features/stats/timestamp_stats/","title":"timestamp_stats","text":""},{"location":"reference/ts_shape/features/stats/timestamp_stats/#ts_shape.features.stats.timestamp_stats","title":"timestamp_stats","text":"<p>Classes:</p> <ul> <li> <code>TimestampStatistics</code>           \u2013            <p>Provides class methods to calculate statistics on timestamp columns in a pandas DataFrame.</p> </li> </ul>"},{"location":"reference/ts_shape/features/stats/timestamp_stats/#ts_shape.features.stats.timestamp_stats.TimestampStatistics","title":"TimestampStatistics","text":"<pre><code>TimestampStatistics(dataframe: DataFrame, column_name: str = 'systime')\n</code></pre> <p>               Bases: <code>Base</code></p> <p>Provides class methods to calculate statistics on timestamp columns in a pandas DataFrame. The default column for calculations is 'systime'.</p> <p>Parameters:</p> <p>Methods:</p> <ul> <li> <code>average_time_gap</code>             \u2013              <p>Returns the average time gap between consecutive timestamps.</p> </li> <li> <code>count_most_frequent_timestamp</code>             \u2013              <p>Returns the count of the most frequent timestamp in the column.</p> </li> <li> <code>count_not_null</code>             \u2013              <p>Returns the number of non-null (valid) timestamps in the column.</p> </li> <li> <code>count_null</code>             \u2013              <p>Returns the number of null (NaN) values in the timestamp column.</p> </li> <li> <code>days_with_most_activity</code>             \u2013              <p>Returns the top N days with the most timestamp activity.</p> </li> <li> <code>earliest_timestamp</code>             \u2013              <p>Returns the earliest timestamp in the column.</p> </li> <li> <code>get_dataframe</code>             \u2013              <p>Returns the processed DataFrame.</p> </li> <li> <code>hour_distribution</code>             \u2013              <p>Returns the distribution of timestamps per hour of the day.</p> </li> <li> <code>latest_timestamp</code>             \u2013              <p>Returns the latest timestamp in the column.</p> </li> <li> <code>median_timestamp</code>             \u2013              <p>Returns the median timestamp in the column.</p> </li> <li> <code>month_distribution</code>             \u2013              <p>Returns the distribution of timestamps per month.</p> </li> <li> <code>most_frequent_day</code>             \u2013              <p>Returns the most frequent day of the week (0=Monday, 6=Sunday).</p> </li> <li> <code>most_frequent_hour</code>             \u2013              <p>Returns the most frequent hour of the day (0-23).</p> </li> <li> <code>most_frequent_timestamp</code>             \u2013              <p>Returns the most frequent timestamp in the column.</p> </li> <li> <code>standard_deviation_timestamps</code>             \u2013              <p>Returns the standard deviation of the time differences between consecutive timestamps.</p> </li> <li> <code>timestamp_quartiles</code>             \u2013              <p>Returns the 25th, 50th (median), and 75th percentiles of the timestamps.</p> </li> <li> <code>timestamp_range</code>             \u2013              <p>Returns the time range (difference) between the earliest and latest timestamps.</p> </li> <li> <code>weekday_distribution</code>             \u2013              <p>Returns the distribution of timestamps per weekday.</p> </li> <li> <code>year_distribution</code>             \u2013              <p>Returns the distribution of timestamps per year.</p> </li> </ul> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def __init__(self, dataframe: pd.DataFrame, column_name: str = 'systime') -&gt; pd.DataFrame:\n    \"\"\"\n    Initializes the Base with a DataFrame, detects time columns, converts them to datetime,\n    and sorts the DataFrame by the specified column (or the detected time column if applicable).\n\n    Args:\n        dataframe (pd.DataFrame): The DataFrame to be processed.\n        column_name (str): The column to sort by. Default is 'systime'. If the column is not found or is not a time column, the class will attempt to detect other time columns.\n    \"\"\"\n    self.dataframe = dataframe.copy()\n\n    # Attempt to convert the specified column_name to datetime if it exists\n    if column_name in self.dataframe.columns:\n        self.dataframe[column_name] = pd.to_datetime(self.dataframe[column_name], errors='coerce')\n    else:\n        # If the column_name is not in the DataFrame, fallback to automatic time detection\n        time_columns = [col for col in self.dataframe.columns if 'time' in col.lower() or 'date' in col.lower()]\n\n        # Convert all detected time columns to datetime, if any\n        for col in time_columns:\n            self.dataframe[col] = pd.to_datetime(self.dataframe[col], errors='coerce')\n\n        # If any time columns are detected, sort by the first one; otherwise, do nothing\n        if time_columns:\n            column_name = time_columns[0]\n\n    # Sort by the datetime column (either specified or detected)\n    if column_name in self.dataframe.columns:\n        self.dataframe = self.dataframe.sort_values(by=column_name)\n</code></pre>"},{"location":"reference/ts_shape/features/stats/timestamp_stats/#ts_shape.features.stats.timestamp_stats.TimestampStatistics(dataframe)","title":"<code>dataframe</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The DataFrame to be processed.</p>"},{"location":"reference/ts_shape/features/stats/timestamp_stats/#ts_shape.features.stats.timestamp_stats.TimestampStatistics(column_name)","title":"<code>column_name</code>","text":"(<code>str</code>, default:                   <code>'systime'</code> )           \u2013            <p>The column to sort by. Default is 'systime'. If the column is not found or is not a time column, the class will attempt to detect other time columns.</p>"},{"location":"reference/ts_shape/features/stats/timestamp_stats/#ts_shape.features.stats.timestamp_stats.TimestampStatistics.average_time_gap","title":"average_time_gap  <code>classmethod</code>","text":"<pre><code>average_time_gap(dataframe: DataFrame, column_name: str = 'systime') -&gt; Timedelta\n</code></pre> <p>Returns the average time gap between consecutive timestamps.</p> Source code in <code>src/ts_shape/features/stats/timestamp_stats.py</code> <pre><code>@classmethod\ndef average_time_gap(cls, dataframe: pd.DataFrame, column_name: str = 'systime') -&gt; pd.Timedelta:\n    \"\"\"Returns the average time gap between consecutive timestamps.\"\"\"\n    sorted_times = dataframe[column_name].dropna().sort_values()\n    time_deltas = sorted_times.diff().dropna()\n    return time_deltas.mean()\n</code></pre>"},{"location":"reference/ts_shape/features/stats/timestamp_stats/#ts_shape.features.stats.timestamp_stats.TimestampStatistics.count_most_frequent_timestamp","title":"count_most_frequent_timestamp  <code>classmethod</code>","text":"<pre><code>count_most_frequent_timestamp(dataframe: DataFrame, column_name: str = 'systime') -&gt; int\n</code></pre> <p>Returns the count of the most frequent timestamp in the column.</p> Source code in <code>src/ts_shape/features/stats/timestamp_stats.py</code> <pre><code>@classmethod\ndef count_most_frequent_timestamp(cls, dataframe: pd.DataFrame, column_name: str = 'systime') -&gt; int:\n    \"\"\"Returns the count of the most frequent timestamp in the column.\"\"\"\n    most_frequent_value = cls.most_frequent_timestamp(dataframe, column_name)\n    return dataframe[column_name].value_counts().loc[most_frequent_value]\n</code></pre>"},{"location":"reference/ts_shape/features/stats/timestamp_stats/#ts_shape.features.stats.timestamp_stats.TimestampStatistics.count_not_null","title":"count_not_null  <code>classmethod</code>","text":"<pre><code>count_not_null(dataframe: DataFrame, column_name: str = 'systime') -&gt; int\n</code></pre> <p>Returns the number of non-null (valid) timestamps in the column.</p> Source code in <code>src/ts_shape/features/stats/timestamp_stats.py</code> <pre><code>@classmethod\ndef count_not_null(cls, dataframe: pd.DataFrame, column_name: str = 'systime') -&gt; int:\n    \"\"\"Returns the number of non-null (valid) timestamps in the column.\"\"\"\n    return dataframe[column_name].notna().sum()\n</code></pre>"},{"location":"reference/ts_shape/features/stats/timestamp_stats/#ts_shape.features.stats.timestamp_stats.TimestampStatistics.count_null","title":"count_null  <code>classmethod</code>","text":"<pre><code>count_null(dataframe: DataFrame, column_name: str = 'systime') -&gt; int\n</code></pre> <p>Returns the number of null (NaN) values in the timestamp column.</p> Source code in <code>src/ts_shape/features/stats/timestamp_stats.py</code> <pre><code>@classmethod\ndef count_null(cls, dataframe: pd.DataFrame, column_name: str = 'systime') -&gt; int:\n    \"\"\"Returns the number of null (NaN) values in the timestamp column.\"\"\"\n    return dataframe[column_name].isna().sum()\n</code></pre>"},{"location":"reference/ts_shape/features/stats/timestamp_stats/#ts_shape.features.stats.timestamp_stats.TimestampStatistics.days_with_most_activity","title":"days_with_most_activity  <code>classmethod</code>","text":"<pre><code>days_with_most_activity(dataframe: DataFrame, column_name: str = 'systime', n: int = 3) -&gt; Series\n</code></pre> <p>Returns the top N days with the most timestamp activity.</p> Source code in <code>src/ts_shape/features/stats/timestamp_stats.py</code> <pre><code>@classmethod\ndef days_with_most_activity(cls, dataframe: pd.DataFrame, column_name: str = 'systime', n: int = 3) -&gt; pd.Series:\n    \"\"\"Returns the top N days with the most timestamp activity.\"\"\"\n    return dataframe[column_name].dt.date.value_counts().head(n)\n</code></pre>"},{"location":"reference/ts_shape/features/stats/timestamp_stats/#ts_shape.features.stats.timestamp_stats.TimestampStatistics.earliest_timestamp","title":"earliest_timestamp  <code>classmethod</code>","text":"<pre><code>earliest_timestamp(dataframe: DataFrame, column_name: str = 'systime')\n</code></pre> <p>Returns the earliest timestamp in the column.</p> Source code in <code>src/ts_shape/features/stats/timestamp_stats.py</code> <pre><code>@classmethod\ndef earliest_timestamp(cls, dataframe: pd.DataFrame, column_name: str = 'systime'):\n    \"\"\"Returns the earliest timestamp in the column.\"\"\"\n    return dataframe[column_name].min()\n</code></pre>"},{"location":"reference/ts_shape/features/stats/timestamp_stats/#ts_shape.features.stats.timestamp_stats.TimestampStatistics.get_dataframe","title":"get_dataframe","text":"<pre><code>get_dataframe() -&gt; DataFrame\n</code></pre> <p>Returns the processed DataFrame.</p> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def get_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"Returns the processed DataFrame.\"\"\"\n    return self.dataframe\n</code></pre>"},{"location":"reference/ts_shape/features/stats/timestamp_stats/#ts_shape.features.stats.timestamp_stats.TimestampStatistics.hour_distribution","title":"hour_distribution  <code>classmethod</code>","text":"<pre><code>hour_distribution(dataframe: DataFrame, column_name: str = 'systime') -&gt; Series\n</code></pre> <p>Returns the distribution of timestamps per hour of the day.</p> Source code in <code>src/ts_shape/features/stats/timestamp_stats.py</code> <pre><code>@classmethod\ndef hour_distribution(cls, dataframe: pd.DataFrame, column_name: str = 'systime') -&gt; pd.Series:\n    \"\"\"Returns the distribution of timestamps per hour of the day.\"\"\"\n    return dataframe[column_name].dt.hour.value_counts()\n</code></pre>"},{"location":"reference/ts_shape/features/stats/timestamp_stats/#ts_shape.features.stats.timestamp_stats.TimestampStatistics.latest_timestamp","title":"latest_timestamp  <code>classmethod</code>","text":"<pre><code>latest_timestamp(dataframe: DataFrame, column_name: str = 'systime')\n</code></pre> <p>Returns the latest timestamp in the column.</p> Source code in <code>src/ts_shape/features/stats/timestamp_stats.py</code> <pre><code>@classmethod\ndef latest_timestamp(cls, dataframe: pd.DataFrame, column_name: str = 'systime'):\n    \"\"\"Returns the latest timestamp in the column.\"\"\"\n    return dataframe[column_name].max()\n</code></pre>"},{"location":"reference/ts_shape/features/stats/timestamp_stats/#ts_shape.features.stats.timestamp_stats.TimestampStatistics.median_timestamp","title":"median_timestamp  <code>classmethod</code>","text":"<pre><code>median_timestamp(dataframe: DataFrame, column_name: str = 'systime')\n</code></pre> <p>Returns the median timestamp in the column.</p> Source code in <code>src/ts_shape/features/stats/timestamp_stats.py</code> <pre><code>@classmethod\ndef median_timestamp(cls, dataframe: pd.DataFrame, column_name: str = 'systime'):\n    \"\"\"Returns the median timestamp in the column.\"\"\"\n    return dataframe[column_name].median()\n</code></pre>"},{"location":"reference/ts_shape/features/stats/timestamp_stats/#ts_shape.features.stats.timestamp_stats.TimestampStatistics.month_distribution","title":"month_distribution  <code>classmethod</code>","text":"<pre><code>month_distribution(dataframe: DataFrame, column_name: str = 'systime') -&gt; Series\n</code></pre> <p>Returns the distribution of timestamps per month.</p> Source code in <code>src/ts_shape/features/stats/timestamp_stats.py</code> <pre><code>@classmethod\ndef month_distribution(cls, dataframe: pd.DataFrame, column_name: str = 'systime') -&gt; pd.Series:\n    \"\"\"Returns the distribution of timestamps per month.\"\"\"\n    return dataframe[column_name].dt.month.value_counts()\n</code></pre>"},{"location":"reference/ts_shape/features/stats/timestamp_stats/#ts_shape.features.stats.timestamp_stats.TimestampStatistics.most_frequent_day","title":"most_frequent_day  <code>classmethod</code>","text":"<pre><code>most_frequent_day(dataframe: DataFrame, column_name: str = 'systime') -&gt; int\n</code></pre> <p>Returns the most frequent day of the week (0=Monday, 6=Sunday).</p> Source code in <code>src/ts_shape/features/stats/timestamp_stats.py</code> <pre><code>@classmethod\ndef most_frequent_day(cls, dataframe: pd.DataFrame, column_name: str = 'systime') -&gt; int:\n    \"\"\"Returns the most frequent day of the week (0=Monday, 6=Sunday).\"\"\"\n    return dataframe[column_name].dt.weekday.mode().iloc[0]\n</code></pre>"},{"location":"reference/ts_shape/features/stats/timestamp_stats/#ts_shape.features.stats.timestamp_stats.TimestampStatistics.most_frequent_hour","title":"most_frequent_hour  <code>classmethod</code>","text":"<pre><code>most_frequent_hour(dataframe: DataFrame, column_name: str = 'systime') -&gt; int\n</code></pre> <p>Returns the most frequent hour of the day (0-23).</p> Source code in <code>src/ts_shape/features/stats/timestamp_stats.py</code> <pre><code>@classmethod\ndef most_frequent_hour(cls, dataframe: pd.DataFrame, column_name: str = 'systime') -&gt; int:\n    \"\"\"Returns the most frequent hour of the day (0-23).\"\"\"\n    return dataframe[column_name].dt.hour.mode().iloc[0]\n</code></pre>"},{"location":"reference/ts_shape/features/stats/timestamp_stats/#ts_shape.features.stats.timestamp_stats.TimestampStatistics.most_frequent_timestamp","title":"most_frequent_timestamp  <code>classmethod</code>","text":"<pre><code>most_frequent_timestamp(dataframe: DataFrame, column_name: str = 'systime')\n</code></pre> <p>Returns the most frequent timestamp in the column.</p> Source code in <code>src/ts_shape/features/stats/timestamp_stats.py</code> <pre><code>@classmethod\ndef most_frequent_timestamp(cls, dataframe: pd.DataFrame, column_name: str = 'systime'):\n    \"\"\"Returns the most frequent timestamp in the column.\"\"\"\n    return dataframe[column_name].mode().iloc[0]\n</code></pre>"},{"location":"reference/ts_shape/features/stats/timestamp_stats/#ts_shape.features.stats.timestamp_stats.TimestampStatistics.standard_deviation_timestamps","title":"standard_deviation_timestamps  <code>classmethod</code>","text":"<pre><code>standard_deviation_timestamps(dataframe: DataFrame, column_name: str = 'systime') -&gt; Timedelta\n</code></pre> <p>Returns the standard deviation of the time differences between consecutive timestamps.</p> Source code in <code>src/ts_shape/features/stats/timestamp_stats.py</code> <pre><code>@classmethod\ndef standard_deviation_timestamps(cls, dataframe: pd.DataFrame, column_name: str = 'systime') -&gt; pd.Timedelta:\n    \"\"\"Returns the standard deviation of the time differences between consecutive timestamps.\"\"\"\n    sorted_times = dataframe[column_name].dropna().sort_values()\n    time_deltas = sorted_times.diff().dropna()\n    return time_deltas.std()\n</code></pre>"},{"location":"reference/ts_shape/features/stats/timestamp_stats/#ts_shape.features.stats.timestamp_stats.TimestampStatistics.timestamp_quartiles","title":"timestamp_quartiles  <code>classmethod</code>","text":"<pre><code>timestamp_quartiles(dataframe: DataFrame, column_name: str = 'systime') -&gt; Series\n</code></pre> <p>Returns the 25th, 50th (median), and 75th percentiles of the timestamps.</p> Source code in <code>src/ts_shape/features/stats/timestamp_stats.py</code> <pre><code>@classmethod\ndef timestamp_quartiles(cls, dataframe: pd.DataFrame, column_name: str = 'systime') -&gt; pd.Series:\n    \"\"\"Returns the 25th, 50th (median), and 75th percentiles of the timestamps.\"\"\"\n    return dataframe[column_name].quantile([0.25, 0.5, 0.75])\n</code></pre>"},{"location":"reference/ts_shape/features/stats/timestamp_stats/#ts_shape.features.stats.timestamp_stats.TimestampStatistics.timestamp_range","title":"timestamp_range  <code>classmethod</code>","text":"<pre><code>timestamp_range(dataframe: DataFrame, column_name: str = 'systime')\n</code></pre> <p>Returns the time range (difference) between the earliest and latest timestamps.</p> Source code in <code>src/ts_shape/features/stats/timestamp_stats.py</code> <pre><code>@classmethod\ndef timestamp_range(cls, dataframe: pd.DataFrame, column_name: str = 'systime'):\n    \"\"\"Returns the time range (difference) between the earliest and latest timestamps.\"\"\"\n    return cls.latest_timestamp(dataframe, column_name) - cls.earliest_timestamp(dataframe, column_name)\n</code></pre>"},{"location":"reference/ts_shape/features/stats/timestamp_stats/#ts_shape.features.stats.timestamp_stats.TimestampStatistics.weekday_distribution","title":"weekday_distribution  <code>classmethod</code>","text":"<pre><code>weekday_distribution(dataframe: DataFrame, column_name: str = 'systime') -&gt; Series\n</code></pre> <p>Returns the distribution of timestamps per weekday.</p> Source code in <code>src/ts_shape/features/stats/timestamp_stats.py</code> <pre><code>@classmethod\ndef weekday_distribution(cls, dataframe: pd.DataFrame, column_name: str = 'systime') -&gt; pd.Series:\n    \"\"\"Returns the distribution of timestamps per weekday.\"\"\"\n    return dataframe[column_name].dt.weekday.value_counts()\n</code></pre>"},{"location":"reference/ts_shape/features/stats/timestamp_stats/#ts_shape.features.stats.timestamp_stats.TimestampStatistics.year_distribution","title":"year_distribution  <code>classmethod</code>","text":"<pre><code>year_distribution(dataframe: DataFrame, column_name: str = 'systime') -&gt; Series\n</code></pre> <p>Returns the distribution of timestamps per year.</p> Source code in <code>src/ts_shape/features/stats/timestamp_stats.py</code> <pre><code>@classmethod\ndef year_distribution(cls, dataframe: pd.DataFrame, column_name: str = 'systime') -&gt; pd.Series:\n    \"\"\"Returns the distribution of timestamps per year.\"\"\"\n    return dataframe[column_name].dt.year.value_counts()\n</code></pre>"},{"location":"reference/ts_shape/features/time_stats/__init__/","title":"init","text":""},{"location":"reference/ts_shape/features/time_stats/__init__/#ts_shape.features.time_stats","title":"time_stats","text":"<p>Modules:</p> <ul> <li> <code>time_stats_numeric</code>           \u2013            </li> </ul>"},{"location":"reference/ts_shape/features/time_stats/time_stats_numeric/","title":"time_stats_numeric","text":""},{"location":"reference/ts_shape/features/time_stats/time_stats_numeric/#ts_shape.features.time_stats.time_stats_numeric","title":"time_stats_numeric","text":"<p>Classes:</p> <ul> <li> <code>TimeGroupedStatistics</code>           \u2013            <p>A class for calculating time-grouped statistics on numeric data, with class methods to apply various statistical functions.</p> </li> </ul>"},{"location":"reference/ts_shape/features/time_stats/time_stats_numeric/#ts_shape.features.time_stats.time_stats_numeric.TimeGroupedStatistics","title":"TimeGroupedStatistics","text":"<pre><code>TimeGroupedStatistics(dataframe: DataFrame, column_name: str = 'systime')\n</code></pre> <p>               Bases: <code>Base</code></p> <p>A class for calculating time-grouped statistics on numeric data, with class methods to apply various statistical functions.</p> <p>Parameters:</p> <p>Methods:</p> <ul> <li> <code>calculate_custom_func</code>             \u2013              <p>Apply a custom aggregation function on the value column over the grouped time intervals.</p> </li> <li> <code>calculate_statistic</code>             \u2013              <p>Calculate a specified statistic on the value column over the grouped time intervals.</p> </li> <li> <code>calculate_statistics</code>             \u2013              <p>Calculate multiple specified statistics on the value column over the grouped time intervals.</p> </li> <li> <code>get_dataframe</code>             \u2013              <p>Returns the processed DataFrame.</p> </li> </ul> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def __init__(self, dataframe: pd.DataFrame, column_name: str = 'systime') -&gt; pd.DataFrame:\n    \"\"\"\n    Initializes the Base with a DataFrame, detects time columns, converts them to datetime,\n    and sorts the DataFrame by the specified column (or the detected time column if applicable).\n\n    Args:\n        dataframe (pd.DataFrame): The DataFrame to be processed.\n        column_name (str): The column to sort by. Default is 'systime'. If the column is not found or is not a time column, the class will attempt to detect other time columns.\n    \"\"\"\n    self.dataframe = dataframe.copy()\n\n    # Attempt to convert the specified column_name to datetime if it exists\n    if column_name in self.dataframe.columns:\n        self.dataframe[column_name] = pd.to_datetime(self.dataframe[column_name], errors='coerce')\n    else:\n        # If the column_name is not in the DataFrame, fallback to automatic time detection\n        time_columns = [col for col in self.dataframe.columns if 'time' in col.lower() or 'date' in col.lower()]\n\n        # Convert all detected time columns to datetime, if any\n        for col in time_columns:\n            self.dataframe[col] = pd.to_datetime(self.dataframe[col], errors='coerce')\n\n        # If any time columns are detected, sort by the first one; otherwise, do nothing\n        if time_columns:\n            column_name = time_columns[0]\n\n    # Sort by the datetime column (either specified or detected)\n    if column_name in self.dataframe.columns:\n        self.dataframe = self.dataframe.sort_values(by=column_name)\n</code></pre>"},{"location":"reference/ts_shape/features/time_stats/time_stats_numeric/#ts_shape.features.time_stats.time_stats_numeric.TimeGroupedStatistics(dataframe)","title":"<code>dataframe</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The DataFrame to be processed.</p>"},{"location":"reference/ts_shape/features/time_stats/time_stats_numeric/#ts_shape.features.time_stats.time_stats_numeric.TimeGroupedStatistics(column_name)","title":"<code>column_name</code>","text":"(<code>str</code>, default:                   <code>'systime'</code> )           \u2013            <p>The column to sort by. Default is 'systime'. If the column is not found or is not a time column, the class will attempt to detect other time columns.</p>"},{"location":"reference/ts_shape/features/time_stats/time_stats_numeric/#ts_shape.features.time_stats.time_stats_numeric.TimeGroupedStatistics.calculate_custom_func","title":"calculate_custom_func  <code>classmethod</code>","text":"<pre><code>calculate_custom_func(dataframe: DataFrame, time_column: str, value_column: str, freq: str, func) -&gt; DataFrame\n</code></pre> <p>Apply a custom aggregation function on the value column over the grouped time intervals.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: A DataFrame with the custom calculated statistics.</p> </li> </ul> Source code in <code>src/ts_shape/features/time_stats/time_stats_numeric.py</code> <pre><code>@classmethod\ndef calculate_custom_func(cls, dataframe: pd.DataFrame, time_column: str, value_column: str, freq: str, func) -&gt; pd.DataFrame:\n    \"\"\"\n    Apply a custom aggregation function on the value column over the grouped time intervals.\n\n    Args:\n        dataframe (pd.DataFrame): The DataFrame containing the data.\n        time_column (str): The name of the time column to group and sort by.\n        value_column (str): The name of the numeric column to calculate statistics on.\n        freq (str): Frequency string for time grouping (e.g., 'H' for hourly, 'D' for daily).\n        func (callable): Custom function to apply to each group.\n\n    Returns:\n        pd.DataFrame: A DataFrame with the custom calculated statistics.\n    \"\"\"\n    grouped_df = dataframe.set_index(time_column).resample(freq)\n    result = grouped_df[value_column].apply(func).to_frame('custom')\n    return result\n</code></pre>"},{"location":"reference/ts_shape/features/time_stats/time_stats_numeric/#ts_shape.features.time_stats.time_stats_numeric.TimeGroupedStatistics.calculate_custom_func(dataframe)","title":"<code>dataframe</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The DataFrame containing the data.</p>"},{"location":"reference/ts_shape/features/time_stats/time_stats_numeric/#ts_shape.features.time_stats.time_stats_numeric.TimeGroupedStatistics.calculate_custom_func(time_column)","title":"<code>time_column</code>","text":"(<code>str</code>)           \u2013            <p>The name of the time column to group and sort by.</p>"},{"location":"reference/ts_shape/features/time_stats/time_stats_numeric/#ts_shape.features.time_stats.time_stats_numeric.TimeGroupedStatistics.calculate_custom_func(value_column)","title":"<code>value_column</code>","text":"(<code>str</code>)           \u2013            <p>The name of the numeric column to calculate statistics on.</p>"},{"location":"reference/ts_shape/features/time_stats/time_stats_numeric/#ts_shape.features.time_stats.time_stats_numeric.TimeGroupedStatistics.calculate_custom_func(freq)","title":"<code>freq</code>","text":"(<code>str</code>)           \u2013            <p>Frequency string for time grouping (e.g., 'H' for hourly, 'D' for daily).</p>"},{"location":"reference/ts_shape/features/time_stats/time_stats_numeric/#ts_shape.features.time_stats.time_stats_numeric.TimeGroupedStatistics.calculate_custom_func(func)","title":"<code>func</code>","text":"(<code>callable</code>)           \u2013            <p>Custom function to apply to each group.</p>"},{"location":"reference/ts_shape/features/time_stats/time_stats_numeric/#ts_shape.features.time_stats.time_stats_numeric.TimeGroupedStatistics.calculate_statistic","title":"calculate_statistic  <code>classmethod</code>","text":"<pre><code>calculate_statistic(dataframe: DataFrame, time_column: str, value_column: str, freq: str, stat_method: str) -&gt; DataFrame\n</code></pre> <p>Calculate a specified statistic on the value column over the grouped time intervals.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: A DataFrame with the time intervals and the calculated statistics.</p> </li> </ul> Source code in <code>src/ts_shape/features/time_stats/time_stats_numeric.py</code> <pre><code>@classmethod\ndef calculate_statistic(cls, dataframe: pd.DataFrame, time_column: str, value_column: str, freq: str, stat_method: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Calculate a specified statistic on the value column over the grouped time intervals.\n\n    Args:\n        dataframe (pd.DataFrame): The DataFrame containing the data.\n        time_column (str): The name of the time column to group and sort by.\n        value_column (str): The name of the numeric column to calculate statistics on.\n        freq (str): Frequency string for time grouping (e.g., 'H' for hourly, 'D' for daily).\n        stat_method (str): The statistical method to apply ('mean', 'sum', 'min', 'max', 'diff', 'range').\n\n    Returns:\n        pd.DataFrame: A DataFrame with the time intervals and the calculated statistics.\n    \"\"\"\n    # Set the DataFrame index to the time column and resample to the specified frequency\n    grouped_df = dataframe.set_index(time_column).resample(freq)\n\n    # Select the calculation method\n    if stat_method == 'mean':\n        result = grouped_df[value_column].mean().to_frame('mean')\n    elif stat_method == 'sum':\n        result = grouped_df[value_column].sum().to_frame('sum')\n    elif stat_method == 'min':\n        result = grouped_df[value_column].min().to_frame('min')\n    elif stat_method == 'max':\n        result = grouped_df[value_column].max().to_frame('max')\n    elif stat_method == 'diff':\n        # Improved diff: last value - first value within each interval\n        result = (grouped_df[value_column].last() - grouped_df[value_column].first()).to_frame('difference')\n    elif stat_method == 'range':\n        # Range: max value - min value within each interval\n        result = (grouped_df[value_column].max() - grouped_df[value_column].min()).to_frame('range')\n    else:\n        raise ValueError(\"Invalid stat_method. Choose from 'mean', 'sum', 'min', 'max', 'diff', 'range'.\")\n\n    return result\n</code></pre>"},{"location":"reference/ts_shape/features/time_stats/time_stats_numeric/#ts_shape.features.time_stats.time_stats_numeric.TimeGroupedStatistics.calculate_statistic(dataframe)","title":"<code>dataframe</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The DataFrame containing the data.</p>"},{"location":"reference/ts_shape/features/time_stats/time_stats_numeric/#ts_shape.features.time_stats.time_stats_numeric.TimeGroupedStatistics.calculate_statistic(time_column)","title":"<code>time_column</code>","text":"(<code>str</code>)           \u2013            <p>The name of the time column to group and sort by.</p>"},{"location":"reference/ts_shape/features/time_stats/time_stats_numeric/#ts_shape.features.time_stats.time_stats_numeric.TimeGroupedStatistics.calculate_statistic(value_column)","title":"<code>value_column</code>","text":"(<code>str</code>)           \u2013            <p>The name of the numeric column to calculate statistics on.</p>"},{"location":"reference/ts_shape/features/time_stats/time_stats_numeric/#ts_shape.features.time_stats.time_stats_numeric.TimeGroupedStatistics.calculate_statistic(freq)","title":"<code>freq</code>","text":"(<code>str</code>)           \u2013            <p>Frequency string for time grouping (e.g., 'H' for hourly, 'D' for daily).</p>"},{"location":"reference/ts_shape/features/time_stats/time_stats_numeric/#ts_shape.features.time_stats.time_stats_numeric.TimeGroupedStatistics.calculate_statistic(stat_method)","title":"<code>stat_method</code>","text":"(<code>str</code>)           \u2013            <p>The statistical method to apply ('mean', 'sum', 'min', 'max', 'diff', 'range').</p>"},{"location":"reference/ts_shape/features/time_stats/time_stats_numeric/#ts_shape.features.time_stats.time_stats_numeric.TimeGroupedStatistics.calculate_statistics","title":"calculate_statistics  <code>classmethod</code>","text":"<pre><code>calculate_statistics(dataframe: DataFrame, time_column: str, value_column: str, freq: str, stat_methods: list) -&gt; DataFrame\n</code></pre> <p>Calculate multiple specified statistics on the value column over the grouped time intervals.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: A DataFrame with the time intervals and the calculated statistics for each method.</p> </li> </ul> Source code in <code>src/ts_shape/features/time_stats/time_stats_numeric.py</code> <pre><code>@classmethod\ndef calculate_statistics(cls, dataframe: pd.DataFrame, time_column: str, value_column: str, freq: str, stat_methods: list) -&gt; pd.DataFrame:\n    \"\"\"\n    Calculate multiple specified statistics on the value column over the grouped time intervals.\n\n    Args:\n        dataframe (pd.DataFrame): The DataFrame containing the data.\n        time_column (str): The name of the time column to group and sort by.\n        value_column (str): The name of the numeric column to calculate statistics on.\n        freq (str): Frequency string for time grouping (e.g., 'H' for hourly, 'D' for daily).\n        stat_methods (list): A list of statistical methods to apply (e.g., ['mean', 'sum', 'diff', 'range']).\n\n    Returns:\n        pd.DataFrame: A DataFrame with the time intervals and the calculated statistics for each method.\n    \"\"\"\n    # Initialize an empty DataFrame for combining results\n    result_df = pd.DataFrame()\n\n    # Calculate each requested statistic and join to the result DataFrame\n    for method in stat_methods:\n        stat_df = cls.calculate_statistic(dataframe, time_column, value_column, freq, method)\n        result_df = result_df.join(stat_df, how='outer')\n\n    return result_df\n</code></pre>"},{"location":"reference/ts_shape/features/time_stats/time_stats_numeric/#ts_shape.features.time_stats.time_stats_numeric.TimeGroupedStatistics.calculate_statistics(dataframe)","title":"<code>dataframe</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The DataFrame containing the data.</p>"},{"location":"reference/ts_shape/features/time_stats/time_stats_numeric/#ts_shape.features.time_stats.time_stats_numeric.TimeGroupedStatistics.calculate_statistics(time_column)","title":"<code>time_column</code>","text":"(<code>str</code>)           \u2013            <p>The name of the time column to group and sort by.</p>"},{"location":"reference/ts_shape/features/time_stats/time_stats_numeric/#ts_shape.features.time_stats.time_stats_numeric.TimeGroupedStatistics.calculate_statistics(value_column)","title":"<code>value_column</code>","text":"(<code>str</code>)           \u2013            <p>The name of the numeric column to calculate statistics on.</p>"},{"location":"reference/ts_shape/features/time_stats/time_stats_numeric/#ts_shape.features.time_stats.time_stats_numeric.TimeGroupedStatistics.calculate_statistics(freq)","title":"<code>freq</code>","text":"(<code>str</code>)           \u2013            <p>Frequency string for time grouping (e.g., 'H' for hourly, 'D' for daily).</p>"},{"location":"reference/ts_shape/features/time_stats/time_stats_numeric/#ts_shape.features.time_stats.time_stats_numeric.TimeGroupedStatistics.calculate_statistics(stat_methods)","title":"<code>stat_methods</code>","text":"(<code>list</code>)           \u2013            <p>A list of statistical methods to apply (e.g., ['mean', 'sum', 'diff', 'range']).</p>"},{"location":"reference/ts_shape/features/time_stats/time_stats_numeric/#ts_shape.features.time_stats.time_stats_numeric.TimeGroupedStatistics.get_dataframe","title":"get_dataframe","text":"<pre><code>get_dataframe() -&gt; DataFrame\n</code></pre> <p>Returns the processed DataFrame.</p> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def get_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"Returns the processed DataFrame.\"\"\"\n    return self.dataframe\n</code></pre>"},{"location":"reference/ts_shape/loader/__init__/","title":"init","text":""},{"location":"reference/ts_shape/loader/__init__/#ts_shape.loader","title":"loader","text":"<p>Modules:</p> <ul> <li> <code>combine</code>           \u2013            </li> <li> <code>metadata</code>           \u2013            </li> <li> <code>timeseries</code>           \u2013            </li> </ul>"},{"location":"reference/ts_shape/loader/combine/__init__/","title":"init","text":""},{"location":"reference/ts_shape/loader/combine/__init__/#ts_shape.loader.combine","title":"combine","text":"<p>Modules:</p> <ul> <li> <code>integrator</code>           \u2013            </li> </ul>"},{"location":"reference/ts_shape/loader/combine/integrator/","title":"integrator","text":""},{"location":"reference/ts_shape/loader/combine/integrator/#ts_shape.loader.combine.integrator","title":"integrator","text":"<p>Classes:</p> <ul> <li> <code>DataIntegratorHybrid</code>           \u2013            <p>A flexible utility class to integrate data from various sources, including:</p> </li> </ul>"},{"location":"reference/ts_shape/loader/combine/integrator/#ts_shape.loader.combine.integrator.DataIntegratorHybrid","title":"DataIntegratorHybrid","text":"<p>A flexible utility class to integrate data from various sources, including: - API instances (e.g., DatapointAPI) - Direct raw data (e.g., UUID list, metadata, timeseries DataFrame) - Hybrid approaches (combination of instances and raw data)</p> <p>Methods:</p> <ul> <li> <code>combine_data</code>             \u2013              <p>Combine timeseries and metadata from various sources.</p> </li> </ul>"},{"location":"reference/ts_shape/loader/combine/integrator/#ts_shape.loader.combine.integrator.DataIntegratorHybrid.combine_data","title":"combine_data  <code>classmethod</code>","text":"<pre><code>combine_data(timeseries_sources: Optional[List[Union[DataFrame, object]]] = None, metadata_sources: Optional[List[Union[DataFrame, object]]] = None, uuids: Optional[List[str]] = None, join_key: str = 'uuid', merge_how: str = 'left') -&gt; DataFrame\n</code></pre> <p>Combine timeseries and metadata from various sources.</p> <p>:param timeseries_sources: List of timeseries sources (DataFrame or instances with <code>fetch_data_as_dataframe</code>). :param metadata_sources: List of metadata sources (DataFrame or instances with <code>fetch_metadata</code>). :param uuids: Optional list of UUIDs to filter the combined data. :param join_key: Key column to use for merging, default is \"uuid\". :param merge_how: Merge strategy ('left', 'inner', etc.), default is \"left\". :return: A combined DataFrame.</p> Source code in <code>src/ts_shape/loader/combine/integrator.py</code> <pre><code>@classmethod\ndef combine_data(\n    cls,\n    timeseries_sources: Optional[List[Union[pd.DataFrame, object]]] = None,\n    metadata_sources: Optional[List[Union[pd.DataFrame, object]]] = None,\n    uuids: Optional[List[str]] = None,\n    join_key: str = \"uuid\",\n    merge_how: str = \"left\",\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Combine timeseries and metadata from various sources.\n\n    :param timeseries_sources: List of timeseries sources (DataFrame or instances with `fetch_data_as_dataframe`).\n    :param metadata_sources: List of metadata sources (DataFrame or instances with `fetch_metadata`).\n    :param uuids: Optional list of UUIDs to filter the combined data.\n    :param join_key: Key column to use for merging, default is \"uuid\".\n    :param merge_how: Merge strategy ('left', 'inner', etc.), default is \"left\".\n    :return: A combined DataFrame.\n    \"\"\"\n    # Retrieve and combine timeseries data\n    timeseries_data = cls._combine_timeseries(timeseries_sources, join_key)\n\n    if timeseries_data.empty:\n        print(\"No timeseries data found.\")\n        return pd.DataFrame()\n\n    # Retrieve and combine metadata\n    metadata = cls._combine_metadata(metadata_sources, join_key)\n\n    if metadata.empty:\n        print(\"No metadata found.\")\n        return timeseries_data\n\n    # Merge timeseries data with metadata\n    combined_data = pd.merge(timeseries_data, metadata, on=join_key, how=merge_how)\n\n    # Optionally filter the combined data by UUIDs\n    if uuids:\n        combined_data = combined_data[combined_data[join_key].isin(uuids)]\n\n    return combined_data\n</code></pre>"},{"location":"reference/ts_shape/loader/context/__init__/","title":"context","text":""},{"location":"reference/ts_shape/loader/context/__init__/#ts_shape.loader.context","title":"context","text":""},{"location":"reference/ts_shape/loader/metadata/__init__/","title":"init","text":""},{"location":"reference/ts_shape/loader/metadata/__init__/#ts_shape.loader.metadata","title":"metadata","text":"<p>Modules:</p> <ul> <li> <code>metadata_api_loader</code>           \u2013            </li> <li> <code>metadata_db_loader</code>           \u2013            </li> </ul>"},{"location":"reference/ts_shape/loader/metadata/metadata_api_loader/","title":"metadata_api_loader","text":""},{"location":"reference/ts_shape/loader/metadata/metadata_api_loader/#ts_shape.loader.metadata.metadata_api_loader","title":"metadata_api_loader","text":"<p>Classes:</p> <ul> <li> <code>DatapointAPI</code>           \u2013            <p>Class for accessing datapoints for multiple devices via an API.</p> </li> </ul>"},{"location":"reference/ts_shape/loader/metadata/metadata_api_loader/#ts_shape.loader.metadata.metadata_api_loader.DatapointAPI","title":"DatapointAPI","text":"<pre><code>DatapointAPI(device_names: List[str], base_url: str, api_token: str, output_path: str = 'data', required_uuid_list: List[str] = None, filter_enabled: bool = True)\n</code></pre> <p>Class for accessing datapoints for multiple devices via an API.</p> <p>:param device_names: List of device names to retrieve metadata for. :param base_url: Base URL of the API. :param api_token: API token for authentication. :param output_path: Directory to save the data points JSON files. :param required_uuid_list: Mixed list of UUIDs to filter the metadata across devices (optional). :param filter_enabled: Whether to filter metadata by \"enabled == True\" (default is True).</p> <p>Methods:</p> <ul> <li> <code>display_dataframe</code>             \u2013              <p>Print the metadata DataFrame for a specific device or all devices.</p> </li> <li> <code>get_all_metadata</code>             \u2013              <p>Return a dictionary of metadata for each device.</p> </li> <li> <code>get_all_uuids</code>             \u2013              <p>Return a dictionary of UUIDs for each device.</p> </li> </ul> Source code in <code>src/ts_shape/loader/metadata/metadata_api_loader.py</code> <pre><code>def __init__(self, device_names: List[str], base_url: str, api_token: str, output_path: str = \"data\", required_uuid_list: List[str] = None, filter_enabled: bool = True):\n    \"\"\"\n    Initialize the DatapointAPI class.\n\n    :param device_names: List of device names to retrieve metadata for.\n    :param base_url: Base URL of the API.\n    :param api_token: API token for authentication.\n    :param output_path: Directory to save the data points JSON files.\n    :param required_uuid_list: Mixed list of UUIDs to filter the metadata across devices (optional).\n    :param filter_enabled: Whether to filter metadata by \"enabled == True\" (default is True).\n    \"\"\"\n    self.device_names = device_names\n    self.base_url = base_url\n    self.api_token = api_token\n    self.output_path = output_path\n    self.required_uuid_list = required_uuid_list or []  # Defaults to an empty list if None\n    self.filter_enabled = filter_enabled\n    self.device_metadata: Dict[str, pd.DataFrame] = {}  # Store metadata for each device\n    self.device_uuids: Dict[str, List[str]] = {}  # Store UUIDs for each device\n    self._api_access()\n</code></pre>"},{"location":"reference/ts_shape/loader/metadata/metadata_api_loader/#ts_shape.loader.metadata.metadata_api_loader.DatapointAPI.display_dataframe","title":"display_dataframe","text":"<pre><code>display_dataframe(device_name: str = None) -&gt; None\n</code></pre> <p>Print the metadata DataFrame for a specific device or all devices.</p> <p>:param device_name: Name of the device to display metadata for (optional).                     If None, displays metadata for all devices.</p> Source code in <code>src/ts_shape/loader/metadata/metadata_api_loader.py</code> <pre><code>def display_dataframe(self, device_name: str = None) -&gt; None:\n    \"\"\"\n    Print the metadata DataFrame for a specific device or all devices.\n\n    :param device_name: Name of the device to display metadata for (optional).\n                        If None, displays metadata for all devices.\n    \"\"\"\n    if device_name:\n        # Display metadata for a specific device\n        if device_name in self.device_metadata:\n            print(f\"Metadata for device: {device_name}\")\n            print(self.device_metadata[device_name])\n        else:\n            print(f\"No metadata found for device: {device_name}\")\n    else:\n        # Display metadata for all devices\n        for device, metadata in self.device_metadata.items():\n            print(f\"\\nMetadata for device: {device}\")\n            print(metadata)\n</code></pre>"},{"location":"reference/ts_shape/loader/metadata/metadata_api_loader/#ts_shape.loader.metadata.metadata_api_loader.DatapointAPI.get_all_metadata","title":"get_all_metadata","text":"<pre><code>get_all_metadata() -&gt; Dict[str, List[Dict[str, str]]]\n</code></pre> <p>Return a dictionary of metadata for each device.</p> Source code in <code>src/ts_shape/loader/metadata/metadata_api_loader.py</code> <pre><code>def get_all_metadata(self) -&gt; Dict[str, List[Dict[str, str]]]:\n    \"\"\"Return a dictionary of metadata for each device.\"\"\"\n    return {device: metadata.to_dict(orient=\"records\") for device, metadata in self.device_metadata.items()}\n</code></pre>"},{"location":"reference/ts_shape/loader/metadata/metadata_api_loader/#ts_shape.loader.metadata.metadata_api_loader.DatapointAPI.get_all_uuids","title":"get_all_uuids","text":"<pre><code>get_all_uuids() -&gt; Dict[str, List[str]]\n</code></pre> <p>Return a dictionary of UUIDs for each device.</p> Source code in <code>src/ts_shape/loader/metadata/metadata_api_loader.py</code> <pre><code>def get_all_uuids(self) -&gt; Dict[str, List[str]]:\n    \"\"\"Return a dictionary of UUIDs for each device.\"\"\"\n    return self.device_uuids\n</code></pre>"},{"location":"reference/ts_shape/loader/metadata/metadata_db_loader/","title":"metadata_db_loader","text":""},{"location":"reference/ts_shape/loader/metadata/metadata_db_loader/#ts_shape.loader.metadata.metadata_db_loader","title":"metadata_db_loader","text":"<p>Classes:</p> <ul> <li> <code>DatapointDB</code>           \u2013            <p>Class for accessing datapoints via a database.</p> </li> </ul>"},{"location":"reference/ts_shape/loader/metadata/metadata_db_loader/#ts_shape.loader.metadata.metadata_db_loader.DatapointDB","title":"DatapointDB","text":"<pre><code>DatapointDB(device_names: List[str], db_user: str, db_pass: str, db_host: str, output_path: str = 'data', required_uuid_list: List[str] = None, filter_enabled: bool = True)\n</code></pre> <p>Class for accessing datapoints via a database.</p> <p>:param device_names: List of device names to retrieve metadata for. :param db_user: Database user. :param db_pass: Database password. :param db_host: Database host. :param output_path: Directory to save JSON files. :param required_uuid_list: List of UUIDs to filter the metadata (optional). :param filter_enabled: Whether to filter metadata by \"enabled == True\" and \"archived == False\" (default is True).</p> <p>Methods:</p> <ul> <li> <code>display_dataframe</code>             \u2013              <p>Display metadata as a DataFrame for a specific device or all devices.</p> </li> <li> <code>get_all_metadata</code>             \u2013              <p>Return a dictionary of metadata for each device.</p> </li> <li> <code>get_all_uuids</code>             \u2013              <p>Return a dictionary of UUIDs for each device.</p> </li> </ul> Source code in <code>src/ts_shape/loader/metadata/metadata_db_loader.py</code> <pre><code>def __init__(self, device_names: List[str], db_user: str, db_pass: str, db_host: str, output_path: str = \"data\", required_uuid_list: List[str] = None, filter_enabled: bool = True):\n    \"\"\"\n    Initialize the DatapointDB class.\n\n    :param device_names: List of device names to retrieve metadata for.\n    :param db_user: Database user.\n    :param db_pass: Database password.\n    :param db_host: Database host.\n    :param output_path: Directory to save JSON files.\n    :param required_uuid_list: List of UUIDs to filter the metadata (optional).\n    :param filter_enabled: Whether to filter metadata by \"enabled == True\" and \"archived == False\" (default is True).\n    \"\"\"\n    self.device_names = device_names\n    self.db_user = db_user\n    self.db_pass = db_pass\n    self.db_host = db_host\n    self.output_path = output_path\n    self.required_uuid_list = required_uuid_list or []\n    self.filter_enabled = filter_enabled\n    self.device_metadata: Dict[str, pd.DataFrame] = {}  # Store metadata for each device\n    self.device_uuids: Dict[str, List[str]] = {}  # Store UUIDs for each device\n    self._db_access()\n</code></pre>"},{"location":"reference/ts_shape/loader/metadata/metadata_db_loader/#ts_shape.loader.metadata.metadata_db_loader.DatapointDB.display_dataframe","title":"display_dataframe","text":"<pre><code>display_dataframe(device_name: str = None, aggregate: bool = False) -&gt; None\n</code></pre> <p>Display metadata as a DataFrame for a specific device or all devices.</p> <p>:param device_name: Name of the device to display metadata for (optional). :param aggregate: If True, combine metadata from all devices into a single DataFrame.</p> Source code in <code>src/ts_shape/loader/metadata/metadata_db_loader.py</code> <pre><code>def display_dataframe(self, device_name: str = None, aggregate: bool = False) -&gt; None:\n    \"\"\"\n    Display metadata as a DataFrame for a specific device or all devices.\n\n    :param device_name: Name of the device to display metadata for (optional).\n    :param aggregate: If True, combine metadata from all devices into a single DataFrame.\n    \"\"\"\n    if aggregate:\n        combined_df = pd.concat(self.device_metadata.values(), keys=self.device_metadata.keys())\n        print(\"Aggregated metadata for all devices:\")\n        print(combined_df)\n    elif device_name:\n        if device_name in self.device_metadata:\n            print(f\"Metadata for device: {device_name}\")\n            print(self.device_metadata[device_name])\n        else:\n            print(f\"No metadata found for device: {device_name}\")\n    else:\n        for device, metadata in self.device_metadata.items():\n            print(f\"\\nMetadata for device: {device}\")\n            print(metadata)\n</code></pre>"},{"location":"reference/ts_shape/loader/metadata/metadata_db_loader/#ts_shape.loader.metadata.metadata_db_loader.DatapointDB.get_all_metadata","title":"get_all_metadata","text":"<pre><code>get_all_metadata() -&gt; Dict[str, List[Dict[str, str]]]\n</code></pre> <p>Return a dictionary of metadata for each device.</p> Source code in <code>src/ts_shape/loader/metadata/metadata_db_loader.py</code> <pre><code>def get_all_metadata(self) -&gt; Dict[str, List[Dict[str, str]]]:\n    \"\"\"Return a dictionary of metadata for each device.\"\"\"\n    return {device: metadata.to_dict(orient=\"records\") for device, metadata in self.device_metadata.items()}\n</code></pre>"},{"location":"reference/ts_shape/loader/metadata/metadata_db_loader/#ts_shape.loader.metadata.metadata_db_loader.DatapointDB.get_all_uuids","title":"get_all_uuids","text":"<pre><code>get_all_uuids() -&gt; Dict[str, List[str]]\n</code></pre> <p>Return a dictionary of UUIDs for each device.</p> Source code in <code>src/ts_shape/loader/metadata/metadata_db_loader.py</code> <pre><code>def get_all_uuids(self) -&gt; Dict[str, List[str]]:\n    \"\"\"Return a dictionary of UUIDs for each device.\"\"\"\n    return self.device_uuids\n</code></pre>"},{"location":"reference/ts_shape/loader/timeseries/__init__/","title":"init","text":""},{"location":"reference/ts_shape/loader/timeseries/__init__/#ts_shape.loader.timeseries","title":"timeseries","text":"<p>Modules:</p> <ul> <li> <code>parquet_loader</code>           \u2013            </li> <li> <code>s3proxy_parquet_loader</code>           \u2013            </li> <li> <code>timescale_loader</code>           \u2013            </li> </ul>"},{"location":"reference/ts_shape/loader/timeseries/parquet_loader/","title":"parquet_loader","text":""},{"location":"reference/ts_shape/loader/timeseries/parquet_loader/#ts_shape.loader.timeseries.parquet_loader","title":"parquet_loader","text":"<p>Classes:</p> <ul> <li> <code>ParquetLoader</code>           \u2013            <p>This class provides class methods to load parquet files from a specified directory structure.</p> </li> </ul>"},{"location":"reference/ts_shape/loader/timeseries/parquet_loader/#ts_shape.loader.timeseries.parquet_loader.ParquetLoader","title":"ParquetLoader","text":"<pre><code>ParquetLoader(base_path: str)\n</code></pre> <p>This class provides class methods to load parquet files from a specified directory structure.</p> <p>Parameters:</p> <p>Methods:</p> <ul> <li> <code>load_all_files</code>             \u2013              <p>Loads all parquet files in the specified base directory into a single pandas DataFrame.</p> </li> <li> <code>load_by_time_range</code>             \u2013              <p>Loads parquet files that fall within a specified time range based on the directory structure.</p> </li> <li> <code>load_by_uuid_list</code>             \u2013              <p>Loads parquet files that match any UUID in the specified list.</p> </li> <li> <code>load_files_by_time_range_and_uuids</code>             \u2013              <p>Loads parquet files that fall within a specified time range and match any UUID in the list.</p> </li> </ul> Source code in <code>src/ts_shape/loader/timeseries/parquet_loader.py</code> <pre><code>def __init__(self, base_path: str):\n    \"\"\"\n    Initialize the ParquetLoader with the base directory path.\n\n    Args:\n        base_path (str): The base directory where parquet files are stored.\n    \"\"\"\n    self.base_path = Path(base_path)\n</code></pre>"},{"location":"reference/ts_shape/loader/timeseries/parquet_loader/#ts_shape.loader.timeseries.parquet_loader.ParquetLoader(base_path)","title":"<code>base_path</code>","text":"(<code>str</code>)           \u2013            <p>The base directory where parquet files are stored.</p>"},{"location":"reference/ts_shape/loader/timeseries/parquet_loader/#ts_shape.loader.timeseries.parquet_loader.ParquetLoader.load_all_files","title":"load_all_files  <code>classmethod</code>","text":"<pre><code>load_all_files(base_path: str) -&gt; DataFrame\n</code></pre> <p>Loads all parquet files in the specified base directory into a single pandas DataFrame.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: A DataFrame containing all the data from the parquet files.</p> </li> </ul> Source code in <code>src/ts_shape/loader/timeseries/parquet_loader.py</code> <pre><code>@classmethod\ndef load_all_files(cls, base_path: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Loads all parquet files in the specified base directory into a single pandas DataFrame.\n\n    Args:\n        base_path (str): The base directory where parquet files are stored.\n\n    Returns:\n        pd.DataFrame: A DataFrame containing all the data from the parquet files.\n    \"\"\"\n    # Convert base path to a Path object\n    base_path = Path(base_path)\n    # Get all parquet files in the directory\n    parquet_files = cls._get_parquet_files(base_path)\n    # Load all files into pandas DataFrames\n    dataframes = [pd.read_parquet(file) for file in parquet_files]\n\n    # Concatenate all DataFrames into a single DataFrame\n    return pd.concat(dataframes, ignore_index=True)\n</code></pre>"},{"location":"reference/ts_shape/loader/timeseries/parquet_loader/#ts_shape.loader.timeseries.parquet_loader.ParquetLoader.load_all_files(base_path)","title":"<code>base_path</code>","text":"(<code>str</code>)           \u2013            <p>The base directory where parquet files are stored.</p>"},{"location":"reference/ts_shape/loader/timeseries/parquet_loader/#ts_shape.loader.timeseries.parquet_loader.ParquetLoader.load_by_time_range","title":"load_by_time_range  <code>classmethod</code>","text":"<pre><code>load_by_time_range(base_path: str, start_time: Timestamp, end_time: Timestamp) -&gt; DataFrame\n</code></pre> <p>Loads parquet files that fall within a specified time range based on the directory structure.</p> <p>The directory structure is expected to be in the format YYYY/MM/DD/HH.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: A DataFrame containing the data from the parquet files within the time range.</p> </li> </ul> Source code in <code>src/ts_shape/loader/timeseries/parquet_loader.py</code> <pre><code>@classmethod\ndef load_by_time_range(cls, base_path: str, start_time: pd.Timestamp, end_time: pd.Timestamp) -&gt; pd.DataFrame:\n    \"\"\"\n    Loads parquet files that fall within a specified time range based on the directory structure.\n\n    The directory structure is expected to be in the format YYYY/MM/DD/HH.\n\n    Args:\n        base_path (str): The base directory where parquet files are stored.\n        start_time (pd.Timestamp): The start timestamp.\n        end_time (pd.Timestamp): The end timestamp.\n\n    Returns:\n        pd.DataFrame: A DataFrame containing the data from the parquet files within the time range.\n    \"\"\"\n    # Convert base path to a Path object\n    base_path = Path(base_path)\n    # Get all parquet files in the directory\n    parquet_files = cls._get_parquet_files(base_path)\n    valid_files = []\n\n    for file in parquet_files:\n        try:\n            # Extract the timestamp from the file's relative path\n            folder_parts = file.relative_to(base_path).parts[:4]  # Extract YYYY/MM/DD/HH parts\n            folder_time_str = \"/\".join(folder_parts)\n            file_time = pd.to_datetime(folder_time_str, format=\"%Y/%m/%d/%H\")\n\n            # Check if the file's timestamp falls within the specified time range\n            if start_time &lt;= file_time &lt;= end_time:\n                valid_files.append(file)\n        except ValueError:\n            # Skip files that do not follow the expected folder structure\n            continue\n\n    # Load all valid files into pandas DataFrames\n    dataframes = [pd.read_parquet(file) for file in valid_files]\n    return pd.concat(dataframes, ignore_index=True)\n</code></pre>"},{"location":"reference/ts_shape/loader/timeseries/parquet_loader/#ts_shape.loader.timeseries.parquet_loader.ParquetLoader.load_by_time_range(base_path)","title":"<code>base_path</code>","text":"(<code>str</code>)           \u2013            <p>The base directory where parquet files are stored.</p>"},{"location":"reference/ts_shape/loader/timeseries/parquet_loader/#ts_shape.loader.timeseries.parquet_loader.ParquetLoader.load_by_time_range(start_time)","title":"<code>start_time</code>","text":"(<code>Timestamp</code>)           \u2013            <p>The start timestamp.</p>"},{"location":"reference/ts_shape/loader/timeseries/parquet_loader/#ts_shape.loader.timeseries.parquet_loader.ParquetLoader.load_by_time_range(end_time)","title":"<code>end_time</code>","text":"(<code>Timestamp</code>)           \u2013            <p>The end timestamp.</p>"},{"location":"reference/ts_shape/loader/timeseries/parquet_loader/#ts_shape.loader.timeseries.parquet_loader.ParquetLoader.load_by_uuid_list","title":"load_by_uuid_list  <code>classmethod</code>","text":"<pre><code>load_by_uuid_list(base_path: str, uuid_list: list) -&gt; DataFrame\n</code></pre> <p>Loads parquet files that match any UUID in the specified list.</p> <p>The UUIDs are expected to be part of the file names.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: A DataFrame containing the data from the parquet files with matching UUIDs.</p> </li> </ul> Source code in <code>src/ts_shape/loader/timeseries/parquet_loader.py</code> <pre><code>@classmethod\ndef load_by_uuid_list(cls, base_path: str, uuid_list: list) -&gt; pd.DataFrame:\n    \"\"\"\n    Loads parquet files that match any UUID in the specified list.\n\n    The UUIDs are expected to be part of the file names.\n\n    Args:\n        base_path (str): The base directory where parquet files are stored.\n        uuid_list (list): A list of UUIDs to filter the files.\n\n    Returns:\n        pd.DataFrame: A DataFrame containing the data from the parquet files with matching UUIDs.\n    \"\"\"\n    # Convert base path to a Path object\n    base_path = Path(base_path)\n    # Get all parquet files in the directory\n    parquet_files = cls._get_parquet_files(base_path)\n    valid_files = []\n\n    for file in parquet_files:\n        # Extract the file name without extension\n        file_name = file.stem\n        # Check if the file name contains any of the UUIDs in the list\n        for uuid in uuid_list:\n            if uuid in file_name:\n                valid_files.append(file)\n                break  # Stop checking other UUIDs for this file\n\n    # Load all valid files into pandas DataFrames\n    dataframes = [pd.read_parquet(file) for file in valid_files]\n    return pd.concat(dataframes, ignore_index=True)\n</code></pre>"},{"location":"reference/ts_shape/loader/timeseries/parquet_loader/#ts_shape.loader.timeseries.parquet_loader.ParquetLoader.load_by_uuid_list(base_path)","title":"<code>base_path</code>","text":"(<code>str</code>)           \u2013            <p>The base directory where parquet files are stored.</p>"},{"location":"reference/ts_shape/loader/timeseries/parquet_loader/#ts_shape.loader.timeseries.parquet_loader.ParquetLoader.load_by_uuid_list(uuid_list)","title":"<code>uuid_list</code>","text":"(<code>list</code>)           \u2013            <p>A list of UUIDs to filter the files.</p>"},{"location":"reference/ts_shape/loader/timeseries/parquet_loader/#ts_shape.loader.timeseries.parquet_loader.ParquetLoader.load_files_by_time_range_and_uuids","title":"load_files_by_time_range_and_uuids  <code>classmethod</code>","text":"<pre><code>load_files_by_time_range_and_uuids(base_path: str, start_time: Timestamp, end_time: Timestamp, uuid_list: list) -&gt; DataFrame\n</code></pre> <p>Loads parquet files that fall within a specified time range and match any UUID in the list.</p> <p>The directory structure is expected to be in the format YYYY/MM/DD/HH, and UUIDs are part of the file names.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: A DataFrame containing the data from the parquet files that meet both criteria.</p> </li> </ul> Source code in <code>src/ts_shape/loader/timeseries/parquet_loader.py</code> <pre><code>@classmethod\ndef load_files_by_time_range_and_uuids(cls, base_path: str, start_time: pd.Timestamp, end_time: pd.Timestamp, uuid_list: list) -&gt; pd.DataFrame:\n    \"\"\"\n    Loads parquet files that fall within a specified time range and match any UUID in the list.\n\n    The directory structure is expected to be in the format YYYY/MM/DD/HH, and UUIDs are part of the file names.\n\n    Args:\n        base_path (str): The base directory where parquet files are stored.\n        start_time (pd.Timestamp): The start timestamp.\n        end_time (pd.Timestamp): The end timestamp.\n        uuid_list (list): A list of UUIDs to filter the files.\n\n    Returns:\n        pd.DataFrame: A DataFrame containing the data from the parquet files that meet both criteria.\n    \"\"\"\n    # Convert base path to a Path object\n    base_path = Path(base_path)\n    # Get all parquet files in the directory\n    parquet_files = cls._get_parquet_files(base_path)\n    valid_files = []\n\n    for file in parquet_files:\n        try:\n            # Extract the timestamp from the file's relative path\n            folder_parts = file.relative_to(base_path).parts[:4]  # Extract YYYY/MM/DD/HH parts\n            folder_time_str = \"/\".join(folder_parts)\n            file_time = pd.to_datetime(folder_time_str, format=\"%Y/%m/%d/%H\")\n\n            # Check if the file's timestamp falls within the specified time range\n            if start_time &lt;= file_time &lt;= end_time:\n                # Extract the file name without extension\n                file_name = file.stem\n                # Check if the file name contains any of the UUIDs in the list\n                for uuid in uuid_list:\n                    if uuid in file_name:\n                        valid_files.append(file)\n                        break  # Stop checking other UUIDs for this file\n        except ValueError:\n            # Skip files that do not follow the expected folder structure\n            continue\n\n    # Load all valid files into pandas DataFrames\n    dataframes = [pd.read_parquet(file) for file in valid_files]\n    return pd.concat(dataframes, ignore_index=True)\n</code></pre>"},{"location":"reference/ts_shape/loader/timeseries/parquet_loader/#ts_shape.loader.timeseries.parquet_loader.ParquetLoader.load_files_by_time_range_and_uuids(base_path)","title":"<code>base_path</code>","text":"(<code>str</code>)           \u2013            <p>The base directory where parquet files are stored.</p>"},{"location":"reference/ts_shape/loader/timeseries/parquet_loader/#ts_shape.loader.timeseries.parquet_loader.ParquetLoader.load_files_by_time_range_and_uuids(start_time)","title":"<code>start_time</code>","text":"(<code>Timestamp</code>)           \u2013            <p>The start timestamp.</p>"},{"location":"reference/ts_shape/loader/timeseries/parquet_loader/#ts_shape.loader.timeseries.parquet_loader.ParquetLoader.load_files_by_time_range_and_uuids(end_time)","title":"<code>end_time</code>","text":"(<code>Timestamp</code>)           \u2013            <p>The end timestamp.</p>"},{"location":"reference/ts_shape/loader/timeseries/parquet_loader/#ts_shape.loader.timeseries.parquet_loader.ParquetLoader.load_files_by_time_range_and_uuids(uuid_list)","title":"<code>uuid_list</code>","text":"(<code>list</code>)           \u2013            <p>A list of UUIDs to filter the files.</p>"},{"location":"reference/ts_shape/loader/timeseries/s3proxy_parquet_loader/","title":"s3proxy_parquet_loader","text":""},{"location":"reference/ts_shape/loader/timeseries/s3proxy_parquet_loader/#ts_shape.loader.timeseries.s3proxy_parquet_loader","title":"s3proxy_parquet_loader","text":"<p>Classes:</p> <ul> <li> <code>S3ProxyDataAccess</code>           \u2013            <p>A class to access timeseries data via an S3 proxy. This class retrieves </p> </li> </ul>"},{"location":"reference/ts_shape/loader/timeseries/s3proxy_parquet_loader/#ts_shape.loader.timeseries.s3proxy_parquet_loader.S3ProxyDataAccess","title":"S3ProxyDataAccess","text":"<pre><code>S3ProxyDataAccess(start_timestamp: str, end_timestamp: str, uuids: List[str], s3_config: Dict[str, str])\n</code></pre> <p>A class to access timeseries data via an S3 proxy. This class retrieves  data for specified UUIDs within a defined time range, with the option to  output data as Parquet files or as a single combined DataFrame.</p> <p>:param end_timestamp: End timestamp in \"Year-Month-Day Hour:Minute:Second\" format. :param uuids: List of UUIDs to retrieve data for. :param s3_config: Configuration dictionary for S3 connection.</p> <p>Methods:</p> <ul> <li> <code>fetch_data_as_dataframe</code>             \u2013              <p>Retrieves timeseries data from S3 and returns it as a single DataFrame.</p> </li> <li> <code>fetch_data_as_parquet</code>             \u2013              <p>Retrieves timeseries data from S3 and saves it as Parquet files.</p> </li> </ul> Source code in <code>src/ts_shape/loader/timeseries/s3proxy_parquet_loader.py</code> <pre><code>def __init__(self, start_timestamp: str, end_timestamp: str, uuids: List[str], s3_config: Dict[str, str]):\n    \"\"\"\n    Initialize the S3ProxyDataAccess object.\n    :param start_timestamp: Start timestamp in \"Year-Month-Day Hour:Minute:Second\" format.\n    :param end_timestamp: End timestamp in \"Year-Month-Day Hour:Minute:Second\" format.\n    :param uuids: List of UUIDs to retrieve data for.\n    :param s3_config: Configuration dictionary for S3 connection.\n    \"\"\"\n    self.start_timestamp = start_timestamp\n    self.end_timestamp = end_timestamp\n    self.uuids = uuids\n    self.s3_config = s3_config\n\n    # Establish connection to S3 using provided configuration\n    self.s3 = s3fs.S3FileSystem(\n        endpoint_url=s3_config[\"endpoint_url\"],\n        key=s3_config[\"key\"],\n        secret=s3_config[\"secret\"],\n        use_ssl=s3_config[\"use_ssl\"],\n        version_aware=s3_config[\"version_aware\"]\n    )\n    self.s3_path_base = s3_config[\"s3_path_base\"]\n</code></pre>"},{"location":"reference/ts_shape/loader/timeseries/s3proxy_parquet_loader/#ts_shape.loader.timeseries.s3proxy_parquet_loader.S3ProxyDataAccess.fetch_data_as_dataframe","title":"fetch_data_as_dataframe","text":"<pre><code>fetch_data_as_dataframe() -&gt; DataFrame\n</code></pre> <p>Retrieves timeseries data from S3 and returns it as a single DataFrame. :return: A combined DataFrame with data for all specified UUIDs and time slots.</p> Source code in <code>src/ts_shape/loader/timeseries/s3proxy_parquet_loader.py</code> <pre><code>def fetch_data_as_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"\n    Retrieves timeseries data from S3 and returns it as a single DataFrame.\n    :return: A combined DataFrame with data for all specified UUIDs and time slots.\n    \"\"\"\n    data_frames = [self._fetch_parquet(uuid, timeslot_dir) \n                   for timeslot_dir in self._generate_timeslot_paths()\n                   for uuid in set(self.uuids)]\n    return pd.concat([df for df in data_frames if df is not None], ignore_index=True) if data_frames else pd.DataFrame()\n</code></pre>"},{"location":"reference/ts_shape/loader/timeseries/s3proxy_parquet_loader/#ts_shape.loader.timeseries.s3proxy_parquet_loader.S3ProxyDataAccess.fetch_data_as_parquet","title":"fetch_data_as_parquet","text":"<pre><code>fetch_data_as_parquet(output_dir: str)\n</code></pre> <p>Retrieves timeseries data from S3 and saves it as Parquet files. Each file is saved in a directory structure of UUID/year/month/day/hour. :param output_dir: Base directory to save the Parquet files.</p> Source code in <code>src/ts_shape/loader/timeseries/s3proxy_parquet_loader.py</code> <pre><code>def fetch_data_as_parquet(self, output_dir: str):\n    \"\"\"\n    Retrieves timeseries data from S3 and saves it as Parquet files.\n    Each file is saved in a directory structure of UUID/year/month/day/hour.\n    :param output_dir: Base directory to save the Parquet files.\n    \"\"\"\n    for timeslot_dir in self._generate_timeslot_paths():\n        for uuid in set(self.uuids):\n            df = self._fetch_parquet(uuid, timeslot_dir)\n            if df is not None:\n                output_path = Path(output_dir, timeslot_dir)\n                output_path.mkdir(parents=True, exist_ok=True)\n                df.to_parquet(output_path / f\"{uuid}.parquet\")\n</code></pre>"},{"location":"reference/ts_shape/loader/timeseries/timescale_loader/","title":"timescale_loader","text":""},{"location":"reference/ts_shape/loader/timeseries/timescale_loader/#ts_shape.loader.timeseries.timescale_loader","title":"timescale_loader","text":"<p>Classes:</p> <ul> <li> <code>TimescaleDBDataAccess</code>           \u2013            </li> </ul>"},{"location":"reference/ts_shape/loader/timeseries/timescale_loader/#ts_shape.loader.timeseries.timescale_loader.TimescaleDBDataAccess","title":"TimescaleDBDataAccess","text":"<pre><code>TimescaleDBDataAccess(start_timestamp: str, end_timestamp: str, uuids: List[str], db_config: Dict[str, str])\n</code></pre> <p>Methods:</p> <ul> <li> <code>fetch_data_as_dataframe</code>             \u2013              <p>Retrieves timeseries data from TimescaleDB and returns it as a single DataFrame.</p> </li> </ul> Source code in <code>src/ts_shape/loader/timeseries/timescale_loader.py</code> <pre><code>def __init__(self, start_timestamp: str, end_timestamp: str, uuids: List[str], db_config: Dict[str, str]):\n    self.start_timestamp = start_timestamp\n    self.end_timestamp = end_timestamp\n    self.uuids = uuids\n    self.db_config = db_config\n    self.engine = create_engine(\n        f'postgresql+psycopg2://{db_config[\"db_user\"]}:{db_config[\"db_pass\"]}@{db_config[\"db_host\"]}/{db_config[\"db_name\"]}'\n    )\n</code></pre>"},{"location":"reference/ts_shape/loader/timeseries/timescale_loader/#ts_shape.loader.timeseries.timescale_loader.TimescaleDBDataAccess.fetch_data_as_dataframe","title":"fetch_data_as_dataframe","text":"<pre><code>fetch_data_as_dataframe() -&gt; DataFrame\n</code></pre> <p>Retrieves timeseries data from TimescaleDB and returns it as a single DataFrame. :return: A combined DataFrame with data for all specified UUIDs within the time range.</p> Source code in <code>src/ts_shape/loader/timeseries/timescale_loader.py</code> <pre><code>def fetch_data_as_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"\n    Retrieves timeseries data from TimescaleDB and returns it as a single DataFrame.\n    :return: A combined DataFrame with data for all specified UUIDs within the time range.\n    \"\"\"\n    df_list = [chunk for uuid in self.uuids for chunk in self._fetch_data(uuid)]\n    return pd.concat(df_list, ignore_index=True) if df_list else pd.DataFrame()\n</code></pre>"},{"location":"reference/ts_shape/transform/__init__/","title":"init","text":""},{"location":"reference/ts_shape/transform/__init__/#ts_shape.transform","title":"transform","text":"<p>Modules:</p> <ul> <li> <code>calculator</code>           \u2013            </li> <li> <code>filter</code>           \u2013            </li> <li> <code>functions</code>           \u2013            </li> <li> <code>time_functions</code>           \u2013            </li> </ul>"},{"location":"reference/ts_shape/transform/calculator/__init__/","title":"init","text":""},{"location":"reference/ts_shape/transform/calculator/__init__/#ts_shape.transform.calculator","title":"calculator","text":"<p>Modules:</p> <ul> <li> <code>numeric_calc</code>           \u2013            </li> </ul>"},{"location":"reference/ts_shape/transform/calculator/numeric_calc/","title":"numeric_calc","text":""},{"location":"reference/ts_shape/transform/calculator/numeric_calc/#ts_shape.transform.calculator.numeric_calc","title":"numeric_calc","text":"<p>Classes:</p> <ul> <li> <code>IntegerCalc</code>           \u2013            <p>Provides class methods for performing calculations on integer columns in a pandas DataFrame.</p> </li> </ul>"},{"location":"reference/ts_shape/transform/calculator/numeric_calc/#ts_shape.transform.calculator.numeric_calc.IntegerCalc","title":"IntegerCalc","text":"<pre><code>IntegerCalc(dataframe: DataFrame, column_name: str = 'systime')\n</code></pre> <p>               Bases: <code>Base</code></p> <p>Provides class methods for performing calculations on integer columns in a pandas DataFrame.</p> <p>Parameters:</p> <p>Methods:</p> <ul> <li> <code>calculate_with_fixed_factors</code>             \u2013              <p>Performs a calculation by multiplying with a factor and then adding an additional factor.</p> </li> <li> <code>divide_column</code>             \u2013              <p>Divides each value in the integer column by the given divisor.</p> </li> <li> <code>get_dataframe</code>             \u2013              <p>Returns the processed DataFrame.</p> </li> <li> <code>mod_column</code>             \u2013              <p>Performs a modulus operation on the integer column with a specified value.</p> </li> <li> <code>offset_column</code>             \u2013              <p>Offsets the integer column by the given value.</p> </li> <li> <code>power_column</code>             \u2013              <p>Raises each value in the integer column to the power of a specified value.</p> </li> <li> <code>scale_column</code>             \u2013              <p>Scales the integer column by the given factor.</p> </li> <li> <code>subtract_column</code>             \u2013              <p>Subtracts a given value from each element in the integer column.</p> </li> </ul> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def __init__(self, dataframe: pd.DataFrame, column_name: str = 'systime') -&gt; pd.DataFrame:\n    \"\"\"\n    Initializes the Base with a DataFrame, detects time columns, converts them to datetime,\n    and sorts the DataFrame by the specified column (or the detected time column if applicable).\n\n    Args:\n        dataframe (pd.DataFrame): The DataFrame to be processed.\n        column_name (str): The column to sort by. Default is 'systime'. If the column is not found or is not a time column, the class will attempt to detect other time columns.\n    \"\"\"\n    self.dataframe = dataframe.copy()\n\n    # Attempt to convert the specified column_name to datetime if it exists\n    if column_name in self.dataframe.columns:\n        self.dataframe[column_name] = pd.to_datetime(self.dataframe[column_name], errors='coerce')\n    else:\n        # If the column_name is not in the DataFrame, fallback to automatic time detection\n        time_columns = [col for col in self.dataframe.columns if 'time' in col.lower() or 'date' in col.lower()]\n\n        # Convert all detected time columns to datetime, if any\n        for col in time_columns:\n            self.dataframe[col] = pd.to_datetime(self.dataframe[col], errors='coerce')\n\n        # If any time columns are detected, sort by the first one; otherwise, do nothing\n        if time_columns:\n            column_name = time_columns[0]\n\n    # Sort by the datetime column (either specified or detected)\n    if column_name in self.dataframe.columns:\n        self.dataframe = self.dataframe.sort_values(by=column_name)\n</code></pre>"},{"location":"reference/ts_shape/transform/calculator/numeric_calc/#ts_shape.transform.calculator.numeric_calc.IntegerCalc(dataframe)","title":"<code>dataframe</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The DataFrame to be processed.</p>"},{"location":"reference/ts_shape/transform/calculator/numeric_calc/#ts_shape.transform.calculator.numeric_calc.IntegerCalc(column_name)","title":"<code>column_name</code>","text":"(<code>str</code>, default:                   <code>'systime'</code> )           \u2013            <p>The column to sort by. Default is 'systime'. If the column is not found or is not a time column, the class will attempt to detect other time columns.</p>"},{"location":"reference/ts_shape/transform/calculator/numeric_calc/#ts_shape.transform.calculator.numeric_calc.IntegerCalc.calculate_with_fixed_factors","title":"calculate_with_fixed_factors  <code>classmethod</code>","text":"<pre><code>calculate_with_fixed_factors(dataframe: DataFrame, column_name: str = 'value_integer', multiply_factor: float = 1, add_factor: float = 0) -&gt; DataFrame\n</code></pre> <p>Performs a calculation by multiplying with a factor and then adding an additional factor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: The DataFrame after applying the calculations.</p> </li> </ul> Source code in <code>src/ts_shape/transform/calculator/numeric_calc.py</code> <pre><code>@classmethod\ndef calculate_with_fixed_factors(cls, dataframe: pd.DataFrame, column_name: str = 'value_integer', multiply_factor: float = 1, add_factor: float = 0) -&gt; pd.DataFrame:\n    \"\"\"\n    Performs a calculation by multiplying with a factor and then adding an additional factor.\n\n    Args:\n        dataframe (pd.DataFrame): The DataFrame to perform the operation on.\n        column_name (str): The column to apply the calculations to.\n        multiply_factor (float): The factor to multiply each value by. Defaults to 1 (no scaling).\n        add_factor (float): The value to add after multiplication. Defaults to 0 (no offset).\n\n    Returns:\n        pd.DataFrame: The DataFrame after applying the calculations.\n    \"\"\"\n    dataframe[column_name] = (dataframe[column_name] * multiply_factor) + add_factor\n    return dataframe\n</code></pre>"},{"location":"reference/ts_shape/transform/calculator/numeric_calc/#ts_shape.transform.calculator.numeric_calc.IntegerCalc.calculate_with_fixed_factors(dataframe)","title":"<code>dataframe</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The DataFrame to perform the operation on.</p>"},{"location":"reference/ts_shape/transform/calculator/numeric_calc/#ts_shape.transform.calculator.numeric_calc.IntegerCalc.calculate_with_fixed_factors(column_name)","title":"<code>column_name</code>","text":"(<code>str</code>, default:                   <code>'value_integer'</code> )           \u2013            <p>The column to apply the calculations to.</p>"},{"location":"reference/ts_shape/transform/calculator/numeric_calc/#ts_shape.transform.calculator.numeric_calc.IntegerCalc.calculate_with_fixed_factors(multiply_factor)","title":"<code>multiply_factor</code>","text":"(<code>float</code>, default:                   <code>1</code> )           \u2013            <p>The factor to multiply each value by. Defaults to 1 (no scaling).</p>"},{"location":"reference/ts_shape/transform/calculator/numeric_calc/#ts_shape.transform.calculator.numeric_calc.IntegerCalc.calculate_with_fixed_factors(add_factor)","title":"<code>add_factor</code>","text":"(<code>float</code>, default:                   <code>0</code> )           \u2013            <p>The value to add after multiplication. Defaults to 0 (no offset).</p>"},{"location":"reference/ts_shape/transform/calculator/numeric_calc/#ts_shape.transform.calculator.numeric_calc.IntegerCalc.divide_column","title":"divide_column  <code>classmethod</code>","text":"<pre><code>divide_column(dataframe: DataFrame, column_name: str = 'value_integer', divisor: float = 1) -&gt; DataFrame\n</code></pre> <p>Divides each value in the integer column by the given divisor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: The DataFrame with the divided column.</p> </li> </ul> Source code in <code>src/ts_shape/transform/calculator/numeric_calc.py</code> <pre><code>@classmethod\ndef divide_column(cls, dataframe: pd.DataFrame, column_name: str = 'value_integer', divisor: float = 1) -&gt; pd.DataFrame:\n    \"\"\"\n    Divides each value in the integer column by the given divisor.\n\n    Args:\n        dataframe (pd.DataFrame): The DataFrame to perform the operation on.\n        column_name (str): The column to apply the division to.\n        divisor (float): The value by which to divide each element.\n\n    Returns:\n        pd.DataFrame: The DataFrame with the divided column.\n    \"\"\"\n    dataframe[column_name] = dataframe[column_name] / divisor\n    return dataframe\n</code></pre>"},{"location":"reference/ts_shape/transform/calculator/numeric_calc/#ts_shape.transform.calculator.numeric_calc.IntegerCalc.divide_column(dataframe)","title":"<code>dataframe</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The DataFrame to perform the operation on.</p>"},{"location":"reference/ts_shape/transform/calculator/numeric_calc/#ts_shape.transform.calculator.numeric_calc.IntegerCalc.divide_column(column_name)","title":"<code>column_name</code>","text":"(<code>str</code>, default:                   <code>'value_integer'</code> )           \u2013            <p>The column to apply the division to.</p>"},{"location":"reference/ts_shape/transform/calculator/numeric_calc/#ts_shape.transform.calculator.numeric_calc.IntegerCalc.divide_column(divisor)","title":"<code>divisor</code>","text":"(<code>float</code>, default:                   <code>1</code> )           \u2013            <p>The value by which to divide each element.</p>"},{"location":"reference/ts_shape/transform/calculator/numeric_calc/#ts_shape.transform.calculator.numeric_calc.IntegerCalc.get_dataframe","title":"get_dataframe","text":"<pre><code>get_dataframe() -&gt; DataFrame\n</code></pre> <p>Returns the processed DataFrame.</p> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def get_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"Returns the processed DataFrame.\"\"\"\n    return self.dataframe\n</code></pre>"},{"location":"reference/ts_shape/transform/calculator/numeric_calc/#ts_shape.transform.calculator.numeric_calc.IntegerCalc.mod_column","title":"mod_column  <code>classmethod</code>","text":"<pre><code>mod_column(dataframe: DataFrame, column_name: str = 'value_integer', mod_value: int = 1) -&gt; DataFrame\n</code></pre> <p>Performs a modulus operation on the integer column with a specified value.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: The DataFrame with the modulus operation applied.</p> </li> </ul> Source code in <code>src/ts_shape/transform/calculator/numeric_calc.py</code> <pre><code>@classmethod\ndef mod_column(cls, dataframe: pd.DataFrame, column_name: str = 'value_integer', mod_value: int = 1) -&gt; pd.DataFrame:\n    \"\"\"\n    Performs a modulus operation on the integer column with a specified value.\n\n    Args:\n        dataframe (pd.DataFrame): The DataFrame to perform the operation on.\n        column_name (str): The column to apply the modulus operation to.\n        mod_value (int): The value to perform the modulus operation with.\n\n    Returns:\n        pd.DataFrame: The DataFrame with the modulus operation applied.\n    \"\"\"\n    dataframe[column_name] = dataframe[column_name] % mod_value\n    return dataframe\n</code></pre>"},{"location":"reference/ts_shape/transform/calculator/numeric_calc/#ts_shape.transform.calculator.numeric_calc.IntegerCalc.mod_column(dataframe)","title":"<code>dataframe</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The DataFrame to perform the operation on.</p>"},{"location":"reference/ts_shape/transform/calculator/numeric_calc/#ts_shape.transform.calculator.numeric_calc.IntegerCalc.mod_column(column_name)","title":"<code>column_name</code>","text":"(<code>str</code>, default:                   <code>'value_integer'</code> )           \u2013            <p>The column to apply the modulus operation to.</p>"},{"location":"reference/ts_shape/transform/calculator/numeric_calc/#ts_shape.transform.calculator.numeric_calc.IntegerCalc.mod_column(mod_value)","title":"<code>mod_value</code>","text":"(<code>int</code>, default:                   <code>1</code> )           \u2013            <p>The value to perform the modulus operation with.</p>"},{"location":"reference/ts_shape/transform/calculator/numeric_calc/#ts_shape.transform.calculator.numeric_calc.IntegerCalc.offset_column","title":"offset_column  <code>classmethod</code>","text":"<pre><code>offset_column(dataframe: DataFrame, column_name: str = 'value_integer', offset_value: float = 0) -&gt; DataFrame\n</code></pre> <p>Offsets the integer column by the given value.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: The DataFrame with the offset column.</p> </li> </ul> Source code in <code>src/ts_shape/transform/calculator/numeric_calc.py</code> <pre><code>@classmethod\ndef offset_column(cls, dataframe: pd.DataFrame, column_name: str = 'value_integer', offset_value: float = 0) -&gt; pd.DataFrame:\n    \"\"\"\n    Offsets the integer column by the given value.\n\n    Args:\n        dataframe (pd.DataFrame): The DataFrame to perform the operation on.\n        column_name (str): The column to apply the offset to.\n        offset_value (float): The value to add (positive) or subtract (negative) from each element in the column.\n\n    Returns:\n        pd.DataFrame: The DataFrame with the offset column.\n    \"\"\"\n    dataframe[column_name] = dataframe[column_name] + offset_value\n    return dataframe\n</code></pre>"},{"location":"reference/ts_shape/transform/calculator/numeric_calc/#ts_shape.transform.calculator.numeric_calc.IntegerCalc.offset_column(dataframe)","title":"<code>dataframe</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The DataFrame to perform the operation on.</p>"},{"location":"reference/ts_shape/transform/calculator/numeric_calc/#ts_shape.transform.calculator.numeric_calc.IntegerCalc.offset_column(column_name)","title":"<code>column_name</code>","text":"(<code>str</code>, default:                   <code>'value_integer'</code> )           \u2013            <p>The column to apply the offset to.</p>"},{"location":"reference/ts_shape/transform/calculator/numeric_calc/#ts_shape.transform.calculator.numeric_calc.IntegerCalc.offset_column(offset_value)","title":"<code>offset_value</code>","text":"(<code>float</code>, default:                   <code>0</code> )           \u2013            <p>The value to add (positive) or subtract (negative) from each element in the column.</p>"},{"location":"reference/ts_shape/transform/calculator/numeric_calc/#ts_shape.transform.calculator.numeric_calc.IntegerCalc.power_column","title":"power_column  <code>classmethod</code>","text":"<pre><code>power_column(dataframe: DataFrame, column_name: str = 'value_integer', power_value: float = 1) -&gt; DataFrame\n</code></pre> <p>Raises each value in the integer column to the power of a specified value.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: The DataFrame with the power operation applied.</p> </li> </ul> Source code in <code>src/ts_shape/transform/calculator/numeric_calc.py</code> <pre><code>@classmethod\ndef power_column(cls, dataframe: pd.DataFrame, column_name: str = 'value_integer', power_value: float = 1) -&gt; pd.DataFrame:\n    \"\"\"\n    Raises each value in the integer column to the power of a specified value.\n\n    Args:\n        dataframe (pd.DataFrame): The DataFrame to perform the operation on.\n        column_name (str): The column to apply the power operation to.\n        power_value (float): The exponent to raise each element to.\n\n    Returns:\n        pd.DataFrame: The DataFrame with the power operation applied.\n    \"\"\"\n    dataframe[column_name] = dataframe[column_name] ** power_value\n    return dataframe\n</code></pre>"},{"location":"reference/ts_shape/transform/calculator/numeric_calc/#ts_shape.transform.calculator.numeric_calc.IntegerCalc.power_column(dataframe)","title":"<code>dataframe</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The DataFrame to perform the operation on.</p>"},{"location":"reference/ts_shape/transform/calculator/numeric_calc/#ts_shape.transform.calculator.numeric_calc.IntegerCalc.power_column(column_name)","title":"<code>column_name</code>","text":"(<code>str</code>, default:                   <code>'value_integer'</code> )           \u2013            <p>The column to apply the power operation to.</p>"},{"location":"reference/ts_shape/transform/calculator/numeric_calc/#ts_shape.transform.calculator.numeric_calc.IntegerCalc.power_column(power_value)","title":"<code>power_value</code>","text":"(<code>float</code>, default:                   <code>1</code> )           \u2013            <p>The exponent to raise each element to.</p>"},{"location":"reference/ts_shape/transform/calculator/numeric_calc/#ts_shape.transform.calculator.numeric_calc.IntegerCalc.scale_column","title":"scale_column  <code>classmethod</code>","text":"<pre><code>scale_column(dataframe: DataFrame, column_name: str = 'value_integer', factor: float = 1) -&gt; DataFrame\n</code></pre> <p>Scales the integer column by the given factor.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: The DataFrame with the scaled column.</p> </li> </ul> Source code in <code>src/ts_shape/transform/calculator/numeric_calc.py</code> <pre><code>@classmethod\ndef scale_column(cls, dataframe: pd.DataFrame, column_name: str = 'value_integer', factor: float = 1) -&gt; pd.DataFrame:\n    \"\"\"\n    Scales the integer column by the given factor.\n\n    Args:\n        dataframe (pd.DataFrame): The DataFrame to perform the operation on.\n        column_name (str): The column to apply the scaling to.\n        factor (float): The scaling factor.\n\n    Returns:\n        pd.DataFrame: The DataFrame with the scaled column.\n    \"\"\"\n    dataframe[column_name] = dataframe[column_name] * factor\n    return dataframe\n</code></pre>"},{"location":"reference/ts_shape/transform/calculator/numeric_calc/#ts_shape.transform.calculator.numeric_calc.IntegerCalc.scale_column(dataframe)","title":"<code>dataframe</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The DataFrame to perform the operation on.</p>"},{"location":"reference/ts_shape/transform/calculator/numeric_calc/#ts_shape.transform.calculator.numeric_calc.IntegerCalc.scale_column(column_name)","title":"<code>column_name</code>","text":"(<code>str</code>, default:                   <code>'value_integer'</code> )           \u2013            <p>The column to apply the scaling to.</p>"},{"location":"reference/ts_shape/transform/calculator/numeric_calc/#ts_shape.transform.calculator.numeric_calc.IntegerCalc.scale_column(factor)","title":"<code>factor</code>","text":"(<code>float</code>, default:                   <code>1</code> )           \u2013            <p>The scaling factor.</p>"},{"location":"reference/ts_shape/transform/calculator/numeric_calc/#ts_shape.transform.calculator.numeric_calc.IntegerCalc.subtract_column","title":"subtract_column  <code>classmethod</code>","text":"<pre><code>subtract_column(dataframe: DataFrame, column_name: str = 'value_integer', subtract_value: float = 0) -&gt; DataFrame\n</code></pre> <p>Subtracts a given value from each element in the integer column.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: The DataFrame with the subtracted column.</p> </li> </ul> Source code in <code>src/ts_shape/transform/calculator/numeric_calc.py</code> <pre><code>@classmethod\ndef subtract_column(cls, dataframe: pd.DataFrame, column_name: str = 'value_integer', subtract_value: float = 0) -&gt; pd.DataFrame:\n    \"\"\"\n    Subtracts a given value from each element in the integer column.\n\n    Args:\n        dataframe (pd.DataFrame): The DataFrame to perform the operation on.\n        column_name (str): The column to apply the subtraction to.\n        subtract_value (float): The value to subtract from each element.\n\n    Returns:\n        pd.DataFrame: The DataFrame with the subtracted column.\n    \"\"\"\n    dataframe[column_name] = dataframe[column_name] - subtract_value\n    return dataframe\n</code></pre>"},{"location":"reference/ts_shape/transform/calculator/numeric_calc/#ts_shape.transform.calculator.numeric_calc.IntegerCalc.subtract_column(dataframe)","title":"<code>dataframe</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The DataFrame to perform the operation on.</p>"},{"location":"reference/ts_shape/transform/calculator/numeric_calc/#ts_shape.transform.calculator.numeric_calc.IntegerCalc.subtract_column(column_name)","title":"<code>column_name</code>","text":"(<code>str</code>, default:                   <code>'value_integer'</code> )           \u2013            <p>The column to apply the subtraction to.</p>"},{"location":"reference/ts_shape/transform/calculator/numeric_calc/#ts_shape.transform.calculator.numeric_calc.IntegerCalc.subtract_column(subtract_value)","title":"<code>subtract_value</code>","text":"(<code>float</code>, default:                   <code>0</code> )           \u2013            <p>The value to subtract from each element.</p>"},{"location":"reference/ts_shape/transform/filter/__init__/","title":"init","text":""},{"location":"reference/ts_shape/transform/filter/__init__/#ts_shape.transform.filter","title":"filter","text":"<p>Modules:</p> <ul> <li> <code>boolean_filter</code>           \u2013            </li> <li> <code>custom_filter</code>           \u2013            </li> <li> <code>datetime_filter</code>           \u2013            </li> <li> <code>numeric_filter</code>           \u2013            </li> <li> <code>string_filter</code>           \u2013            </li> </ul>"},{"location":"reference/ts_shape/transform/filter/boolean_filter/","title":"boolean_filter","text":""},{"location":"reference/ts_shape/transform/filter/boolean_filter/#ts_shape.transform.filter.boolean_filter","title":"boolean_filter","text":"<p>Classes:</p> <ul> <li> <code>BooleanFilter</code>           \u2013            <p>Provides class methods for filtering boolean columns in a pandas DataFrame,</p> </li> <li> <code>IsDeltaFilter</code>           \u2013            <p>Provides class methods for filtering is_delta columns in a pandas DataFrame.</p> </li> </ul>"},{"location":"reference/ts_shape/transform/filter/boolean_filter/#ts_shape.transform.filter.boolean_filter.BooleanFilter","title":"BooleanFilter","text":"<pre><code>BooleanFilter(dataframe: DataFrame, column_name: str = 'systime')\n</code></pre> <p>               Bases: <code>Base</code></p> <p>Provides class methods for filtering boolean columns in a pandas DataFrame, particularly focusing on status changes.</p> <p>Parameters:</p> <p>Methods:</p> <ul> <li> <code>filter_falling_value_bool</code>             \u2013              <p>Filters rows where 'value_bool' changes from True to False.</p> </li> <li> <code>filter_raising_value_bool</code>             \u2013              <p>Filters rows where 'value_bool' changes from False to True.</p> </li> <li> <code>get_dataframe</code>             \u2013              <p>Returns the processed DataFrame.</p> </li> </ul> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def __init__(self, dataframe: pd.DataFrame, column_name: str = 'systime') -&gt; pd.DataFrame:\n    \"\"\"\n    Initializes the Base with a DataFrame, detects time columns, converts them to datetime,\n    and sorts the DataFrame by the specified column (or the detected time column if applicable).\n\n    Args:\n        dataframe (pd.DataFrame): The DataFrame to be processed.\n        column_name (str): The column to sort by. Default is 'systime'. If the column is not found or is not a time column, the class will attempt to detect other time columns.\n    \"\"\"\n    self.dataframe = dataframe.copy()\n\n    # Attempt to convert the specified column_name to datetime if it exists\n    if column_name in self.dataframe.columns:\n        self.dataframe[column_name] = pd.to_datetime(self.dataframe[column_name], errors='coerce')\n    else:\n        # If the column_name is not in the DataFrame, fallback to automatic time detection\n        time_columns = [col for col in self.dataframe.columns if 'time' in col.lower() or 'date' in col.lower()]\n\n        # Convert all detected time columns to datetime, if any\n        for col in time_columns:\n            self.dataframe[col] = pd.to_datetime(self.dataframe[col], errors='coerce')\n\n        # If any time columns are detected, sort by the first one; otherwise, do nothing\n        if time_columns:\n            column_name = time_columns[0]\n\n    # Sort by the datetime column (either specified or detected)\n    if column_name in self.dataframe.columns:\n        self.dataframe = self.dataframe.sort_values(by=column_name)\n</code></pre>"},{"location":"reference/ts_shape/transform/filter/boolean_filter/#ts_shape.transform.filter.boolean_filter.BooleanFilter(dataframe)","title":"<code>dataframe</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The DataFrame to be processed.</p>"},{"location":"reference/ts_shape/transform/filter/boolean_filter/#ts_shape.transform.filter.boolean_filter.BooleanFilter(column_name)","title":"<code>column_name</code>","text":"(<code>str</code>, default:                   <code>'systime'</code> )           \u2013            <p>The column to sort by. Default is 'systime'. If the column is not found or is not a time column, the class will attempt to detect other time columns.</p>"},{"location":"reference/ts_shape/transform/filter/boolean_filter/#ts_shape.transform.filter.boolean_filter.BooleanFilter.filter_falling_value_bool","title":"filter_falling_value_bool  <code>classmethod</code>","text":"<pre><code>filter_falling_value_bool(dataframe: DataFrame, column_name: str = 'value_bool') -&gt; DataFrame\n</code></pre> <p>Filters rows where 'value_bool' changes from True to False.</p> Source code in <code>src/ts_shape/transform/filter/boolean_filter.py</code> <pre><code>@classmethod\ndef filter_falling_value_bool(cls, dataframe: pd.DataFrame, column_name: str = 'value_bool') -&gt; pd.DataFrame:\n    \"\"\"Filters rows where 'value_bool' changes from True to False.\"\"\"\n    dataframe['previous_value_bool'] = dataframe[column_name].shift(1)\n    return dataframe[(dataframe['previous_value_bool'] == True) &amp; (dataframe[column_name] == False)]\n</code></pre>"},{"location":"reference/ts_shape/transform/filter/boolean_filter/#ts_shape.transform.filter.boolean_filter.BooleanFilter.filter_raising_value_bool","title":"filter_raising_value_bool  <code>classmethod</code>","text":"<pre><code>filter_raising_value_bool(dataframe: DataFrame, column_name: str = 'value_bool') -&gt; DataFrame\n</code></pre> <p>Filters rows where 'value_bool' changes from False to True.</p> Source code in <code>src/ts_shape/transform/filter/boolean_filter.py</code> <pre><code>@classmethod\ndef filter_raising_value_bool(cls, dataframe: pd.DataFrame, column_name: str = 'value_bool') -&gt; pd.DataFrame:\n    \"\"\"Filters rows where 'value_bool' changes from False to True.\"\"\"\n    dataframe['previous_value_bool'] = dataframe[column_name].shift(1)\n    return dataframe[(dataframe['previous_value_bool'] == False) &amp; (dataframe[column_name] == True)]\n</code></pre>"},{"location":"reference/ts_shape/transform/filter/boolean_filter/#ts_shape.transform.filter.boolean_filter.BooleanFilter.get_dataframe","title":"get_dataframe","text":"<pre><code>get_dataframe() -&gt; DataFrame\n</code></pre> <p>Returns the processed DataFrame.</p> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def get_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"Returns the processed DataFrame.\"\"\"\n    return self.dataframe\n</code></pre>"},{"location":"reference/ts_shape/transform/filter/boolean_filter/#ts_shape.transform.filter.boolean_filter.IsDeltaFilter","title":"IsDeltaFilter","text":"<pre><code>IsDeltaFilter(dataframe: DataFrame, column_name: str = 'systime')\n</code></pre> <p>               Bases: <code>Base</code></p> <p>Provides class methods for filtering is_delta columns in a pandas DataFrame.</p> <p>Parameters:</p> <p>Methods:</p> <ul> <li> <code>filter_is_delta_false</code>             \u2013              <p>Filters rows where 'is_delta' is False.</p> </li> <li> <code>filter_is_delta_true</code>             \u2013              <p>Filters rows where 'is_delta' is True.</p> </li> <li> <code>get_dataframe</code>             \u2013              <p>Returns the processed DataFrame.</p> </li> </ul> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def __init__(self, dataframe: pd.DataFrame, column_name: str = 'systime') -&gt; pd.DataFrame:\n    \"\"\"\n    Initializes the Base with a DataFrame, detects time columns, converts them to datetime,\n    and sorts the DataFrame by the specified column (or the detected time column if applicable).\n\n    Args:\n        dataframe (pd.DataFrame): The DataFrame to be processed.\n        column_name (str): The column to sort by. Default is 'systime'. If the column is not found or is not a time column, the class will attempt to detect other time columns.\n    \"\"\"\n    self.dataframe = dataframe.copy()\n\n    # Attempt to convert the specified column_name to datetime if it exists\n    if column_name in self.dataframe.columns:\n        self.dataframe[column_name] = pd.to_datetime(self.dataframe[column_name], errors='coerce')\n    else:\n        # If the column_name is not in the DataFrame, fallback to automatic time detection\n        time_columns = [col for col in self.dataframe.columns if 'time' in col.lower() or 'date' in col.lower()]\n\n        # Convert all detected time columns to datetime, if any\n        for col in time_columns:\n            self.dataframe[col] = pd.to_datetime(self.dataframe[col], errors='coerce')\n\n        # If any time columns are detected, sort by the first one; otherwise, do nothing\n        if time_columns:\n            column_name = time_columns[0]\n\n    # Sort by the datetime column (either specified or detected)\n    if column_name in self.dataframe.columns:\n        self.dataframe = self.dataframe.sort_values(by=column_name)\n</code></pre>"},{"location":"reference/ts_shape/transform/filter/boolean_filter/#ts_shape.transform.filter.boolean_filter.IsDeltaFilter(dataframe)","title":"<code>dataframe</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The DataFrame to be processed.</p>"},{"location":"reference/ts_shape/transform/filter/boolean_filter/#ts_shape.transform.filter.boolean_filter.IsDeltaFilter(column_name)","title":"<code>column_name</code>","text":"(<code>str</code>, default:                   <code>'systime'</code> )           \u2013            <p>The column to sort by. Default is 'systime'. If the column is not found or is not a time column, the class will attempt to detect other time columns.</p>"},{"location":"reference/ts_shape/transform/filter/boolean_filter/#ts_shape.transform.filter.boolean_filter.IsDeltaFilter.filter_is_delta_false","title":"filter_is_delta_false  <code>classmethod</code>","text":"<pre><code>filter_is_delta_false(dataframe: DataFrame, column_name: str = 'is_delta') -&gt; DataFrame\n</code></pre> <p>Filters rows where 'is_delta' is False.</p> Source code in <code>src/ts_shape/transform/filter/boolean_filter.py</code> <pre><code>@classmethod\ndef filter_is_delta_false(cls, dataframe: pd.DataFrame, column_name: str = 'is_delta') -&gt; pd.DataFrame:\n    \"\"\"Filters rows where 'is_delta' is False.\"\"\"\n    return dataframe[dataframe[column_name] == False]\n</code></pre>"},{"location":"reference/ts_shape/transform/filter/boolean_filter/#ts_shape.transform.filter.boolean_filter.IsDeltaFilter.filter_is_delta_true","title":"filter_is_delta_true  <code>classmethod</code>","text":"<pre><code>filter_is_delta_true(dataframe: DataFrame, column_name: str = 'is_delta') -&gt; DataFrame\n</code></pre> <p>Filters rows where 'is_delta' is True.</p> Source code in <code>src/ts_shape/transform/filter/boolean_filter.py</code> <pre><code>@classmethod\ndef filter_is_delta_true(cls, dataframe: pd.DataFrame, column_name: str = 'is_delta') -&gt; pd.DataFrame:\n    \"\"\"Filters rows where 'is_delta' is True.\"\"\"\n    # No need for instance, working directly on class level\n    return dataframe[dataframe[column_name] == True]\n</code></pre>"},{"location":"reference/ts_shape/transform/filter/boolean_filter/#ts_shape.transform.filter.boolean_filter.IsDeltaFilter.get_dataframe","title":"get_dataframe","text":"<pre><code>get_dataframe() -&gt; DataFrame\n</code></pre> <p>Returns the processed DataFrame.</p> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def get_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"Returns the processed DataFrame.\"\"\"\n    return self.dataframe\n</code></pre>"},{"location":"reference/ts_shape/transform/filter/custom_filter/","title":"custom_filter","text":""},{"location":"reference/ts_shape/transform/filter/custom_filter/#ts_shape.transform.filter.custom_filter","title":"custom_filter","text":"<p>Classes:</p> <ul> <li> <code>CustomFilter</code>           \u2013            </li> </ul>"},{"location":"reference/ts_shape/transform/filter/custom_filter/#ts_shape.transform.filter.custom_filter.CustomFilter","title":"CustomFilter","text":"<pre><code>CustomFilter(dataframe: DataFrame, column_name: str = 'systime')\n</code></pre> <p>               Bases: <code>Base</code></p> <p>Parameters:</p> <p>Methods:</p> <ul> <li> <code>filter_custom_conditions</code>             \u2013              <p>Filters the DataFrame based on a set of user-defined conditions passed as a string.</p> </li> <li> <code>get_dataframe</code>             \u2013              <p>Returns the processed DataFrame.</p> </li> </ul> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def __init__(self, dataframe: pd.DataFrame, column_name: str = 'systime') -&gt; pd.DataFrame:\n    \"\"\"\n    Initializes the Base with a DataFrame, detects time columns, converts them to datetime,\n    and sorts the DataFrame by the specified column (or the detected time column if applicable).\n\n    Args:\n        dataframe (pd.DataFrame): The DataFrame to be processed.\n        column_name (str): The column to sort by. Default is 'systime'. If the column is not found or is not a time column, the class will attempt to detect other time columns.\n    \"\"\"\n    self.dataframe = dataframe.copy()\n\n    # Attempt to convert the specified column_name to datetime if it exists\n    if column_name in self.dataframe.columns:\n        self.dataframe[column_name] = pd.to_datetime(self.dataframe[column_name], errors='coerce')\n    else:\n        # If the column_name is not in the DataFrame, fallback to automatic time detection\n        time_columns = [col for col in self.dataframe.columns if 'time' in col.lower() or 'date' in col.lower()]\n\n        # Convert all detected time columns to datetime, if any\n        for col in time_columns:\n            self.dataframe[col] = pd.to_datetime(self.dataframe[col], errors='coerce')\n\n        # If any time columns are detected, sort by the first one; otherwise, do nothing\n        if time_columns:\n            column_name = time_columns[0]\n\n    # Sort by the datetime column (either specified or detected)\n    if column_name in self.dataframe.columns:\n        self.dataframe = self.dataframe.sort_values(by=column_name)\n</code></pre>"},{"location":"reference/ts_shape/transform/filter/custom_filter/#ts_shape.transform.filter.custom_filter.CustomFilter(dataframe)","title":"<code>dataframe</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The DataFrame to be processed.</p>"},{"location":"reference/ts_shape/transform/filter/custom_filter/#ts_shape.transform.filter.custom_filter.CustomFilter(column_name)","title":"<code>column_name</code>","text":"(<code>str</code>, default:                   <code>'systime'</code> )           \u2013            <p>The column to sort by. Default is 'systime'. If the column is not found or is not a time column, the class will attempt to detect other time columns.</p>"},{"location":"reference/ts_shape/transform/filter/custom_filter/#ts_shape.transform.filter.custom_filter.CustomFilter.filter_custom_conditions","title":"filter_custom_conditions  <code>classmethod</code>","text":"<pre><code>filter_custom_conditions(dataframe: DataFrame, conditions: str) -&gt; DataFrame\n</code></pre> <p>Filters the DataFrame based on a set of user-defined conditions passed as a string.</p> <p>This method allows for flexible data filtering by evaluating a condition or multiple conditions specified in the 'conditions' parameter. The conditions must be provided as a string that can be interpreted by pandas' DataFrame.query() method.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: A DataFrame containing only the rows that meet the specified conditions.</p> </li> </ul>"},{"location":"reference/ts_shape/transform/filter/custom_filter/#ts_shape.transform.filter.custom_filter.CustomFilter.filter_custom_conditions(dataframe)","title":"<code>dataframe</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The DataFrame to apply the filter on.</p>"},{"location":"reference/ts_shape/transform/filter/custom_filter/#ts_shape.transform.filter.custom_filter.CustomFilter.filter_custom_conditions(conditions)","title":"<code>conditions</code>","text":"(<code>str</code>)           \u2013            <p>A string representing the conditions to filter the DataFrame.             The string should be formatted according to pandas query syntax.</p>"},{"location":"reference/ts_shape/transform/filter/custom_filter/#ts_shape.transform.filter.custom_filter.CustomFilter.filter_custom_conditions--example","title":"Example:","text":""},{"location":"reference/ts_shape/transform/filter/custom_filter/#ts_shape.transform.filter.custom_filter.CustomFilter.filter_custom_conditions--given-a-dataframe-df-containing-columns-age-and-score","title":"Given a DataFrame 'df' containing columns 'age' and 'score':","text":"<p>filtered_data = CustomFilter.filter_custom_conditions(df, \"age &gt; 30 and score &gt; 80\") print(filtered_data)</p> Note <p>Ensure that the column names and values used in conditions match those in the DataFrame. Complex expressions and functions available in pandas query syntax can also be used.</p> Source code in <code>src/ts_shape/transform/filter/custom_filter.py</code> <pre><code>@classmethod\ndef filter_custom_conditions(cls, dataframe: pd.DataFrame, conditions: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Filters the DataFrame based on a set of user-defined conditions passed as a string.\n\n    This method allows for flexible data filtering by evaluating a condition or multiple conditions\n    specified in the 'conditions' parameter. The conditions must be provided as a string\n    that can be interpreted by pandas' DataFrame.query() method.\n\n    Args:\n        dataframe (pd.DataFrame): The DataFrame to apply the filter on.\n        conditions (str): A string representing the conditions to filter the DataFrame.\n                        The string should be formatted according to pandas query syntax.\n\n    Returns:\n        pd.DataFrame: A DataFrame containing only the rows that meet the specified conditions.\n\n    Example:\n    --------\n    # Given a DataFrame 'df' containing columns 'age' and 'score':\n    &gt;&gt;&gt; filtered_data = CustomFilter.filter_custom_conditions(df, \"age &gt; 30 and score &gt; 80\")\n    &gt;&gt;&gt; print(filtered_data)\n\n    Note:\n        Ensure that the column names and values used in conditions match those in the DataFrame.\n        Complex expressions and functions available in pandas query syntax can also be used.\n    \"\"\"\n    return dataframe.query(conditions)\n</code></pre>"},{"location":"reference/ts_shape/transform/filter/custom_filter/#ts_shape.transform.filter.custom_filter.CustomFilter.get_dataframe","title":"get_dataframe","text":"<pre><code>get_dataframe() -&gt; DataFrame\n</code></pre> <p>Returns the processed DataFrame.</p> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def get_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"Returns the processed DataFrame.\"\"\"\n    return self.dataframe\n</code></pre>"},{"location":"reference/ts_shape/transform/filter/datetime_filter/","title":"datetime_filter","text":""},{"location":"reference/ts_shape/transform/filter/datetime_filter/#ts_shape.transform.filter.datetime_filter","title":"datetime_filter","text":"<p>Classes:</p> <ul> <li> <code>DateTimeFilter</code>           \u2013            <p>Provides class methods for filtering time columns in a pandas DataFrame.</p> </li> </ul>"},{"location":"reference/ts_shape/transform/filter/datetime_filter/#ts_shape.transform.filter.datetime_filter.DateTimeFilter","title":"DateTimeFilter","text":"<pre><code>DateTimeFilter(dataframe: DataFrame, column_name: str = 'systime')\n</code></pre> <p>               Bases: <code>Base</code></p> <p>Provides class methods for filtering time columns in a pandas DataFrame. Allows specification of which column to operate on.</p> Inherits from <p>Base (class): Base class with common initializations for DataFrame handling.</p> <p>Parameters:</p> <p>Methods:</p> <ul> <li> <code>filter_after_date</code>             \u2013              <p>Filters the DataFrame to include only rows after the specified date.</p> </li> <li> <code>filter_after_datetime</code>             \u2013              <p>Filters the DataFrame to include only rows after the specified datetime.</p> </li> <li> <code>filter_before_date</code>             \u2013              <p>Filters the DataFrame to include only rows before the specified date.</p> </li> <li> <code>filter_before_datetime</code>             \u2013              <p>Filters the DataFrame to include only rows before the specified datetime.</p> </li> <li> <code>filter_between_dates</code>             \u2013              <p>Filters the DataFrame to include only rows between the specified start and end dates.</p> </li> <li> <code>filter_between_datetimes</code>             \u2013              <p>Filters the DataFrame to include only rows between the specified start and end datetimes.</p> </li> <li> <code>get_dataframe</code>             \u2013              <p>Returns the processed DataFrame.</p> </li> </ul> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def __init__(self, dataframe: pd.DataFrame, column_name: str = 'systime') -&gt; pd.DataFrame:\n    \"\"\"\n    Initializes the Base with a DataFrame, detects time columns, converts them to datetime,\n    and sorts the DataFrame by the specified column (or the detected time column if applicable).\n\n    Args:\n        dataframe (pd.DataFrame): The DataFrame to be processed.\n        column_name (str): The column to sort by. Default is 'systime'. If the column is not found or is not a time column, the class will attempt to detect other time columns.\n    \"\"\"\n    self.dataframe = dataframe.copy()\n\n    # Attempt to convert the specified column_name to datetime if it exists\n    if column_name in self.dataframe.columns:\n        self.dataframe[column_name] = pd.to_datetime(self.dataframe[column_name], errors='coerce')\n    else:\n        # If the column_name is not in the DataFrame, fallback to automatic time detection\n        time_columns = [col for col in self.dataframe.columns if 'time' in col.lower() or 'date' in col.lower()]\n\n        # Convert all detected time columns to datetime, if any\n        for col in time_columns:\n            self.dataframe[col] = pd.to_datetime(self.dataframe[col], errors='coerce')\n\n        # If any time columns are detected, sort by the first one; otherwise, do nothing\n        if time_columns:\n            column_name = time_columns[0]\n\n    # Sort by the datetime column (either specified or detected)\n    if column_name in self.dataframe.columns:\n        self.dataframe = self.dataframe.sort_values(by=column_name)\n</code></pre>"},{"location":"reference/ts_shape/transform/filter/datetime_filter/#ts_shape.transform.filter.datetime_filter.DateTimeFilter(dataframe)","title":"<code>dataframe</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The DataFrame to be processed.</p>"},{"location":"reference/ts_shape/transform/filter/datetime_filter/#ts_shape.transform.filter.datetime_filter.DateTimeFilter(column_name)","title":"<code>column_name</code>","text":"(<code>str</code>, default:                   <code>'systime'</code> )           \u2013            <p>The column to sort by. Default is 'systime'. If the column is not found or is not a time column, the class will attempt to detect other time columns.</p>"},{"location":"reference/ts_shape/transform/filter/datetime_filter/#ts_shape.transform.filter.datetime_filter.DateTimeFilter.filter_after_date","title":"filter_after_date  <code>classmethod</code>","text":"<pre><code>filter_after_date(dataframe: DataFrame, column_name: str = 'systime', date: str = None) -&gt; DataFrame\n</code></pre> <p>Filters the DataFrame to include only rows after the specified date.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: A DataFrame containing rows where the 'systime' is after the specified date.</p> </li> </ul>"},{"location":"reference/ts_shape/transform/filter/datetime_filter/#ts_shape.transform.filter.datetime_filter.DateTimeFilter.filter_after_date(date)","title":"<code>date</code>","text":"(<code>str</code>, default:                   <code>None</code> )           \u2013            <p>The cutoff date in 'YYYY-MM-DD' format.</p>"},{"location":"reference/ts_shape/transform/filter/datetime_filter/#ts_shape.transform.filter.datetime_filter.DateTimeFilter.filter_after_date--example","title":"Example:","text":"<p>filtered_data = DateTimeFilter.filter_after_date(df, \"systime\", \"2023-01-01\") print(filtered_data)</p> Source code in <code>src/ts_shape/transform/filter/datetime_filter.py</code> <pre><code>@classmethod\ndef filter_after_date(cls, dataframe: pd.DataFrame, column_name: str = 'systime', date: str = None) -&gt; pd.DataFrame:\n    \"\"\"\n    Filters the DataFrame to include only rows after the specified date.\n\n    Args:\n        date (str): The cutoff date in 'YYYY-MM-DD' format.\n\n    Returns:\n        pd.DataFrame: A DataFrame containing rows where the 'systime' is after the specified date.\n\n    Example:\n    --------\n    &gt;&gt;&gt; filtered_data = DateTimeFilter.filter_after_date(df, \"systime\", \"2023-01-01\")\n    &gt;&gt;&gt; print(filtered_data)\n    \"\"\"\n    return dataframe[dataframe[column_name] &gt; pd.to_datetime(date)]\n</code></pre>"},{"location":"reference/ts_shape/transform/filter/datetime_filter/#ts_shape.transform.filter.datetime_filter.DateTimeFilter.filter_after_datetime","title":"filter_after_datetime  <code>classmethod</code>","text":"<pre><code>filter_after_datetime(dataframe: DataFrame, column_name: str = 'systime', datetime: str = None) -&gt; DataFrame\n</code></pre> <p>Filters the DataFrame to include only rows after the specified datetime.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: A DataFrame containing rows where the 'systime' is after the specified datetime.</p> </li> </ul>"},{"location":"reference/ts_shape/transform/filter/datetime_filter/#ts_shape.transform.filter.datetime_filter.DateTimeFilter.filter_after_datetime(datetime)","title":"<code>datetime</code>","text":"(<code>str</code>, default:                   <code>None</code> )           \u2013            <p>The cutoff datetime in 'YYYY-MM-DD HH:MM:SS' format.</p>"},{"location":"reference/ts_shape/transform/filter/datetime_filter/#ts_shape.transform.filter.datetime_filter.DateTimeFilter.filter_after_datetime--example","title":"Example:","text":"<p>filtered_data = DateTimeFilter.filter_after_datetime(df, \"systime\", \"2023-01-01 12:00:00\") print(filtered_data)</p> Source code in <code>src/ts_shape/transform/filter/datetime_filter.py</code> <pre><code>@classmethod\ndef filter_after_datetime(cls, dataframe: pd.DataFrame, column_name: str = 'systime', datetime: str = None) -&gt; pd.DataFrame:\n    \"\"\"\n    Filters the DataFrame to include only rows after the specified datetime.\n\n    Args:\n        datetime (str): The cutoff datetime in 'YYYY-MM-DD HH:MM:SS' format.\n\n    Returns:\n        pd.DataFrame: A DataFrame containing rows where the 'systime' is after the specified datetime.\n\n    Example:\n    --------\n    &gt;&gt;&gt; filtered_data = DateTimeFilter.filter_after_datetime(df, \"systime\", \"2023-01-01 12:00:00\")\n    &gt;&gt;&gt; print(filtered_data)\n    \"\"\"\n    return dataframe[dataframe[column_name] &gt; pd.to_datetime(datetime)]\n</code></pre>"},{"location":"reference/ts_shape/transform/filter/datetime_filter/#ts_shape.transform.filter.datetime_filter.DateTimeFilter.filter_before_date","title":"filter_before_date  <code>classmethod</code>","text":"<pre><code>filter_before_date(dataframe: DataFrame, column_name: str = 'systime', date: str = None) -&gt; DataFrame\n</code></pre> <p>Filters the DataFrame to include only rows before the specified date.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: A DataFrame containing rows where the 'systime' is before the specified date.</p> </li> </ul>"},{"location":"reference/ts_shape/transform/filter/datetime_filter/#ts_shape.transform.filter.datetime_filter.DateTimeFilter.filter_before_date(date)","title":"<code>date</code>","text":"(<code>str</code>, default:                   <code>None</code> )           \u2013            <p>The cutoff date in 'YYYY-MM-DD' format.</p>"},{"location":"reference/ts_shape/transform/filter/datetime_filter/#ts_shape.transform.filter.datetime_filter.DateTimeFilter.filter_before_date--example","title":"Example:","text":"<p>filtered_data = DateTimeFilter.filter_before_date(df, \"systime\", \"2023-01-01\") print(filtered_data)</p> Source code in <code>src/ts_shape/transform/filter/datetime_filter.py</code> <pre><code>@classmethod\ndef filter_before_date(cls, dataframe: pd.DataFrame, column_name: str = 'systime', date: str = None) -&gt; pd.DataFrame:\n    \"\"\"\n    Filters the DataFrame to include only rows before the specified date.\n\n    Args:\n        date (str): The cutoff date in 'YYYY-MM-DD' format.\n\n    Returns:\n        pd.DataFrame: A DataFrame containing rows where the 'systime' is before the specified date.\n\n    Example:\n    --------\n    &gt;&gt;&gt; filtered_data = DateTimeFilter.filter_before_date(df, \"systime\", \"2023-01-01\")\n    &gt;&gt;&gt; print(filtered_data)\n    \"\"\"\n    return dataframe[dataframe[column_name] &lt; pd.to_datetime(date)]\n</code></pre>"},{"location":"reference/ts_shape/transform/filter/datetime_filter/#ts_shape.transform.filter.datetime_filter.DateTimeFilter.filter_before_datetime","title":"filter_before_datetime  <code>classmethod</code>","text":"<pre><code>filter_before_datetime(dataframe: DataFrame, column_name: str = 'systime', datetime: str = None) -&gt; DataFrame\n</code></pre> <p>Filters the DataFrame to include only rows before the specified datetime.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: A DataFrame containing rows where the 'systime' is before the specified datetime.</p> </li> </ul>"},{"location":"reference/ts_shape/transform/filter/datetime_filter/#ts_shape.transform.filter.datetime_filter.DateTimeFilter.filter_before_datetime(datetime)","title":"<code>datetime</code>","text":"(<code>str</code>, default:                   <code>None</code> )           \u2013            <p>The cutoff datetime in 'YYYY-MM-DD HH:MM:SS' format.</p>"},{"location":"reference/ts_shape/transform/filter/datetime_filter/#ts_shape.transform.filter.datetime_filter.DateTimeFilter.filter_before_datetime--example","title":"Example:","text":"<p>filtered_data = DateTimeFilter.filter_before_datetime(df, \"systime\", \"2023-01-01 12:00:00\") print(filtered_data)</p> Source code in <code>src/ts_shape/transform/filter/datetime_filter.py</code> <pre><code>@classmethod\ndef filter_before_datetime(cls, dataframe: pd.DataFrame, column_name: str = 'systime', datetime: str = None) -&gt; pd.DataFrame:\n    \"\"\"\n    Filters the DataFrame to include only rows before the specified datetime.\n\n    Args:\n        datetime (str): The cutoff datetime in 'YYYY-MM-DD HH:MM:SS' format.\n\n    Returns:\n        pd.DataFrame: A DataFrame containing rows where the 'systime' is before the specified datetime.\n\n    Example:\n    --------\n    &gt;&gt;&gt; filtered_data = DateTimeFilter.filter_before_datetime(df, \"systime\", \"2023-01-01 12:00:00\")\n    &gt;&gt;&gt; print(filtered_data)\n    \"\"\"\n    return dataframe[dataframe[column_name] &lt; pd.to_datetime(datetime)]\n</code></pre>"},{"location":"reference/ts_shape/transform/filter/datetime_filter/#ts_shape.transform.filter.datetime_filter.DateTimeFilter.filter_between_dates","title":"filter_between_dates  <code>classmethod</code>","text":"<pre><code>filter_between_dates(dataframe: DataFrame, column_name: str = 'systime', start_date: str = None, end_date: str = None) -&gt; DataFrame\n</code></pre> <p>Filters the DataFrame to include only rows between the specified start and end dates.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: A DataFrame containing rows where the 'systime' is between the specified dates.</p> </li> </ul>"},{"location":"reference/ts_shape/transform/filter/datetime_filter/#ts_shape.transform.filter.datetime_filter.DateTimeFilter.filter_between_dates(start_date)","title":"<code>start_date</code>","text":"(<code>str</code>, default:                   <code>None</code> )           \u2013            <p>The start date of the interval in 'YYYY-MM-DD' format.</p>"},{"location":"reference/ts_shape/transform/filter/datetime_filter/#ts_shape.transform.filter.datetime_filter.DateTimeFilter.filter_between_dates(end_date)","title":"<code>end_date</code>","text":"(<code>str</code>, default:                   <code>None</code> )           \u2013            <p>The end date of the interval in 'YYYY-MM-DD' format.</p>"},{"location":"reference/ts_shape/transform/filter/datetime_filter/#ts_shape.transform.filter.datetime_filter.DateTimeFilter.filter_between_dates--example","title":"Example:","text":"<p>filtered_data = DateTimeFilter.filter_between_dates(df, \"systime\", \"2023-01-01\", \"2023-02-01\") print(filtered_data)</p> Source code in <code>src/ts_shape/transform/filter/datetime_filter.py</code> <pre><code>@classmethod\ndef filter_between_dates(cls, dataframe: pd.DataFrame, column_name: str = 'systime', start_date: str = None, end_date: str = None) -&gt; pd.DataFrame:\n    \"\"\"\n    Filters the DataFrame to include only rows between the specified start and end dates.\n\n    Args:\n        start_date (str): The start date of the interval in 'YYYY-MM-DD' format.\n        end_date (str): The end date of the interval in 'YYYY-MM-DD' format.\n\n    Returns:\n        pd.DataFrame: A DataFrame containing rows where the 'systime' is between the specified dates.\n\n    Example:\n    --------\n    &gt;&gt;&gt; filtered_data = DateTimeFilter.filter_between_dates(df, \"systime\", \"2023-01-01\", \"2023-02-01\")\n    &gt;&gt;&gt; print(filtered_data)\n    \"\"\"\n    mask = (dataframe[column_name] &gt; pd.to_datetime(start_date)) &amp; (dataframe[column_name] &lt; pd.to_datetime(end_date))\n    return dataframe[mask]\n</code></pre>"},{"location":"reference/ts_shape/transform/filter/datetime_filter/#ts_shape.transform.filter.datetime_filter.DateTimeFilter.filter_between_datetimes","title":"filter_between_datetimes  <code>classmethod</code>","text":"<pre><code>filter_between_datetimes(dataframe: DataFrame, column_name: str = 'systime', start_datetime: str = None, end_datetime: str = None) -&gt; DataFrame\n</code></pre> <p>Filters the DataFrame to include only rows between the specified start and end datetimes.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: A DataFrame containing rows where the 'systime' is between the specified datetimes.</p> </li> </ul>"},{"location":"reference/ts_shape/transform/filter/datetime_filter/#ts_shape.transform.filter.datetime_filter.DateTimeFilter.filter_between_datetimes(start_datetime)","title":"<code>start_datetime</code>","text":"(<code>str</code>, default:                   <code>None</code> )           \u2013            <p>The start datetime of the interval in 'YYYY-MM-DD HH:MM:SS' format.</p>"},{"location":"reference/ts_shape/transform/filter/datetime_filter/#ts_shape.transform.filter.datetime_filter.DateTimeFilter.filter_between_datetimes(end_datetime)","title":"<code>end_datetime</code>","text":"(<code>str</code>, default:                   <code>None</code> )           \u2013            <p>The end datetime of the interval in 'YYYY-MM-DD HH:MM:SS' format.</p>"},{"location":"reference/ts_shape/transform/filter/datetime_filter/#ts_shape.transform.filter.datetime_filter.DateTimeFilter.filter_between_datetimes--example","title":"Example:","text":"<p>filtered_data = DateTimeFilter.filter_between_datetimes(df, \"systime\", \"2023-01-01 12:00:00\", \"2023-02-01 12:00:00\") print(filtered_data)</p> Source code in <code>src/ts_shape/transform/filter/datetime_filter.py</code> <pre><code>@classmethod\ndef filter_between_datetimes(cls, dataframe: pd.DataFrame, column_name: str = 'systime', start_datetime: str = None, end_datetime: str = None) -&gt; pd.DataFrame:\n    \"\"\"\n    Filters the DataFrame to include only rows between the specified start and end datetimes.\n\n    Args:\n        start_datetime (str): The start datetime of the interval in 'YYYY-MM-DD HH:MM:SS' format.\n        end_datetime (str): The end datetime of the interval in 'YYYY-MM-DD HH:MM:SS' format.\n\n    Returns:\n        pd.DataFrame: A DataFrame containing rows where the 'systime' is between the specified datetimes.\n\n    Example:\n    --------\n    &gt;&gt;&gt; filtered_data = DateTimeFilter.filter_between_datetimes(df, \"systime\", \"2023-01-01 12:00:00\", \"2023-02-01 12:00:00\")\n    &gt;&gt;&gt; print(filtered_data)\n    \"\"\"\n    mask = (dataframe[column_name] &gt; pd.to_datetime(start_datetime)) &amp; (dataframe[column_name] &lt; pd.to_datetime(end_datetime))\n    return dataframe[mask]\n</code></pre>"},{"location":"reference/ts_shape/transform/filter/datetime_filter/#ts_shape.transform.filter.datetime_filter.DateTimeFilter.get_dataframe","title":"get_dataframe","text":"<pre><code>get_dataframe() -&gt; DataFrame\n</code></pre> <p>Returns the processed DataFrame.</p> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def get_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"Returns the processed DataFrame.\"\"\"\n    return self.dataframe\n</code></pre>"},{"location":"reference/ts_shape/transform/filter/numeric_filter/","title":"numeric_filter","text":""},{"location":"reference/ts_shape/transform/filter/numeric_filter/#ts_shape.transform.filter.numeric_filter","title":"numeric_filter","text":"<p>Classes:</p> <ul> <li> <code>DoubleFilter</code>           \u2013            <p>Provides class methods for filtering double (floating-point) columns in a pandas DataFrame,</p> </li> <li> <code>IntegerFilter</code>           \u2013            <p>Provides class methods for filtering integer columns in a pandas DataFrame.</p> </li> </ul>"},{"location":"reference/ts_shape/transform/filter/numeric_filter/#ts_shape.transform.filter.numeric_filter.DoubleFilter","title":"DoubleFilter","text":"<pre><code>DoubleFilter(dataframe: DataFrame, column_name: str = 'systime')\n</code></pre> <p>               Bases: <code>Base</code></p> <p>Provides class methods for filtering double (floating-point) columns in a pandas DataFrame, particularly focusing on NaN values.</p> <p>Parameters:</p> <p>Methods:</p> <ul> <li> <code>filter_nan_value_double</code>             \u2013              <p>Filters out rows where 'value_double' is NaN.</p> </li> <li> <code>filter_value_double_between</code>             \u2013              <p>Filters rows where 'value_double' is between the specified min and max values (inclusive).</p> </li> <li> <code>get_dataframe</code>             \u2013              <p>Returns the processed DataFrame.</p> </li> </ul> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def __init__(self, dataframe: pd.DataFrame, column_name: str = 'systime') -&gt; pd.DataFrame:\n    \"\"\"\n    Initializes the Base with a DataFrame, detects time columns, converts them to datetime,\n    and sorts the DataFrame by the specified column (or the detected time column if applicable).\n\n    Args:\n        dataframe (pd.DataFrame): The DataFrame to be processed.\n        column_name (str): The column to sort by. Default is 'systime'. If the column is not found or is not a time column, the class will attempt to detect other time columns.\n    \"\"\"\n    self.dataframe = dataframe.copy()\n\n    # Attempt to convert the specified column_name to datetime if it exists\n    if column_name in self.dataframe.columns:\n        self.dataframe[column_name] = pd.to_datetime(self.dataframe[column_name], errors='coerce')\n    else:\n        # If the column_name is not in the DataFrame, fallback to automatic time detection\n        time_columns = [col for col in self.dataframe.columns if 'time' in col.lower() or 'date' in col.lower()]\n\n        # Convert all detected time columns to datetime, if any\n        for col in time_columns:\n            self.dataframe[col] = pd.to_datetime(self.dataframe[col], errors='coerce')\n\n        # If any time columns are detected, sort by the first one; otherwise, do nothing\n        if time_columns:\n            column_name = time_columns[0]\n\n    # Sort by the datetime column (either specified or detected)\n    if column_name in self.dataframe.columns:\n        self.dataframe = self.dataframe.sort_values(by=column_name)\n</code></pre>"},{"location":"reference/ts_shape/transform/filter/numeric_filter/#ts_shape.transform.filter.numeric_filter.DoubleFilter(dataframe)","title":"<code>dataframe</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The DataFrame to be processed.</p>"},{"location":"reference/ts_shape/transform/filter/numeric_filter/#ts_shape.transform.filter.numeric_filter.DoubleFilter(column_name)","title":"<code>column_name</code>","text":"(<code>str</code>, default:                   <code>'systime'</code> )           \u2013            <p>The column to sort by. Default is 'systime'. If the column is not found or is not a time column, the class will attempt to detect other time columns.</p>"},{"location":"reference/ts_shape/transform/filter/numeric_filter/#ts_shape.transform.filter.numeric_filter.DoubleFilter.filter_nan_value_double","title":"filter_nan_value_double  <code>classmethod</code>","text":"<pre><code>filter_nan_value_double(dataframe: DataFrame, column_name: str = 'value_double') -&gt; DataFrame\n</code></pre> <p>Filters out rows where 'value_double' is NaN.</p> Source code in <code>src/ts_shape/transform/filter/numeric_filter.py</code> <pre><code>@classmethod\ndef filter_nan_value_double(cls, dataframe: pd.DataFrame, column_name: str = 'value_double') -&gt; pd.DataFrame:\n    \"\"\"Filters out rows where 'value_double' is NaN.\"\"\"\n    return dataframe[dataframe[column_name].notna()]\n</code></pre>"},{"location":"reference/ts_shape/transform/filter/numeric_filter/#ts_shape.transform.filter.numeric_filter.DoubleFilter.filter_value_double_between","title":"filter_value_double_between  <code>classmethod</code>","text":"<pre><code>filter_value_double_between(dataframe: DataFrame, column_name: str = 'value_double', min_value: float = 0.0, max_value: float = 100.0) -&gt; DataFrame\n</code></pre> <p>Filters rows where 'value_double' is between the specified min and max values (inclusive).</p> Source code in <code>src/ts_shape/transform/filter/numeric_filter.py</code> <pre><code>@classmethod\ndef filter_value_double_between(cls, dataframe: pd.DataFrame, column_name: str = 'value_double', min_value: float = 0.0, max_value: float = 100.0) -&gt; pd.DataFrame:\n    \"\"\"Filters rows where 'value_double' is between the specified min and max values (inclusive).\"\"\"\n    return dataframe[(dataframe[column_name] &gt;= min_value) &amp; (dataframe[column_name] &lt;= max_value)]\n</code></pre>"},{"location":"reference/ts_shape/transform/filter/numeric_filter/#ts_shape.transform.filter.numeric_filter.DoubleFilter.get_dataframe","title":"get_dataframe","text":"<pre><code>get_dataframe() -&gt; DataFrame\n</code></pre> <p>Returns the processed DataFrame.</p> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def get_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"Returns the processed DataFrame.\"\"\"\n    return self.dataframe\n</code></pre>"},{"location":"reference/ts_shape/transform/filter/numeric_filter/#ts_shape.transform.filter.numeric_filter.IntegerFilter","title":"IntegerFilter","text":"<pre><code>IntegerFilter(dataframe: DataFrame, column_name: str = 'systime')\n</code></pre> <p>               Bases: <code>Base</code></p> <p>Provides class methods for filtering integer columns in a pandas DataFrame.</p> <p>Parameters:</p> <p>Methods:</p> <ul> <li> <code>filter_value_integer_between</code>             \u2013              <p>Filters rows where 'value_integer' is between the specified min and max values (inclusive).</p> </li> <li> <code>filter_value_integer_match</code>             \u2013              <p>Filters rows where 'value_integer' matches the specified integer.</p> </li> <li> <code>filter_value_integer_not_match</code>             \u2013              <p>Filters rows where 'value_integer' does not match the specified integer.</p> </li> <li> <code>get_dataframe</code>             \u2013              <p>Returns the processed DataFrame.</p> </li> </ul> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def __init__(self, dataframe: pd.DataFrame, column_name: str = 'systime') -&gt; pd.DataFrame:\n    \"\"\"\n    Initializes the Base with a DataFrame, detects time columns, converts them to datetime,\n    and sorts the DataFrame by the specified column (or the detected time column if applicable).\n\n    Args:\n        dataframe (pd.DataFrame): The DataFrame to be processed.\n        column_name (str): The column to sort by. Default is 'systime'. If the column is not found or is not a time column, the class will attempt to detect other time columns.\n    \"\"\"\n    self.dataframe = dataframe.copy()\n\n    # Attempt to convert the specified column_name to datetime if it exists\n    if column_name in self.dataframe.columns:\n        self.dataframe[column_name] = pd.to_datetime(self.dataframe[column_name], errors='coerce')\n    else:\n        # If the column_name is not in the DataFrame, fallback to automatic time detection\n        time_columns = [col for col in self.dataframe.columns if 'time' in col.lower() or 'date' in col.lower()]\n\n        # Convert all detected time columns to datetime, if any\n        for col in time_columns:\n            self.dataframe[col] = pd.to_datetime(self.dataframe[col], errors='coerce')\n\n        # If any time columns are detected, sort by the first one; otherwise, do nothing\n        if time_columns:\n            column_name = time_columns[0]\n\n    # Sort by the datetime column (either specified or detected)\n    if column_name in self.dataframe.columns:\n        self.dataframe = self.dataframe.sort_values(by=column_name)\n</code></pre>"},{"location":"reference/ts_shape/transform/filter/numeric_filter/#ts_shape.transform.filter.numeric_filter.IntegerFilter(dataframe)","title":"<code>dataframe</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The DataFrame to be processed.</p>"},{"location":"reference/ts_shape/transform/filter/numeric_filter/#ts_shape.transform.filter.numeric_filter.IntegerFilter(column_name)","title":"<code>column_name</code>","text":"(<code>str</code>, default:                   <code>'systime'</code> )           \u2013            <p>The column to sort by. Default is 'systime'. If the column is not found or is not a time column, the class will attempt to detect other time columns.</p>"},{"location":"reference/ts_shape/transform/filter/numeric_filter/#ts_shape.transform.filter.numeric_filter.IntegerFilter.filter_value_integer_between","title":"filter_value_integer_between  <code>classmethod</code>","text":"<pre><code>filter_value_integer_between(dataframe: DataFrame, column_name: str = 'value_integer', min_value: int = 0, max_value: int = 100) -&gt; DataFrame\n</code></pre> <p>Filters rows where 'value_integer' is between the specified min and max values (inclusive).</p> Source code in <code>src/ts_shape/transform/filter/numeric_filter.py</code> <pre><code>@classmethod\ndef filter_value_integer_between(cls, dataframe: pd.DataFrame, column_name: str = 'value_integer', min_value: int = 0, max_value: int = 100) -&gt; pd.DataFrame:\n    \"\"\"Filters rows where 'value_integer' is between the specified min and max values (inclusive).\"\"\"\n    return dataframe[(dataframe[column_name] &gt;= min_value) &amp; (dataframe[column_name] &lt;= max_value)]\n</code></pre>"},{"location":"reference/ts_shape/transform/filter/numeric_filter/#ts_shape.transform.filter.numeric_filter.IntegerFilter.filter_value_integer_match","title":"filter_value_integer_match  <code>classmethod</code>","text":"<pre><code>filter_value_integer_match(dataframe: DataFrame, column_name: str = 'value_integer', integer_value: int = 0) -&gt; DataFrame\n</code></pre> <p>Filters rows where 'value_integer' matches the specified integer.</p> Source code in <code>src/ts_shape/transform/filter/numeric_filter.py</code> <pre><code>@classmethod\ndef filter_value_integer_match(cls, dataframe: pd.DataFrame, column_name: str = 'value_integer', integer_value: int = 0) -&gt; pd.DataFrame:\n    \"\"\"Filters rows where 'value_integer' matches the specified integer.\"\"\"\n    return dataframe[dataframe[column_name] == integer_value]\n</code></pre>"},{"location":"reference/ts_shape/transform/filter/numeric_filter/#ts_shape.transform.filter.numeric_filter.IntegerFilter.filter_value_integer_not_match","title":"filter_value_integer_not_match  <code>classmethod</code>","text":"<pre><code>filter_value_integer_not_match(dataframe: DataFrame, column_name: str = 'value_integer', integer_value: int = 0) -&gt; DataFrame\n</code></pre> <p>Filters rows where 'value_integer' does not match the specified integer.</p> Source code in <code>src/ts_shape/transform/filter/numeric_filter.py</code> <pre><code>@classmethod\ndef filter_value_integer_not_match(cls, dataframe: pd.DataFrame, column_name: str = 'value_integer', integer_value: int = 0) -&gt; pd.DataFrame:\n    \"\"\"Filters rows where 'value_integer' does not match the specified integer.\"\"\"\n    return dataframe[dataframe[column_name] != integer_value]\n</code></pre>"},{"location":"reference/ts_shape/transform/filter/numeric_filter/#ts_shape.transform.filter.numeric_filter.IntegerFilter.get_dataframe","title":"get_dataframe","text":"<pre><code>get_dataframe() -&gt; DataFrame\n</code></pre> <p>Returns the processed DataFrame.</p> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def get_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"Returns the processed DataFrame.\"\"\"\n    return self.dataframe\n</code></pre>"},{"location":"reference/ts_shape/transform/filter/string_filter/","title":"string_filter","text":""},{"location":"reference/ts_shape/transform/filter/string_filter/#ts_shape.transform.filter.string_filter","title":"string_filter","text":"<p>Classes:</p> <ul> <li> <code>StringFilter</code>           \u2013            <p>A class for filtering operations on string columns within a pandas DataFrame.</p> </li> </ul>"},{"location":"reference/ts_shape/transform/filter/string_filter/#ts_shape.transform.filter.string_filter.StringFilter","title":"StringFilter","text":"<pre><code>StringFilter(dataframe: DataFrame, column_name: str = 'systime')\n</code></pre> <p>               Bases: <code>Base</code></p> <p>A class for filtering operations on string columns within a pandas DataFrame.</p> <p>Provides class methods for operations on string columns.</p> <p>Parameters:</p> <p>Methods:</p> <ul> <li> <code>detect_changes_in_string</code>             \u2013              <p>Detects changes from row to row in the specified string column.</p> </li> <li> <code>filter_na_value_string</code>             \u2013              <p>Filters out rows where the specified string column is NA.</p> </li> <li> <code>filter_string_contains</code>             \u2013              <p>Filters rows where the specified string column contains the provided substring.</p> </li> <li> <code>filter_value_string_match</code>             \u2013              <p>Filters rows where the specified string column matches the provided string.</p> </li> <li> <code>filter_value_string_not_match</code>             \u2013              <p>Filters rows where the specified string column does not match the provided string.</p> </li> <li> <code>get_dataframe</code>             \u2013              <p>Returns the processed DataFrame.</p> </li> <li> <code>regex_clean_value_string</code>             \u2013              <p>Applies a regex pattern to clean the specified string column.</p> </li> </ul> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def __init__(self, dataframe: pd.DataFrame, column_name: str = 'systime') -&gt; pd.DataFrame:\n    \"\"\"\n    Initializes the Base with a DataFrame, detects time columns, converts them to datetime,\n    and sorts the DataFrame by the specified column (or the detected time column if applicable).\n\n    Args:\n        dataframe (pd.DataFrame): The DataFrame to be processed.\n        column_name (str): The column to sort by. Default is 'systime'. If the column is not found or is not a time column, the class will attempt to detect other time columns.\n    \"\"\"\n    self.dataframe = dataframe.copy()\n\n    # Attempt to convert the specified column_name to datetime if it exists\n    if column_name in self.dataframe.columns:\n        self.dataframe[column_name] = pd.to_datetime(self.dataframe[column_name], errors='coerce')\n    else:\n        # If the column_name is not in the DataFrame, fallback to automatic time detection\n        time_columns = [col for col in self.dataframe.columns if 'time' in col.lower() or 'date' in col.lower()]\n\n        # Convert all detected time columns to datetime, if any\n        for col in time_columns:\n            self.dataframe[col] = pd.to_datetime(self.dataframe[col], errors='coerce')\n\n        # If any time columns are detected, sort by the first one; otherwise, do nothing\n        if time_columns:\n            column_name = time_columns[0]\n\n    # Sort by the datetime column (either specified or detected)\n    if column_name in self.dataframe.columns:\n        self.dataframe = self.dataframe.sort_values(by=column_name)\n</code></pre>"},{"location":"reference/ts_shape/transform/filter/string_filter/#ts_shape.transform.filter.string_filter.StringFilter(dataframe)","title":"<code>dataframe</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The DataFrame to be processed.</p>"},{"location":"reference/ts_shape/transform/filter/string_filter/#ts_shape.transform.filter.string_filter.StringFilter(column_name)","title":"<code>column_name</code>","text":"(<code>str</code>, default:                   <code>'systime'</code> )           \u2013            <p>The column to sort by. Default is 'systime'. If the column is not found or is not a time column, the class will attempt to detect other time columns.</p>"},{"location":"reference/ts_shape/transform/filter/string_filter/#ts_shape.transform.filter.string_filter.StringFilter.detect_changes_in_string","title":"detect_changes_in_string  <code>classmethod</code>","text":"<pre><code>detect_changes_in_string(dataframe: DataFrame, column_name: str = 'value_string') -&gt; DataFrame\n</code></pre> <p>Detects changes from row to row in the specified string column.</p> Source code in <code>src/ts_shape/transform/filter/string_filter.py</code> <pre><code>@classmethod\ndef detect_changes_in_string(cls, dataframe: pd.DataFrame, column_name: str = 'value_string') -&gt; pd.DataFrame:\n    \"\"\"Detects changes from row to row in the specified string column.\"\"\"\n    changes_detected = dataframe[column_name].ne(dataframe[column_name].shift())\n    result = dataframe[changes_detected]\n    if result.empty:\n        print(f\"No changes detected in the '{column_name}' column between consecutive rows.\")\n    return result\n</code></pre>"},{"location":"reference/ts_shape/transform/filter/string_filter/#ts_shape.transform.filter.string_filter.StringFilter.filter_na_value_string","title":"filter_na_value_string  <code>classmethod</code>","text":"<pre><code>filter_na_value_string(dataframe: DataFrame, column_name: str = 'value_string') -&gt; DataFrame\n</code></pre> <p>Filters out rows where the specified string column is NA.</p> Source code in <code>src/ts_shape/transform/filter/string_filter.py</code> <pre><code>@classmethod\ndef filter_na_value_string(cls, dataframe: pd.DataFrame, column_name: str = 'value_string') -&gt; pd.DataFrame:\n    \"\"\"Filters out rows where the specified string column is NA.\"\"\"\n    return dataframe[dataframe[column_name].notna()]\n</code></pre>"},{"location":"reference/ts_shape/transform/filter/string_filter/#ts_shape.transform.filter.string_filter.StringFilter.filter_string_contains","title":"filter_string_contains  <code>classmethod</code>","text":"<pre><code>filter_string_contains(dataframe: DataFrame, substring: str, column_name: str = 'value_string') -&gt; DataFrame\n</code></pre> <p>Filters rows where the specified string column contains the provided substring.</p> Source code in <code>src/ts_shape/transform/filter/string_filter.py</code> <pre><code>@classmethod\ndef filter_string_contains(cls, dataframe: pd.DataFrame, substring: str, column_name: str = 'value_string') -&gt; pd.DataFrame:\n    \"\"\"Filters rows where the specified string column contains the provided substring.\"\"\"\n    return dataframe[dataframe[column_name].str.contains(substring, na=False)]\n</code></pre>"},{"location":"reference/ts_shape/transform/filter/string_filter/#ts_shape.transform.filter.string_filter.StringFilter.filter_value_string_match","title":"filter_value_string_match  <code>classmethod</code>","text":"<pre><code>filter_value_string_match(dataframe: DataFrame, string_value: str, column_name: str = 'value_string') -&gt; DataFrame\n</code></pre> <p>Filters rows where the specified string column matches the provided string.</p> Source code in <code>src/ts_shape/transform/filter/string_filter.py</code> <pre><code>@classmethod\ndef filter_value_string_match(cls, dataframe: pd.DataFrame, string_value: str, column_name: str = 'value_string') -&gt; pd.DataFrame:\n    \"\"\"Filters rows where the specified string column matches the provided string.\"\"\"\n    return dataframe[dataframe[column_name] == string_value]\n</code></pre>"},{"location":"reference/ts_shape/transform/filter/string_filter/#ts_shape.transform.filter.string_filter.StringFilter.filter_value_string_not_match","title":"filter_value_string_not_match  <code>classmethod</code>","text":"<pre><code>filter_value_string_not_match(dataframe: DataFrame, string_value: str, column_name: str = 'value_string') -&gt; DataFrame\n</code></pre> <p>Filters rows where the specified string column does not match the provided string.</p> Source code in <code>src/ts_shape/transform/filter/string_filter.py</code> <pre><code>@classmethod\ndef filter_value_string_not_match(cls, dataframe: pd.DataFrame, string_value: str, column_name: str = 'value_string') -&gt; pd.DataFrame:\n    \"\"\"Filters rows where the specified string column does not match the provided string.\"\"\"\n    return dataframe[dataframe[column_name] != string_value]\n</code></pre>"},{"location":"reference/ts_shape/transform/filter/string_filter/#ts_shape.transform.filter.string_filter.StringFilter.get_dataframe","title":"get_dataframe","text":"<pre><code>get_dataframe() -&gt; DataFrame\n</code></pre> <p>Returns the processed DataFrame.</p> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def get_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"Returns the processed DataFrame.\"\"\"\n    return self.dataframe\n</code></pre>"},{"location":"reference/ts_shape/transform/filter/string_filter/#ts_shape.transform.filter.string_filter.StringFilter.regex_clean_value_string","title":"regex_clean_value_string  <code>classmethod</code>","text":"<pre><code>regex_clean_value_string(dataframe: DataFrame, column_name: str = 'value_string', regex_pattern: str = '(\\\\d+)\\\\s*([a-zA-Z]*)', replacement: str = '', regex: bool = True) -&gt; DataFrame\n</code></pre> <p>Applies a regex pattern to clean the specified string column.</p> Source code in <code>src/ts_shape/transform/filter/string_filter.py</code> <pre><code>@classmethod\ndef regex_clean_value_string(cls, dataframe: pd.DataFrame, column_name: str = 'value_string', regex_pattern: str = r'(\\d+)\\s*([a-zA-Z]*)', replacement: str = '', regex: bool = True) -&gt; pd.DataFrame:\n    \"\"\"Applies a regex pattern to clean the specified string column.\"\"\"\n    dataframe[column_name] = dataframe[column_name].str.replace(regex_pattern, replacement, regex=regex)\n    return dataframe\n</code></pre>"},{"location":"reference/ts_shape/transform/functions/__init__/","title":"init","text":""},{"location":"reference/ts_shape/transform/functions/__init__/#ts_shape.transform.functions","title":"functions","text":"<p>Modules:</p> <ul> <li> <code>lambda_func</code>           \u2013            </li> </ul>"},{"location":"reference/ts_shape/transform/functions/lambda_func/","title":"lambda_func","text":""},{"location":"reference/ts_shape/transform/functions/lambda_func/#ts_shape.transform.functions.lambda_func","title":"lambda_func","text":"<p>Classes:</p> <ul> <li> <code>LambdaProcessor</code>           \u2013            <p>Provides class methods for applying lambda or callable functions to columns in a pandas DataFrame.</p> </li> </ul>"},{"location":"reference/ts_shape/transform/functions/lambda_func/#ts_shape.transform.functions.lambda_func.LambdaProcessor","title":"LambdaProcessor","text":"<pre><code>LambdaProcessor(dataframe: DataFrame, column_name: str = 'systime')\n</code></pre> <p>               Bases: <code>Base</code></p> <p>Provides class methods for applying lambda or callable functions to columns in a pandas DataFrame. This class inherits from Base, ensuring consistency with other processors.</p> <p>Parameters:</p> <p>Methods:</p> <ul> <li> <code>apply_function</code>             \u2013              <p>Applies a lambda or callable function to a specified column in the DataFrame.</p> </li> <li> <code>get_dataframe</code>             \u2013              <p>Returns the processed DataFrame.</p> </li> </ul> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def __init__(self, dataframe: pd.DataFrame, column_name: str = 'systime') -&gt; pd.DataFrame:\n    \"\"\"\n    Initializes the Base with a DataFrame, detects time columns, converts them to datetime,\n    and sorts the DataFrame by the specified column (or the detected time column if applicable).\n\n    Args:\n        dataframe (pd.DataFrame): The DataFrame to be processed.\n        column_name (str): The column to sort by. Default is 'systime'. If the column is not found or is not a time column, the class will attempt to detect other time columns.\n    \"\"\"\n    self.dataframe = dataframe.copy()\n\n    # Attempt to convert the specified column_name to datetime if it exists\n    if column_name in self.dataframe.columns:\n        self.dataframe[column_name] = pd.to_datetime(self.dataframe[column_name], errors='coerce')\n    else:\n        # If the column_name is not in the DataFrame, fallback to automatic time detection\n        time_columns = [col for col in self.dataframe.columns if 'time' in col.lower() or 'date' in col.lower()]\n\n        # Convert all detected time columns to datetime, if any\n        for col in time_columns:\n            self.dataframe[col] = pd.to_datetime(self.dataframe[col], errors='coerce')\n\n        # If any time columns are detected, sort by the first one; otherwise, do nothing\n        if time_columns:\n            column_name = time_columns[0]\n\n    # Sort by the datetime column (either specified or detected)\n    if column_name in self.dataframe.columns:\n        self.dataframe = self.dataframe.sort_values(by=column_name)\n</code></pre>"},{"location":"reference/ts_shape/transform/functions/lambda_func/#ts_shape.transform.functions.lambda_func.LambdaProcessor(dataframe)","title":"<code>dataframe</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The DataFrame to be processed.</p>"},{"location":"reference/ts_shape/transform/functions/lambda_func/#ts_shape.transform.functions.lambda_func.LambdaProcessor(column_name)","title":"<code>column_name</code>","text":"(<code>str</code>, default:                   <code>'systime'</code> )           \u2013            <p>The column to sort by. Default is 'systime'. If the column is not found or is not a time column, the class will attempt to detect other time columns.</p>"},{"location":"reference/ts_shape/transform/functions/lambda_func/#ts_shape.transform.functions.lambda_func.LambdaProcessor.apply_function","title":"apply_function  <code>classmethod</code>","text":"<pre><code>apply_function(dataframe: DataFrame, column_name: str, func: Callable[[Any], Any]) -&gt; DataFrame\n</code></pre> <p>Applies a lambda or callable function to a specified column in the DataFrame.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: The DataFrame with the transformed column.</p> </li> </ul> Source code in <code>src/ts_shape/transform/functions/lambda_func.py</code> <pre><code>@classmethod\ndef apply_function(cls, dataframe: pd.DataFrame, column_name: str, func: Callable[[Any], Any]) -&gt; pd.DataFrame:\n    \"\"\"\n    Applies a lambda or callable function to a specified column in the DataFrame.\n\n    Args:\n        dataframe (pd.DataFrame): The DataFrame containing the data.\n        column_name (str): The name of the column to apply the function to.\n        func (Callable): The lambda function or callable to apply to the column.\n\n    Returns:\n        pd.DataFrame: The DataFrame with the transformed column.\n    \"\"\"\n    if column_name not in dataframe.columns:\n        raise ValueError(f\"Column '{column_name}' not found in DataFrame.\")\n\n    dataframe[column_name] = func(dataframe[column_name].values)\n    return dataframe\n</code></pre>"},{"location":"reference/ts_shape/transform/functions/lambda_func/#ts_shape.transform.functions.lambda_func.LambdaProcessor.apply_function(dataframe)","title":"<code>dataframe</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The DataFrame containing the data.</p>"},{"location":"reference/ts_shape/transform/functions/lambda_func/#ts_shape.transform.functions.lambda_func.LambdaProcessor.apply_function(column_name)","title":"<code>column_name</code>","text":"(<code>str</code>)           \u2013            <p>The name of the column to apply the function to.</p>"},{"location":"reference/ts_shape/transform/functions/lambda_func/#ts_shape.transform.functions.lambda_func.LambdaProcessor.apply_function(func)","title":"<code>func</code>","text":"(<code>Callable</code>)           \u2013            <p>The lambda function or callable to apply to the column.</p>"},{"location":"reference/ts_shape/transform/functions/lambda_func/#ts_shape.transform.functions.lambda_func.LambdaProcessor.get_dataframe","title":"get_dataframe","text":"<pre><code>get_dataframe() -&gt; DataFrame\n</code></pre> <p>Returns the processed DataFrame.</p> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def get_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"Returns the processed DataFrame.\"\"\"\n    return self.dataframe\n</code></pre>"},{"location":"reference/ts_shape/transform/time_functions/__init__/","title":"init","text":""},{"location":"reference/ts_shape/transform/time_functions/__init__/#ts_shape.transform.time_functions","title":"time_functions","text":"<p>Modules:</p> <ul> <li> <code>timestamp_converter</code>           \u2013            </li> <li> <code>timezone_shift</code>           \u2013            </li> </ul>"},{"location":"reference/ts_shape/transform/time_functions/timestamp_converter/","title":"timestamp_converter","text":""},{"location":"reference/ts_shape/transform/time_functions/timestamp_converter/#ts_shape.transform.time_functions.timestamp_converter","title":"timestamp_converter","text":"<p>Classes:</p> <ul> <li> <code>TimestampConverter</code>           \u2013            <p>A class dedicated to converting high-precision timestamp data (e.g., in seconds, milliseconds, microseconds, or nanoseconds)</p> </li> </ul>"},{"location":"reference/ts_shape/transform/time_functions/timestamp_converter/#ts_shape.transform.time_functions.timestamp_converter.TimestampConverter","title":"TimestampConverter","text":"<pre><code>TimestampConverter(dataframe: DataFrame, column_name: str = 'systime')\n</code></pre> <p>               Bases: <code>Base</code></p> <p>A class dedicated to converting high-precision timestamp data (e.g., in seconds, milliseconds, microseconds, or nanoseconds) to standard datetime formats with optional timezone adjustment.</p> <p>Parameters:</p> <p>Methods:</p> <ul> <li> <code>convert_to_datetime</code>             \u2013              <p>Converts specified columns from a given timestamp unit to datetime format in a target timezone.</p> </li> <li> <code>get_dataframe</code>             \u2013              <p>Returns the processed DataFrame.</p> </li> </ul> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def __init__(self, dataframe: pd.DataFrame, column_name: str = 'systime') -&gt; pd.DataFrame:\n    \"\"\"\n    Initializes the Base with a DataFrame, detects time columns, converts them to datetime,\n    and sorts the DataFrame by the specified column (or the detected time column if applicable).\n\n    Args:\n        dataframe (pd.DataFrame): The DataFrame to be processed.\n        column_name (str): The column to sort by. Default is 'systime'. If the column is not found or is not a time column, the class will attempt to detect other time columns.\n    \"\"\"\n    self.dataframe = dataframe.copy()\n\n    # Attempt to convert the specified column_name to datetime if it exists\n    if column_name in self.dataframe.columns:\n        self.dataframe[column_name] = pd.to_datetime(self.dataframe[column_name], errors='coerce')\n    else:\n        # If the column_name is not in the DataFrame, fallback to automatic time detection\n        time_columns = [col for col in self.dataframe.columns if 'time' in col.lower() or 'date' in col.lower()]\n\n        # Convert all detected time columns to datetime, if any\n        for col in time_columns:\n            self.dataframe[col] = pd.to_datetime(self.dataframe[col], errors='coerce')\n\n        # If any time columns are detected, sort by the first one; otherwise, do nothing\n        if time_columns:\n            column_name = time_columns[0]\n\n    # Sort by the datetime column (either specified or detected)\n    if column_name in self.dataframe.columns:\n        self.dataframe = self.dataframe.sort_values(by=column_name)\n</code></pre>"},{"location":"reference/ts_shape/transform/time_functions/timestamp_converter/#ts_shape.transform.time_functions.timestamp_converter.TimestampConverter(dataframe)","title":"<code>dataframe</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The DataFrame to be processed.</p>"},{"location":"reference/ts_shape/transform/time_functions/timestamp_converter/#ts_shape.transform.time_functions.timestamp_converter.TimestampConverter(column_name)","title":"<code>column_name</code>","text":"(<code>str</code>, default:                   <code>'systime'</code> )           \u2013            <p>The column to sort by. Default is 'systime'. If the column is not found or is not a time column, the class will attempt to detect other time columns.</p>"},{"location":"reference/ts_shape/transform/time_functions/timestamp_converter/#ts_shape.transform.time_functions.timestamp_converter.TimestampConverter.convert_to_datetime","title":"convert_to_datetime  <code>classmethod</code>","text":"<pre><code>convert_to_datetime(dataframe: DataFrame, columns: list, unit: str = 'ns', timezone: str = 'UTC') -&gt; DataFrame\n</code></pre> <p>Converts specified columns from a given timestamp unit to datetime format in a target timezone.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: A DataFrame with the converted datetime columns in the specified timezone.</p> </li> </ul> Source code in <code>src/ts_shape/transform/time_functions/timestamp_converter.py</code> <pre><code>@classmethod\ndef convert_to_datetime(cls, dataframe: pd.DataFrame, columns: list, unit: str = 'ns', timezone: str = 'UTC') -&gt; pd.DataFrame:\n    \"\"\"\n    Converts specified columns from a given timestamp unit to datetime format in a target timezone.\n\n    Args:\n        dataframe (pd.DataFrame): The DataFrame containing the data.\n        columns (list): A list of column names with timestamp data to convert.\n        unit (str): The unit of the timestamps ('s', 'ms', 'us', or 'ns').\n        timezone (str): The target timezone for the converted datetime (default is 'UTC').\n\n    Returns:\n        pd.DataFrame: A DataFrame with the converted datetime columns in the specified timezone.\n    \"\"\"\n    # Validate unit\n    valid_units = ['s', 'ms', 'us', 'ns']\n    if unit not in valid_units:\n        raise ValueError(f\"Invalid unit '{unit}'. Must be one of {valid_units}.\")\n\n    # Validate timezone\n    if timezone not in pytz.all_timezones:\n        raise ValueError(f\"Invalid timezone '{timezone}'. Use a valid timezone name from pytz.all_timezones.\")\n\n    df = dataframe.copy()\n    for col in columns:\n        # Convert timestamps to datetime in UTC first\n        df[col] = pd.to_datetime(df[col], unit=unit, utc=True)\n        # Adjust to the target timezone\n        df[col] = df[col].dt.tz_convert(timezone)\n\n    return df\n</code></pre>"},{"location":"reference/ts_shape/transform/time_functions/timestamp_converter/#ts_shape.transform.time_functions.timestamp_converter.TimestampConverter.convert_to_datetime(dataframe)","title":"<code>dataframe</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The DataFrame containing the data.</p>"},{"location":"reference/ts_shape/transform/time_functions/timestamp_converter/#ts_shape.transform.time_functions.timestamp_converter.TimestampConverter.convert_to_datetime(columns)","title":"<code>columns</code>","text":"(<code>list</code>)           \u2013            <p>A list of column names with timestamp data to convert.</p>"},{"location":"reference/ts_shape/transform/time_functions/timestamp_converter/#ts_shape.transform.time_functions.timestamp_converter.TimestampConverter.convert_to_datetime(unit)","title":"<code>unit</code>","text":"(<code>str</code>, default:                   <code>'ns'</code> )           \u2013            <p>The unit of the timestamps ('s', 'ms', 'us', or 'ns').</p>"},{"location":"reference/ts_shape/transform/time_functions/timestamp_converter/#ts_shape.transform.time_functions.timestamp_converter.TimestampConverter.convert_to_datetime(timezone)","title":"<code>timezone</code>","text":"(<code>str</code>, default:                   <code>'UTC'</code> )           \u2013            <p>The target timezone for the converted datetime (default is 'UTC').</p>"},{"location":"reference/ts_shape/transform/time_functions/timestamp_converter/#ts_shape.transform.time_functions.timestamp_converter.TimestampConverter.get_dataframe","title":"get_dataframe","text":"<pre><code>get_dataframe() -&gt; DataFrame\n</code></pre> <p>Returns the processed DataFrame.</p> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def get_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"Returns the processed DataFrame.\"\"\"\n    return self.dataframe\n</code></pre>"},{"location":"reference/ts_shape/transform/time_functions/timezone_shift/","title":"timezone_shift","text":""},{"location":"reference/ts_shape/transform/time_functions/timezone_shift/#ts_shape.transform.time_functions.timezone_shift","title":"timezone_shift","text":"<p>Classes:</p> <ul> <li> <code>TimezoneShift</code>           \u2013            <p>A class for shifting timestamps in a DataFrame to a different timezone, with methods to handle timezone localization and conversion.</p> </li> </ul>"},{"location":"reference/ts_shape/transform/time_functions/timezone_shift/#ts_shape.transform.time_functions.timezone_shift.TimezoneShift","title":"TimezoneShift","text":"<pre><code>TimezoneShift(dataframe: DataFrame, column_name: str = 'systime')\n</code></pre> <p>               Bases: <code>Base</code></p> <p>A class for shifting timestamps in a DataFrame to a different timezone, with methods to handle timezone localization and conversion.</p> <p>Parameters:</p> <p>Methods:</p> <ul> <li> <code>add_timezone_column</code>             \u2013              <p>Creates a new column with timestamps converted from an input timezone to a target timezone, without altering the original column.</p> </li> <li> <code>calculate_time_difference</code>             \u2013              <p>Calculates the time difference between two timestamp columns.</p> </li> <li> <code>detect_timezone_awareness</code>             \u2013              <p>Detects if a time column in a DataFrame is timezone-aware.</p> </li> <li> <code>get_dataframe</code>             \u2013              <p>Returns the processed DataFrame.</p> </li> <li> <code>list_available_timezones</code>             \u2013              <p>Returns a list of all available timezones.</p> </li> <li> <code>revert_to_original_timezone</code>             \u2013              <p>Reverts a timezone-shifted time column back to the original timezone.</p> </li> <li> <code>shift_timezone</code>             \u2013              <p>Shifts timestamps in the specified column of a DataFrame from a given timezone to a target timezone.</p> </li> </ul> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def __init__(self, dataframe: pd.DataFrame, column_name: str = 'systime') -&gt; pd.DataFrame:\n    \"\"\"\n    Initializes the Base with a DataFrame, detects time columns, converts them to datetime,\n    and sorts the DataFrame by the specified column (or the detected time column if applicable).\n\n    Args:\n        dataframe (pd.DataFrame): The DataFrame to be processed.\n        column_name (str): The column to sort by. Default is 'systime'. If the column is not found or is not a time column, the class will attempt to detect other time columns.\n    \"\"\"\n    self.dataframe = dataframe.copy()\n\n    # Attempt to convert the specified column_name to datetime if it exists\n    if column_name in self.dataframe.columns:\n        self.dataframe[column_name] = pd.to_datetime(self.dataframe[column_name], errors='coerce')\n    else:\n        # If the column_name is not in the DataFrame, fallback to automatic time detection\n        time_columns = [col for col in self.dataframe.columns if 'time' in col.lower() or 'date' in col.lower()]\n\n        # Convert all detected time columns to datetime, if any\n        for col in time_columns:\n            self.dataframe[col] = pd.to_datetime(self.dataframe[col], errors='coerce')\n\n        # If any time columns are detected, sort by the first one; otherwise, do nothing\n        if time_columns:\n            column_name = time_columns[0]\n\n    # Sort by the datetime column (either specified or detected)\n    if column_name in self.dataframe.columns:\n        self.dataframe = self.dataframe.sort_values(by=column_name)\n</code></pre>"},{"location":"reference/ts_shape/transform/time_functions/timezone_shift/#ts_shape.transform.time_functions.timezone_shift.TimezoneShift(dataframe)","title":"<code>dataframe</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The DataFrame to be processed.</p>"},{"location":"reference/ts_shape/transform/time_functions/timezone_shift/#ts_shape.transform.time_functions.timezone_shift.TimezoneShift(column_name)","title":"<code>column_name</code>","text":"(<code>str</code>, default:                   <code>'systime'</code> )           \u2013            <p>The column to sort by. Default is 'systime'. If the column is not found or is not a time column, the class will attempt to detect other time columns.</p>"},{"location":"reference/ts_shape/transform/time_functions/timezone_shift/#ts_shape.transform.time_functions.timezone_shift.TimezoneShift.add_timezone_column","title":"add_timezone_column  <code>classmethod</code>","text":"<pre><code>add_timezone_column(dataframe: DataFrame, time_column: str, input_timezone: str, target_timezone: str) -&gt; DataFrame\n</code></pre> <p>Creates a new column with timestamps converted from an input timezone to a target timezone, without altering the original column.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: A DataFrame with an additional column for the shifted timezone.</p> </li> </ul> Source code in <code>src/ts_shape/transform/time_functions/timezone_shift.py</code> <pre><code>@classmethod\ndef add_timezone_column(cls, dataframe: pd.DataFrame, time_column: str, input_timezone: str, target_timezone: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Creates a new column with timestamps converted from an input timezone to a target timezone, without altering the original column.\n\n    Args:\n        dataframe (pd.DataFrame): The DataFrame containing the data.\n        time_column (str): The name of the time column to convert.\n        input_timezone (str): The timezone of the input timestamps.\n        target_timezone (str): The target timezone.\n\n    Returns:\n        pd.DataFrame: A DataFrame with an additional column for the shifted timezone.\n    \"\"\"\n    # Duplicate the DataFrame to prevent modifying the original column\n    df_copy = dataframe.copy()\n\n    # Create the new timezone-shifted column\n    new_column = f\"{time_column}_{target_timezone.replace('/', '_')}\"\n    df_copy[new_column] = df_copy[time_column]\n\n    # Apply the timezone shift to the new column\n    df_copy = cls.shift_timezone(df_copy, new_column, input_timezone, target_timezone)\n\n    return df_copy\n</code></pre>"},{"location":"reference/ts_shape/transform/time_functions/timezone_shift/#ts_shape.transform.time_functions.timezone_shift.TimezoneShift.add_timezone_column(dataframe)","title":"<code>dataframe</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The DataFrame containing the data.</p>"},{"location":"reference/ts_shape/transform/time_functions/timezone_shift/#ts_shape.transform.time_functions.timezone_shift.TimezoneShift.add_timezone_column(time_column)","title":"<code>time_column</code>","text":"(<code>str</code>)           \u2013            <p>The name of the time column to convert.</p>"},{"location":"reference/ts_shape/transform/time_functions/timezone_shift/#ts_shape.transform.time_functions.timezone_shift.TimezoneShift.add_timezone_column(input_timezone)","title":"<code>input_timezone</code>","text":"(<code>str</code>)           \u2013            <p>The timezone of the input timestamps.</p>"},{"location":"reference/ts_shape/transform/time_functions/timezone_shift/#ts_shape.transform.time_functions.timezone_shift.TimezoneShift.add_timezone_column(target_timezone)","title":"<code>target_timezone</code>","text":"(<code>str</code>)           \u2013            <p>The target timezone.</p>"},{"location":"reference/ts_shape/transform/time_functions/timezone_shift/#ts_shape.transform.time_functions.timezone_shift.TimezoneShift.calculate_time_difference","title":"calculate_time_difference  <code>classmethod</code>","text":"<pre><code>calculate_time_difference(dataframe: DataFrame, start_column: str, end_column: str) -&gt; Series\n</code></pre> <p>Calculates the time difference between two timestamp columns.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>Series</code>           \u2013            <p>pd.Series: A Series with the time differences in seconds.</p> </li> </ul> Source code in <code>src/ts_shape/transform/time_functions/timezone_shift.py</code> <pre><code>@classmethod\ndef calculate_time_difference(cls, dataframe: pd.DataFrame, start_column: str, end_column: str) -&gt; pd.Series:\n    \"\"\"\n    Calculates the time difference between two timestamp columns.\n\n    Args:\n        dataframe (pd.DataFrame): The DataFrame containing the data.\n        start_column (str): The name of the start time column.\n        end_column (str): The name of the end time column.\n\n    Returns:\n        pd.Series: A Series with the time differences in seconds.\n    \"\"\"\n    # Check if both columns are timezone-aware or both are timezone-naive\n    start_is_aware = dataframe[start_column].dt.tz is not None\n    end_is_aware = dataframe[end_column].dt.tz is not None\n\n    if start_is_aware != end_is_aware:\n        raise ValueError(\"Both columns must be either timezone-aware or timezone-naive.\")\n\n    # If timezone-aware, convert both columns to UTC for comparison\n    if start_is_aware:\n        start_times = dataframe[start_column].dt.tz_convert('UTC')\n        end_times = dataframe[end_column].dt.tz_convert('UTC')\n    else:\n        start_times = dataframe[start_column]\n        end_times = dataframe[end_column]\n\n    # Calculate the difference in seconds\n    time_difference = (end_times - start_times).dt.total_seconds()\n\n    return time_difference\n</code></pre>"},{"location":"reference/ts_shape/transform/time_functions/timezone_shift/#ts_shape.transform.time_functions.timezone_shift.TimezoneShift.calculate_time_difference(dataframe)","title":"<code>dataframe</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The DataFrame containing the data.</p>"},{"location":"reference/ts_shape/transform/time_functions/timezone_shift/#ts_shape.transform.time_functions.timezone_shift.TimezoneShift.calculate_time_difference(start_column)","title":"<code>start_column</code>","text":"(<code>str</code>)           \u2013            <p>The name of the start time column.</p>"},{"location":"reference/ts_shape/transform/time_functions/timezone_shift/#ts_shape.transform.time_functions.timezone_shift.TimezoneShift.calculate_time_difference(end_column)","title":"<code>end_column</code>","text":"(<code>str</code>)           \u2013            <p>The name of the end time column.</p>"},{"location":"reference/ts_shape/transform/time_functions/timezone_shift/#ts_shape.transform.time_functions.timezone_shift.TimezoneShift.detect_timezone_awareness","title":"detect_timezone_awareness  <code>classmethod</code>","text":"<pre><code>detect_timezone_awareness(dataframe: DataFrame, time_column: str) -&gt; bool\n</code></pre> <p>Detects if a time column in a DataFrame is timezone-aware.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>bool</code> (              <code>bool</code> )          \u2013            <p>True if the column is timezone-aware, False otherwise.</p> </li> </ul> Source code in <code>src/ts_shape/transform/time_functions/timezone_shift.py</code> <pre><code>@classmethod\ndef detect_timezone_awareness(cls, dataframe: pd.DataFrame, time_column: str) -&gt; bool:\n    \"\"\"\n    Detects if a time column in a DataFrame is timezone-aware.\n\n    Args:\n        dataframe (pd.DataFrame): The DataFrame containing the data.\n        time_column (str): The name of the time column to check.\n\n    Returns:\n        bool: True if the column is timezone-aware, False otherwise.\n    \"\"\"\n    return dataframe[time_column].dt.tz is not None\n</code></pre>"},{"location":"reference/ts_shape/transform/time_functions/timezone_shift/#ts_shape.transform.time_functions.timezone_shift.TimezoneShift.detect_timezone_awareness(dataframe)","title":"<code>dataframe</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The DataFrame containing the data.</p>"},{"location":"reference/ts_shape/transform/time_functions/timezone_shift/#ts_shape.transform.time_functions.timezone_shift.TimezoneShift.detect_timezone_awareness(time_column)","title":"<code>time_column</code>","text":"(<code>str</code>)           \u2013            <p>The name of the time column to check.</p>"},{"location":"reference/ts_shape/transform/time_functions/timezone_shift/#ts_shape.transform.time_functions.timezone_shift.TimezoneShift.get_dataframe","title":"get_dataframe","text":"<pre><code>get_dataframe() -&gt; DataFrame\n</code></pre> <p>Returns the processed DataFrame.</p> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def get_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"Returns the processed DataFrame.\"\"\"\n    return self.dataframe\n</code></pre>"},{"location":"reference/ts_shape/transform/time_functions/timezone_shift/#ts_shape.transform.time_functions.timezone_shift.TimezoneShift.list_available_timezones","title":"list_available_timezones  <code>classmethod</code>","text":"<pre><code>list_available_timezones() -&gt; list\n</code></pre> <p>Returns a list of all available timezones.</p> <p>Returns:</p> <ul> <li> <code>list</code> (              <code>list</code> )          \u2013            <p>A list of strings representing all available timezones.</p> </li> </ul> Source code in <code>src/ts_shape/transform/time_functions/timezone_shift.py</code> <pre><code>@classmethod\ndef list_available_timezones(cls) -&gt; list:\n    \"\"\"\n    Returns a list of all available timezones.\n\n    Returns:\n        list: A list of strings representing all available timezones.\n    \"\"\"\n    return pytz.all_timezones\n</code></pre>"},{"location":"reference/ts_shape/transform/time_functions/timezone_shift/#ts_shape.transform.time_functions.timezone_shift.TimezoneShift.revert_to_original_timezone","title":"revert_to_original_timezone  <code>classmethod</code>","text":"<pre><code>revert_to_original_timezone(dataframe: DataFrame, time_column: str, original_timezone: str) -&gt; DataFrame\n</code></pre> <p>Reverts a timezone-shifted time column back to the original timezone.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: A DataFrame with timestamps reverted to the original timezone.</p> </li> </ul> Source code in <code>src/ts_shape/transform/time_functions/timezone_shift.py</code> <pre><code>@classmethod\ndef revert_to_original_timezone(cls, dataframe: pd.DataFrame, time_column: str, original_timezone: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Reverts a timezone-shifted time column back to the original timezone.\n\n    Args:\n        dataframe (pd.DataFrame): The DataFrame containing the data.\n        time_column (str): The name of the time column to revert.\n        original_timezone (str): The original timezone to revert to.\n\n    Returns:\n        pd.DataFrame: A DataFrame with timestamps reverted to the original timezone.\n    \"\"\"\n    # Validate the original timezone\n    if original_timezone not in pytz.all_timezones:\n        raise ValueError(f\"Invalid original timezone: {original_timezone}\")\n\n    # Convert to the original timezone\n    dataframe[time_column] = dataframe[time_column].dt.tz_convert(original_timezone)\n\n    return dataframe\n</code></pre>"},{"location":"reference/ts_shape/transform/time_functions/timezone_shift/#ts_shape.transform.time_functions.timezone_shift.TimezoneShift.revert_to_original_timezone(dataframe)","title":"<code>dataframe</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The DataFrame containing the data.</p>"},{"location":"reference/ts_shape/transform/time_functions/timezone_shift/#ts_shape.transform.time_functions.timezone_shift.TimezoneShift.revert_to_original_timezone(time_column)","title":"<code>time_column</code>","text":"(<code>str</code>)           \u2013            <p>The name of the time column to revert.</p>"},{"location":"reference/ts_shape/transform/time_functions/timezone_shift/#ts_shape.transform.time_functions.timezone_shift.TimezoneShift.revert_to_original_timezone(original_timezone)","title":"<code>original_timezone</code>","text":"(<code>str</code>)           \u2013            <p>The original timezone to revert to.</p>"},{"location":"reference/ts_shape/transform/time_functions/timezone_shift/#ts_shape.transform.time_functions.timezone_shift.TimezoneShift.shift_timezone","title":"shift_timezone  <code>classmethod</code>","text":"<pre><code>shift_timezone(dataframe: DataFrame, time_column: str, input_timezone: str, target_timezone: str) -&gt; DataFrame\n</code></pre> <p>Shifts timestamps in the specified column of a DataFrame from a given timezone to a target timezone.</p> <p>Parameters:</p> <p>Returns:</p> <ul> <li> <code>DataFrame</code>           \u2013            <p>pd.DataFrame: A DataFrame with timestamps converted to the target timezone.</p> </li> </ul> Source code in <code>src/ts_shape/transform/time_functions/timezone_shift.py</code> <pre><code>@classmethod\ndef shift_timezone(cls, dataframe: pd.DataFrame, time_column: str, input_timezone: str, target_timezone: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Shifts timestamps in the specified column of a DataFrame from a given timezone to a target timezone.\n\n    Args:\n        dataframe (pd.DataFrame): The DataFrame containing the data.\n        time_column (str): The name of the time column to convert.\n        input_timezone (str): The timezone of the input timestamps (e.g., 'UTC' or 'America/New_York').\n        target_timezone (str): The target timezone to shift to (e.g., 'America/New_York').\n\n    Returns:\n        pd.DataFrame: A DataFrame with timestamps converted to the target timezone.\n    \"\"\"\n    # Validate timezones\n    if input_timezone not in pytz.all_timezones:\n        raise ValueError(f\"Invalid input timezone: {input_timezone}\")\n    if target_timezone not in pytz.all_timezones:\n        raise ValueError(f\"Invalid target timezone: {target_timezone}\")\n\n    # Ensure the time column is in datetime format\n    if not pd.api.types.is_datetime64_any_dtype(dataframe[time_column]):\n        raise ValueError(f\"Column '{time_column}' must contain datetime values.\")\n\n    # Localize to the specified input timezone if timestamps are naive\n    dataframe[time_column] = pd.to_datetime(dataframe[time_column])\n    if dataframe[time_column].dt.tz is None:\n        dataframe[time_column] = dataframe[time_column].dt.tz_localize(input_timezone)\n    else:\n        # Convert from the existing timezone to the specified input timezone, if they differ\n        dataframe[time_column] = dataframe[time_column].dt.tz_convert(input_timezone)\n\n    # Convert to the target timezone\n    dataframe[time_column] = dataframe[time_column].dt.tz_convert(target_timezone)\n\n    return dataframe\n</code></pre>"},{"location":"reference/ts_shape/transform/time_functions/timezone_shift/#ts_shape.transform.time_functions.timezone_shift.TimezoneShift.shift_timezone(dataframe)","title":"<code>dataframe</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The DataFrame containing the data.</p>"},{"location":"reference/ts_shape/transform/time_functions/timezone_shift/#ts_shape.transform.time_functions.timezone_shift.TimezoneShift.shift_timezone(time_column)","title":"<code>time_column</code>","text":"(<code>str</code>)           \u2013            <p>The name of the time column to convert.</p>"},{"location":"reference/ts_shape/transform/time_functions/timezone_shift/#ts_shape.transform.time_functions.timezone_shift.TimezoneShift.shift_timezone(input_timezone)","title":"<code>input_timezone</code>","text":"(<code>str</code>)           \u2013            <p>The timezone of the input timestamps (e.g., 'UTC' or 'America/New_York').</p>"},{"location":"reference/ts_shape/transform/time_functions/timezone_shift/#ts_shape.transform.time_functions.timezone_shift.TimezoneShift.shift_timezone(target_timezone)","title":"<code>target_timezone</code>","text":"(<code>str</code>)           \u2013            <p>The target timezone to shift to (e.g., 'America/New_York').</p>"},{"location":"reference/ts_shape/utils/__init__/","title":"init","text":""},{"location":"reference/ts_shape/utils/__init__/#ts_shape.utils","title":"utils","text":"<p>Modules:</p> <ul> <li> <code>base</code>           \u2013            </li> </ul>"},{"location":"reference/ts_shape/utils/base/","title":"base","text":""},{"location":"reference/ts_shape/utils/base/#ts_shape.utils.base","title":"base","text":"<p>Classes:</p> <ul> <li> <code>Base</code>           \u2013            </li> </ul>"},{"location":"reference/ts_shape/utils/base/#ts_shape.utils.base.Base","title":"Base","text":"<pre><code>Base(dataframe: DataFrame, column_name: str = 'systime')\n</code></pre> <p>Parameters:</p> <p>Methods:</p> <ul> <li> <code>get_dataframe</code>             \u2013              <p>Returns the processed DataFrame.</p> </li> </ul> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def __init__(self, dataframe: pd.DataFrame, column_name: str = 'systime') -&gt; pd.DataFrame:\n    \"\"\"\n    Initializes the Base with a DataFrame, detects time columns, converts them to datetime,\n    and sorts the DataFrame by the specified column (or the detected time column if applicable).\n\n    Args:\n        dataframe (pd.DataFrame): The DataFrame to be processed.\n        column_name (str): The column to sort by. Default is 'systime'. If the column is not found or is not a time column, the class will attempt to detect other time columns.\n    \"\"\"\n    self.dataframe = dataframe.copy()\n\n    # Attempt to convert the specified column_name to datetime if it exists\n    if column_name in self.dataframe.columns:\n        self.dataframe[column_name] = pd.to_datetime(self.dataframe[column_name], errors='coerce')\n    else:\n        # If the column_name is not in the DataFrame, fallback to automatic time detection\n        time_columns = [col for col in self.dataframe.columns if 'time' in col.lower() or 'date' in col.lower()]\n\n        # Convert all detected time columns to datetime, if any\n        for col in time_columns:\n            self.dataframe[col] = pd.to_datetime(self.dataframe[col], errors='coerce')\n\n        # If any time columns are detected, sort by the first one; otherwise, do nothing\n        if time_columns:\n            column_name = time_columns[0]\n\n    # Sort by the datetime column (either specified or detected)\n    if column_name in self.dataframe.columns:\n        self.dataframe = self.dataframe.sort_values(by=column_name)\n</code></pre>"},{"location":"reference/ts_shape/utils/base/#ts_shape.utils.base.Base(dataframe)","title":"<code>dataframe</code>","text":"(<code>DataFrame</code>)           \u2013            <p>The DataFrame to be processed.</p>"},{"location":"reference/ts_shape/utils/base/#ts_shape.utils.base.Base(column_name)","title":"<code>column_name</code>","text":"(<code>str</code>, default:                   <code>'systime'</code> )           \u2013            <p>The column to sort by. Default is 'systime'. If the column is not found or is not a time column, the class will attempt to detect other time columns.</p>"},{"location":"reference/ts_shape/utils/base/#ts_shape.utils.base.Base.get_dataframe","title":"get_dataframe","text":"<pre><code>get_dataframe() -&gt; DataFrame\n</code></pre> <p>Returns the processed DataFrame.</p> Source code in <code>src/ts_shape/utils/base.py</code> <pre><code>def get_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"Returns the processed DataFrame.\"\"\"\n    return self.dataframe\n</code></pre>"}]}